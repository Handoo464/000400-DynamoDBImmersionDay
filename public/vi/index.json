[
{
	"uri": "//localhost:1313/vi/2-lbed/2.1/",
	"title": "Bắt đầu",
	"tags": [],
	"description": "",
	"content": "Nền tảng Hãy tưởng tượng bạn đang xây dựng một cửa hàng trực tuyến. Hầu hết các mẫu truy cập của bạn phù hợp rất tốt với thế mạnh của DynamoDB. Tra cứu sản phẩm theo SKU, tìm nội dung giỏ hàng, và xem lịch sử đơn hàng của khách hàng đều là các truy vấn khóa giá trị khá đơn giản.\nTuy nhiên, khi ứng dụng của bạn phát triển, bạn có thể muốn thêm một số mẫu truy cập bổ sung. Tìm kiếm? Lọc? Còn về \u0026ldquo;AI Tạo sinh\u0026rdquo; (Generative AI) mà bạn đã nghe rất nhiều thì sao? Đó có thể là một yếu tố khác biệt thú vị cho ứng dụng của bạn.\nTrong lab này, chúng ta sẽ học cách tích hợp DynamoDB với Amazon OpenSearch Service để hỗ trợ các mẫu truy cập mới đó.\nPhần đầu của các hướng dẫn cài đặt này giống hệt cho LADV, LHOL, LMR, LBED, và LGME - tất cả đều sử dụng cùng một mẫu Cloud9. Chỉ hoàn thành phần này một lần, và chỉ khi bạn chạy nó trên tài khoản của riêng mình. Nếu bạn đã khởi chạy stack Cloud9 trong một lab khác, hãy bỏ qua phần này và chuyển đến phần Launch the zETL CloudFormation stack.\nChỉ hoàn thành phần này nếu bạn tự chạy workshop. Nếu bạn đang ở một sự kiện AWS tổ chức (như re:Invent, Immersion Day, v.v.), hãy truy cập At an AWS hosted Event\nKhởi chạy Cloud9 CloudFormation stack Trong quá trình làm lab, bạn sẽ tạo các tài nguyên có thể phát sinh chi phí hàng chục USD mỗi ngày. Đảm bảo xóa CloudFormation stack ngay khi hoàn thành lab và xác minh tất cả các tài nguyên đã bị xóa.\nKhởi chạy mẫu CloudFormation ở khu vực US West 2 để triển khai các tài nguyên trong tài khoản của bạn:\nHoặc, bạn có thể tải xuống mẫu YAML và khởi chạy theo cách của riêng bạn.\nNhấp vào Next trên hộp thoại đầu tiên.\nTrong phần Parameters, lưu ý rằng Timeout được đặt về 0. Điều này có nghĩa là phiên bản Cloud9 sẽ không ngủ; bạn có thể thay đổi thủ công thành một giá trị như 60 để tránh các chi phí không mong muốn nếu bạn quên xóa stack vào cuối quá trình.\nGiữ nguyên tham số WorkshopZIP và nhấp vào Next.\nCuộn xuống cuối trang và nhấp vào Next, sau đó xem lại phần Template và Parameters. Khi bạn đã sẵn sàng tạo stack, cuộn xuống cuối trang, chọn hộp xác nhận tạo tài nguyên IAM và nhấp vào Submit. Stack sẽ tạo một phiên bản Cloud9 lab, một vai trò cho phiên bản, và một vai trò cho hàm AWS Lambda được sử dụng sau này trong lab. Nó sẽ sử dụng Systems Manager để cấu hình phiên bản Cloud9.\nSau khi CloudFormation stack có trạng thái CREATE_COMPLETE, tiếp tục với stack tiếp theo. Khởi chạy zETL CloudFormation stack Không tiếp tục nếu mẫu CloudFormation Cloud9 chưa hoàn tất triển khai.\nKhởi chạy mẫu CloudFormation ở khu vực US West 2 để triển khai các tài nguyên trong tài khoản của bạn:\nHoặc, bạn có thể tải xuống mẫu YAML và khởi chạy theo cách của riêng bạn.\nNhấp vào Next trên hộp thoại đầu tiên.\nTrong phần Parameters, tùy chọn thay đổi giá trị OpenSearchClusterName để đặt một tên cụ thể cho cụm OpenSearch của bạn hoặc giữ nguyên tham số này. Nhấp vào Next.\nCuộn xuống cuối trang và nhấp vào Next, sau đó xem lại phần Template và Parameters. Khi bạn đã sẵn sàng tạo stack, cuộn xuống cuối trang và nhấp vào Submit.\nSau khi CloudFormation stack có trạng thái CREATE_COMPLETE, tiếp tục kết nối với Cloud9.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.1/3.1.1/",
	"title": "Bắt đầu",
	"tags": [],
	"description": "",
	"content": "Hướng dẫn thiết lập Các hướng dẫn thiết lập này áp dụng cho LADV, LHOL, LMR, LBED, và LGME - tất cả đều sử dụng cùng một mẫu Cloud9. Chỉ hoàn thành phần này một lần và chỉ khi bạn đang chạy nó trên tài khoản của riêng bạn.\nChỉ hoàn thành phần này nếu bạn đang tự thực hiện workshop. Nếu bạn đang tham gia một sự kiện do AWS tổ chức (như re:Invent, Immersion Day, v.v.), hãy truy cập At an AWS hosted Event\nKhởi chạy CloudFormation Stack Trong quá trình thực hiện lab, bạn sẽ tạo ra các bảng DynamoDB có thể gây ra chi phí lên đến hàng chục hoặc hàng trăm đô la mỗi ngày. Đảm bảo bạn xóa các bảng DynamoDB bằng cách sử dụng DynamoDB console và chắc chắn xóa CloudFormation stack ngay khi hoàn thành lab.\nKhởi chạy mẫu CloudFormation trong US West 2 để triển khai các tài nguyên trong tài khoản của bạn: Tuỳ chọn, tải xuống tệp YAML mẫu và khởi chạy theo cách riêng của bạn. Nhấn Next trên hộp thoại đầu tiên.\nTrong phần Parameters (Tham số), lưu ý rằng Timeout được đặt là 0. Điều này có nghĩa là phiên bản Cloud9 sẽ không ngủ; bạn có thể muốn thay đổi thủ công giá trị này thành 60 để tránh các chi phí không mong muốn nếu bạn quên xóa stack khi kết thúc.\nGiữ nguyên tham số WorkshopZIP và nhấp vào Next. Cuộn xuống cuối trang và nhấn Next, sau đó xem lại Template và Parameters. Khi bạn đã sẵn sàng tạo stack, cuộn xuống cuối, đánh dấu vào ô xác nhận tạo các tài nguyên IAM và nhấp vào Create stack. Stack sẽ tạo một phiên bản Cloud9 lab, một vai trò cho phiên bản, và một vai trò cho hàm AWS Lambda được sử dụng sau này trong lab. Nó sẽ sử dụng Systems Manager để cấu hình phiên bản Cloud9.\nSau khi CloudFormation stack có trạng thái CREATE_COMPLETE, tiếp tục sang Bước 1.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.1/",
	"title": "Bắt đầu",
	"tags": [],
	"description": "",
	"content": "Bạn sẽ có 2 lựa chọn để bắt đầu:\nBắt đầu bằng từ EC2 Instance Bắt đầu từ Cloud9 "
},
{
	"uri": "//localhost:1313/vi/5-lmr/5.1/",
	"title": "Bắt đầu",
	"tags": [],
	"description": "",
	"content": " Phần đầu tiên của hướng dẫn thiết lập này giống hệt nhau cho LADV, LHOL, LMR, LBED, và LGME - tất cả đều sử dụng cùng một mẫu Cloud9. Chỉ hoàn thành phần này một lần và chỉ khi bạn đang chạy nó trên tài khoản của riêng mình. Nếu bạn đã khởi chạy Cloud9 stack trong một phòng thí nghiệm khác, hãy bỏ qua và chuyển đến phần Launch the zETL CloudFormation stack.\nChỉ hoàn thành phần này nếu bạn tự chạy workshop. Nếu bạn đang tham gia một sự kiện do AWS tổ chức (như re:Invent, Immersion Day, v.v.), hãy chuyển đến At an AWS hosted Event.\nKhởi chạy Cloud9 CloudFormation stack Trong suốt quá trình của phòng thí nghiệm, bạn sẽ tạo các tài nguyên có thể phát sinh chi phí lên đến hàng chục đô la mỗi ngày. Hãy đảm bảo bạn xóa CloudFormation stack ngay khi hoàn thành phòng thí nghiệm và xác minh rằng tất cả các tài nguyên đã được xóa.\nKhởi chạy mẫu CloudFormation tại US West 2 để triển khai các tài nguyên vào tài khoản của bạn: Tùy chọn, tải xuống mẫu YAML và khởi chạy theo cách riêng của bạn.\nNhấp vào Next trên hộp thoại đầu tiên.\nTrong phần Parameters, lưu ý rằng Timeout được đặt là 0. Điều này có nghĩa là phiên bản Cloud9 sẽ không ngủ; bạn có thể muốn thay đổi thủ công giá trị này thành một số như 60 để tránh các chi phí không mong đợi nếu bạn quên xóa stack khi kết thúc.\nĐể nguyên tham số WorkshopZIP không thay đổi và nhấp vào Next.\nCuộn xuống dưới cùng và nhấp vào Next, sau đó xem lại Template và Parameters. Khi bạn đã sẵn sàng tạo stack, cuộn xuống dưới cùng, chọn hộp xác nhận việc tạo tài nguyên IAM và nhấp vào Submit. Stack sẽ tạo một phiên bản Cloud9 lab, một vai trò cho phiên bản này, và một vai trò cho hàm AWS Lambda sẽ được sử dụng sau này trong phòng thí nghiệm. Nó sẽ sử dụng Systems Manager để cấu hình phiên bản Cloud9.\nSau khi CloudFormation stack là CREATE_COMPLETE, tiếp tục với stack tiếp theo. Tải xuống và xem lại mã Trong phòng thí nghiệm này, bạn sử dụng các script Python để tương tác với DynamoDB API. Chạy các lệnh sau trong terminal AWS Cloud9 của bạn để tải xuống và giải nén mã của phòng thí nghiệm này.\ncd ~/environment curl -sL https://amazon-dynamodb-labs.com/assets/battle-royale.zip -o battle-royal.zip \u0026amp;\u0026amp; unzip -oq battle-royal.zip \u0026amp;\u0026amp; rm battle-royal.zip Bạn sẽ thấy hai thư mục trong trình duyệt tệp AWS Cloud9:\napplication: Thư mục application chứa mã ví dụ cho việc đọc và ghi dữ liệu trong bảng của bạn. Mã này tương tự như mã bạn sẽ có trong ứng dụng trò chơi thực tế của mình.\nscripts: Thư mục scripts chứa các script ở cấp độ quản trị viên, như tạo bảng, thêm chỉ mục phụ, hoặc xóa bảng.\nBây giờ bạn đã sẵn sàng bắt đầu phòng thí nghiệm. Với DynamoDB, điều quan trọng là phải lập kế hoạch mô hình dữ liệu của bạn trước để bạn có hiệu suất nhanh, nhất quán trong ứng dụng của mình. Trong module tiếp theo, bạn sẽ học về cách lập kế hoạch mô hình dữ liệu của mình.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.1/4.1.1/",
	"title": "Bắt đầu với Cloud9",
	"tags": [],
	"description": "",
	"content": "Create a Cloud9 Environment To complete the steps in these labs, you need an IAM role that has the privileges to create, update and delete AWS Cloud9 environments, Lambda functions, DynamoDB tables, IAM roles, Kinesis Data Streams and DynamoDB Streams\nLog into the AWS Management Console, go to the AWS Cloud9 service dashboard then select Create environment. Give your new environment a name - DynamoDB Labs then provide an optional description for the environment. Select t2.small as your instance type, leave all other fields as the default values then select Create. Wait for creation of your Cloud9 environment to complete then select Open to launch your Cloud9 evironment. Start a command line terminal in Cloud9 and set up the Region and Account ID environment variables.\nexport REGION={your aws region} \u0026amp;\u0026amp; export ACCOUNT_ID={your aws account ID} Install jq on your AWS Cloud9 environment using the command below.\nsudo yum install jq -y After completing the workshop, remember to complete the Clean Up section to remove AWS resources that you no longer require.\nNow that your environment is set up, continue on to the 2. Scenario Overview.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.1/4.1.2/",
	"title": "Bắt đầu với EC2 Instance",
	"tags": [],
	"description": "",
	"content": "Mở giao diện của EC2 Instance và ấn chọn Lauch Instance\nĐặt tên tùy theo ý muốn của bạn ở đây EC2 Instance được đặt là DynamoDB Labs\nChọn Instance type là t3.small\nTạo keypair mới tùy theo ý muốn của bạn\nHãy cấu hình network setting cho EC2 Instance với network có thể kết nối với session manager. Hoặc nếu bạn chưa có kinh nghiệm trước đó bạn có thể tham khảo qua bài viết này: Sau khi hoàn thành bạn có thể thực hiện kết nối EC2 Instance với session manager và thực hiện phần tiếp theo.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.4/4.4.1/",
	"title": "Bật Kinesis Data Streams",
	"tags": [],
	"description": "",
	"content": "Tắt DynamoDB streams cho bảng Orders bằng cách sử dụng các lệnh AWS CLI dưới đây.\naws dynamodb update-table \\ --table-name Orders \\ --stream-specification \\ StreamEnabled=false \\ --query \u0026#34;Table.StreamSpecification.StreamEnabled\u0026#34; Xác nhận rằng DynamoDB streams đã bị vô hiệu hóa bằng cách sử dụng các lệnh AWS CLI dưới đây.\naws dynamodb describe-table \\ --table-name Orders \\ --query \u0026#34;Table.StreamSpecification.StreamEnabled\u0026#34; Kết quả đầu ra sẽ trả về một giá trị boolean như dưới đây.\nnull Tạo một luồng dữ liệu Kinesis có tên Orders bằng cách sử dụng lệnh sau.\naws kinesis create-stream --stream-name Orders --shard-count 2 Xác nhận rằng luồng đang hoạt động bằng cách sử dụng lệnh sau.\naws kinesis describe-stream \\ --stream-name Orders \\ --query \u0026#34;StreamDescription.[StreamStatus, StreamARN]\u0026#34; Ví dụ về kết quả đầu ra:\n[ \u0026#34;ACTIVE\u0026#34;, \u0026#34;arn:aws:kinesis:${REGION}:${ACCOUNT_ID}:stream/Orders\u0026#34; ] Kích hoạt streaming Kinesis cho bảng DynamoDB Orders bằng cách sử dụng lệnh sau. Sao chép ARN từ lệnh trước đó vào tham số \u0026ndash;stream-arn.\naws dynamodb enable-kinesis-streaming-destination \\ --table-name Orders \\ --stream-arn arn:aws:kinesis:${REGION}:${ACCOUNT_ID}:stream/Orders Ví dụ về kết quả đầu ra:\n{ \u0026#34;TableName\u0026#34;: \u0026#34;Orders\u0026#34;, \u0026#34;StreamArn\u0026#34;: \u0026#34;arn:aws:kinesis:${REGION}:${ACCOUNT_ID}:stream/Orders\u0026#34;, \u0026#34;DestinationStatus\u0026#34;: \u0026#34;ENABLING\u0026#34;, \u0026#34;EnableKinesisStreamingConfiguration\u0026#34;: {} } Xác nhận rằng streaming Kinesis đang hoạt động trên bảng Orders bằng cách sử dụng lệnh sau.\naws dynamodb describe-kinesis-streaming-destination \\ --table-name Orders \\ --query \u0026#34;KinesisDataStreamDestinations[0].DestinationStatus\u0026#34; Ví dụ về kết quả đầu ra sẽ bao gồm tên bảng, ARN của luồng dữ liệu Kinesis và trạng thái streaming.\n\u0026#34;ACTIVE\u0026#34; "
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.3/4.3.1/",
	"title": "Bật luồng DynamoDB",
	"tags": [],
	"description": "",
	"content": "Khi kích hoạt DynamoDB streams trên một bảng, bạn có thể chọn ghi lại một trong các tùy chọn sau:\nKey attributes chỉ - chỉ các thuộc tính khóa của mục đang được cập nhật New image - hình ảnh mới của một mục sau khi nó được cập nhật Old image - hình ảnh ban đầu của một mục trước khi nó được cập nhật New and old images - hình ảnh trước và sau của một mục sau khi cập nhật. Vì yêu cầu cho kịch bản này là chỉ giữ bản hiện tại của các đơn hàng trên bảng Orders, bạn sẽ thiết lập DynamoDB stream cho bảng để chỉ lưu trữ old image của các mục khi thực hiện các cập nhật. New image không cần được ghi vào stream vì không cần thiết.\nKích hoạt DynamoDB streams trên bảng Orders bằng cách chạy lệnh AWS CLI dưới đây.\naws dynamodb update-table \\ --table-name Orders \\ --stream-specification \\ StreamEnabled=true,StreamViewType=OLD_IMAGE \\ --query \u0026#34;TableDescription.LatestStreamArn\u0026#34; Xác nhận rằng DynamoDB streams đã được kích hoạt bằng cách sử dụng các lệnh AWS CLI dưới đây.\naws dynamodb describe-table \\ --table-name Orders \\ --query \u0026#34;Table.StreamSpecification.StreamEnabled\u0026#34; Kết quả đầu ra sẽ trả về một giá trị boolean như dưới đây.\ntrue "
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.2/7.2.1/",
	"title": "Best Practices",
	"tags": [],
	"description": "",
	"content": "Sử dụng các phương pháp tốt nhất sau đây khi mô hình hóa dữ liệu với DynamoDB Tập trung vào các mẫu truy cập Khi thực hiện bất kỳ loại mô hình hóa dữ liệu nào, bạn sẽ bắt đầu với một sơ đồ thực thể-mối quan hệ mô tả các đối tượng khác nhau (hoặc thực thể) trong ứng dụng của bạn và cách chúng được kết nối (hoặc các mối quan hệ giữa các thực thể của bạn).\nTrong các cơ sở dữ liệu quan hệ, bạn sẽ đặt các thực thể của mình trực tiếp vào các bảng và chỉ định các mối quan hệ bằng cách sử dụng khóa ngoại. Sau khi bạn đã xác định các bảng dữ liệu của mình, cơ sở dữ liệu quan hệ cung cấp một ngôn ngữ truy vấn linh hoạt để trả về dữ liệu dưới dạng bạn cần.\nTrong DynamoDB, bạn cần xem xét các mẫu truy cập trước khi mô hình hóa bảng của mình. Các cơ sở dữ liệu NoSQL tập trung vào tốc độ, không phải tính linh hoạt. Bạn cần hỏi trước cách bạn sẽ truy cập dữ liệu của mình, sau đó mô hình hóa dữ liệu theo cách nó sẽ được truy cập.\nTrước khi thiết kế bảng DynamoDB của bạn, hãy ghi lại mọi nhu cầu mà bạn cần để đọc và ghi dữ liệu trong ứng dụng của mình. Hãy kỹ lưỡng và suy nghĩ về tất cả các luồng trong ứng dụng của bạn bởi vì bạn sẽ tối ưu hóa bảng của mình cho các mẫu truy cập của bạn.\nTối ưu hóa số lượng yêu cầu đến DynamoDB Sau khi bạn đã ghi lại các nhu cầu về mẫu truy cập của ứng dụng, bạn đã sẵn sàng để thiết kế bảng của mình. Bạn nên thiết kế bảng để giảm thiểu số lượng yêu cầu đến DynamoDB cho mỗi mẫu truy cập. Lý tưởng nhất là mỗi mẫu truy cập chỉ cần một yêu cầu duy nhất đến DynamoDB, do đó bạn muốn giảm số lần round-trip từ ứng dụng đến bảng.\nĐể tối ưu hóa số lượng yêu cầu đến DynamoDB, bạn cần hiểu một số khái niệm cốt lõi: Khóa chính (Primary Keys)\nChỉ mục phụ (Secondary Indexes)\nGiao dịch (Transactions)\nĐừng giả lập mô hình quan hệ Những người mới sử dụng DynamoDB thường cố gắng triển khai mô hình quan hệ trên nền tảng DynamoDB không quan hệ. Nếu bạn cố gắng làm điều này, bạn sẽ mất hầu hết các lợi ích của DynamoDB.\nCác anti-pattern (phản mẫu) phổ biến nhất mà mọi người thử với DynamoDB là: Chuẩn hóa (Normalization)\nTrong cơ sở dữ liệu quan hệ, bạn chuẩn hóa dữ liệu của mình để giảm dư thừa dữ liệu và không gian lưu trữ, sau đó sử dụng các phép nối (joins) để kết hợp nhiều bảng khác nhau. Tuy nhiên, các phép nối ở quy mô lớn rất chậm và tốn kém. DynamoDB không cho phép các phép nối vì chúng sẽ chậm lại khi bảng của bạn phát triển.\nMột loại thực thể cho mỗi bảng\nBảng DynamoDB của bạn thường bao gồm các loại dữ liệu khác nhau trong một bảng duy nhất. Trong ví dụ này, bạn có các thực thể User, Game, và UserGameMapping trong một bảng duy nhất. Trong cơ sở dữ liệu quan hệ, điều này sẽ được mô hình hóa như ba bảng khác nhau.\nQuá nhiều chỉ mục phụ\nMọi người thường cố gắng tạo một chỉ mục phụ cho mỗi mẫu truy cập bổ sung mà họ cần. DynamoDB không có schema, và điều này cũng áp dụng cho các chỉ mục của bạn. Hãy sử dụng tính linh hoạt trong các thuộc tính của bạn để tái sử dụng một chỉ mục phụ duy nhất cho nhiều loại dữ liệu trong bảng của bạn. Điều này được gọi là index overloading (quá tải chỉ mục).\nTrong bước tiếp theo, chúng ta sẽ xây dựng sơ đồ thực thể-mối quan hệ và vạch ra các mẫu truy cập ngay từ đầu. Đây luôn nên là các bước đầu tiên khi sử dụng DynamoDB. Sau đó, trong các mô-đun tiếp theo, bạn sẽ triển khai các mẫu truy cập này trong thiết kế bảng.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.9/3.9.1/",
	"title": "Bước 1 - Tạo bảng bản sao",
	"tags": [],
	"description": "",
	"content": "\nHãy tạo một bảng có tên để chứa các hàng được sao chép. Lệnh này dựa trên lệnh để tạo bảng. Kết quả là, nó tạo ra một bảng có thể chứa các mục giống như bảng ngược dòng của nó.logfile_replica``create-table``logfile\naws dynamodb create-table --table-name logfile_replica \\ --attribute-definitions AttributeName=PK,AttributeType=S AttributeName=GSI_1_PK,AttributeType=S \\ --key-schema AttributeName=PK,KeyType=HASH --provisioned-throughput ReadCapacityUnits=10,WriteCapacityUnits=5 \\ --tags Key=workshop-design-patterns,Value=targeted-for-cleanup \\ --global-secondary-indexes \u0026#34;IndexName=GSI_1,KeySchema=[{AttributeName=GSI_1_PK,KeyType=HASH}],\\ Projection={ProjectionType=INCLUDE,NonKeyAttributes=[\u0026#39;bytessent\u0026#39;, \u0026#39;requestid\u0026#39;, \u0026#39;host\u0026#39;]},\\ ProvisionedThroughput={ReadCapacityUnits=10,WriteCapacityUnits=5}\u0026#34; Lệnh này tạo một bảng mới và một chỉ mục phụ toàn cục được liên kết với định nghĩa sau.\nBàn: logfile_replica Lược đồ khóa: HASH (khóa phân vùng) Đơn vị dung lượng đọc bảng (RCU) = 10 Đơn vị dung lượng ghi bảng (WCU) = 5 • Chỉ số phụ toàn cầu: GSI_1 (10 RCU, 5 WCU) - Cho phép truy vấn theo địa chỉ IP máy chủ. Tên thuộc tính (loại) Thuộc tính đặc biệt? Trường hợp sử dụng thuộc tính Giá trị thuộc tính mẫu PK (CHUỖI) Khóa phân vùng Giữ id yêu cầu request#104009 GSI_1_PK (CHUỖI) Khóa phân vùng GSI 1 Chủ nhà host#66.249.67.3 Chạy lệnh sau để đợi cho đến khi bảng hoạt động.\naws dynamodb wait table-exists --table-name logfile_replica "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.5/3.5.1/",
	"title": "Bước 1 - Tạo bảng employees cho global secondary index key quá tải",
	"tags": [],
	"description": "",
	"content": "Chạy lệnh AWS CLI sau để tạo bảng.employees\naws dynamodb create-table --table-name employees \\ --attribute-definitions AttributeName=PK,AttributeType=S AttributeName=SK,AttributeType=S \\ AttributeName=GSI_1_PK,AttributeType=S AttributeName=GSI_1_SK,AttributeType=S \\ --key-schema AttributeName=PK,KeyType=HASH AttributeName=SK,KeyType=RANGE \\ --provisioned-throughput ReadCapacityUnits=100,WriteCapacityUnits=100 \\ --tags Key=workshop-design-patterns,Value=targeted-for-cleanup \\ --global-secondary-indexes \u0026#34;IndexName=GSI_1,\\ KeySchema=[{AttributeName=GSI_1_PK,KeyType=HASH},{AttributeName=GSI_1_SK,KeyType=RANGE}],\\ Projection={ProjectionType=ALL},\\ ProvisionedThroughput={ReadCapacityUnits=100,WriteCapacityUnits=100}\u0026#34; Chạy lệnh sau để đợi cho đến khi bảng hoạt động.\naws dynamodb wait table-exists --table-name employees Hãy xem xét kỹ hơn lệnh create-table. Bạn đang tạo một bảng có tên là employees. Khóa phân vùng trên bảng là PK và nó chứa ID của nhân viên. Khóa sắp xếp là SK, chứa một giá trị được tạo ra mà bạn chọn trong script Python. (Chúng ta sẽ quay lại điểm này trong chốc lát.) Bạn sẽ tạo một chỉ mục phụ toàn cầu trên bảng này và đặt tên là GSI_1; Đây sẽ là một chỉ mục phụ toàn cầu được nạp chồng. Khóa phân vùng trên chỉ mục phụ toàn cầu là GSI_1_PK, và chứa cùng giá trị với khóa sắp xếp SK trên bảng cơ sở. Giá trị khóa sắp xếp GSI_1 là name, và tên thuộc tính của nó là GSI_1_SK.\nBảng: employees Sơ đồ khóa: HASH, RANGE (khóa phân vùng và khóa sắp xếp) Số đơn vị dung lượng đọc (RCUs) của bảng = 100 Số đơn vị dung lượng ghi (WCUs) của bảng = 100 Chỉ mục phụ toàn cầu: GSI_1 (100 RCUs, 100 WCUs) - Cho phép truy vấn theo địa chỉ IP của host. Tên thuộc tính (Loại) Thuộc tính đặc biệt? Trường hợp sử dụng thuộc tính Giá trị mẫu của thuộc tính PK (STRING) Khóa phân vùng ID nhân viên e#129 SK (STRING) Khóa sắp xếp Giá trị được tạo ra root, state#MI GSI_1_PK (STRING) Khóa phân vùng GSI_1 Giá trị được tạo ra root, state#MI GSI_1_SK (STRING) Khóa sắp xếp GSI_1 Tên nhân viên Christine Milsted "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.2/3.2.1/",
	"title": "Bước 1 - Tạo DynamoDB table",
	"tags": [],
	"description": "",
	"content": "Chạy lệnh AWS CLI sau để tạo bảng DynamoDB đầu tiên có tên logfile:\naws dynamodb create-table --table-name logfile \\ --attribute-definitions AttributeName=PK,AttributeType=S AttributeName=GSI_1_PK,AttributeType=S \\ --key-schema AttributeName=PK,KeyType=HASH \\ --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \\ --tags Key=workshop-design-patterns,Value=targeted-for-cleanup \\ --global-secondary-indexes \u0026#34;IndexName=GSI_1,\\ KeySchema=[{AttributeName=GSI_1_PK,KeyType=HASH}],\\ Projection={ProjectionType=INCLUDE,NonKeyAttributes=[\u0026#39;bytessent\u0026#39;]},\\ ProvisionedThroughput={ReadCapacityUnits=5,WriteCapacityUnits=5}\u0026#34; Bảng bạn vừa tạo sẽ có cấu trúc như sau.\nBàn:logfile Lược đồ khóa: HASH (khóa phân vùng) Đơn vị dung lượng đọc bảng (RCU) = 5 Đơn vị dung lượng ghi bảng (WCU) = 5 Chỉ số phụ toàn cầu (GSI): GSI_1 (5 RCU, 5 WCU) - Cho phép truy vấn theo địa chỉ IP máy chủ. Tên thuộc tính (loại) Thuộc tính đặc biệt? Trường hợp sử dụng thuộc tính Giá trị thuộc tính mẫu PK (CHUỖI) Khóa phân vùng Giữ id yêu cầu cho nhật ký truy cập Yêu cầu#104009 GSI_1_PK (CHUỖI) Khóa phân vùng GSI 1 Máy chủ lưu trữ cho yêu cầu, địa chỉ IPv4 Máy chủ#66.249.67.3 Các thuộc tính đặc biệt bao gồm các thuộc tính được đặt tên để xác định khóa chính của một bảng DynamoDB hoặc một chỉ mục phụ toàn cầu (GSI). Chỉ mục phụ toàn cầu có các khóa chính giống như các bảng DynamoDB. Trong DynamoDB, partition key (khóa phân vùng) giống như hash key (khóa băm), và sort key (khóa sắp xếp) giống như range key (khóa phạm vi). Các API của DynamoDB sử dụng thuật ngữ hash và range, trong khi tài liệu của AWS sử dụng thuật ngữ partition và range. Dù bạn sử dụng thuật ngữ nào, hai khóa này cùng nhau tạo thành khóa chính. Để tìm hiểu thêm, vui lòng xem hướng dẫn cho nhà phát triển AWS của chúng tôi về phần khóa chính trong Amazon DynamoDB.\nChạy lệnh AWS CLI sau để đợi cho đến khi bảng chuyển sang trạng thái ACTIVE.\naws dynamodb wait table-exists --table-name logfile Bạn cũng có thể chạy lệnh AWS CLI sau để chỉ nhận trạng thái bảng.\naws dynamodb describe-table --table-name logfile --query \u0026#34;Table.TableStatus\u0026#34; "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.7/3.7.1/",
	"title": "Bước 1 - Tạo global secondary index mới cho City-Department",
	"tags": [],
	"description": "",
	"content": "Chạy lệnh sau để tạo một global secondary index mới có tên là GSI_3:\naws dynamodb update-table --table-name employees \\ --attribute-definitions AttributeName=GSI_3_PK,AttributeType=S AttributeName=GSI_3_SK,AttributeType=S \\ --global-secondary-index-updates file://gsi_city_dept.json Bạn phải chờ cho đến khi chỉ mục được tạo xong trước khi tiếp tục.\nLưu ý rằng lệnh sau sẽ hiển thị trạng thái của global secondary index là CREATING.\naws dynamodb describe-table --table-name employees --query \u0026#34;Table.GlobalSecondaryIndexes[].IndexStatus\u0026#34; Kết quả đầu ra trông tương tự như sau. Thứ tự của các trạng thái bảng có thể khác nhau.\n[ \u0026#34;ACTIVE\u0026#34;, \u0026#34;ACTIVE\u0026#34;, \u0026#34;CREATING\u0026#34; ] Bạn có thể script lệnh này để chạy mỗi hai giây bằng cách sử dụng watch, để bạn dễ dàng thấy khi trạng thái bảng đã thay đổi thành ACTIVE.\n# Watch mặc định kiểm tra mỗi hai giây watch -n 2 \u0026#34;aws dynamodb describe-table --table-name employees --query \\\u0026#34;Table.GlobalSecondaryIndexes[].IndexStatus\\\u0026#34;\u0026#34; Sử dụng Ctrl + C để kết thúc watch sau khi global secondary index đã được tạo.\nChờ cho đến khi chỉ mục mới là ACTIVE trước khi tiếp tục.\n[ \u0026#34;ACTIVE\u0026#34;, \u0026#34;ACTIVE\u0026#34;, \u0026#34;ACTIVE\u0026#34; ] Bây giờ bạn có thể sử dụng global secondary index mới để truy vấn bảng. Bạn phải sử dụng khóa phân vùng, và bạn có thể sử dụng khóa sắp xếp (nhưng không bắt buộc).\nĐối với khóa sắp xếp, bạn có thể sử dụng biểu thức begins_with để truy vấn bắt đầu với thuộc tính bên trái nhất của khóa tổng hợp. Kết quả là, bạn có thể truy vấn tất cả nhân viên trong một thành phố hoặc trong một phòng ban cụ thể ở một thành phố.\nKeyConditionExpression sẽ trông như sau:\nKey(\u0026#39;GSI_3_PK\u0026#39;).eq(\u0026#34;state#{}\u0026#34;.format(\u0026#39;TX\u0026#39;)) \u0026amp; Key(\u0026#39;GSI_3_SK\u0026#39;).begins_with(\u0026#39;Austin\u0026#39;) Chờ cho đến khi IndexStatus là ACTIVE trên tất cả các chỉ mục trước khi tiếp tục. Nếu bạn cố gắng truy vấn một GSI nhưng nó chưa hoàn thành việc tạo, bạn sẽ nhận được lỗi.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.4/3.4.1/",
	"title": "Bước 1 - Tạo GSI",
	"tags": [],
	"description": "",
	"content": "Chỉ mục phụ toàn cầu cho bài tập này đã được tạo trong giai đoạn thiết lập của workshop. Bạn có thể xem mô tả của chỉ mục phụ toàn cầu bằng cách thực thi lệnh AWS CLI sau:\naws dynamodb describe-table --table-name logfile_scan --query \u0026#34;Table.GlobalSecondaryIndexes\u0026#34; Mô tả của các chỉ mục phụ toàn cầu sẽ trông như sau:\n{ \u0026#34;GlobalSecondaryIndexes\u0026#34;: [ { \u0026#34;IndexName\u0026#34;: \u0026#34;GSI_1\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;GSI_1_PK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;GSI_1_SK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], \u0026#34;Projection\u0026#34;: { \u0026#34;ProjectionType\u0026#34;: \u0026#34;KEYS_ONLY\u0026#34; }, \u0026#34;IndexStatus\u0026#34;: \u0026#34;ACTIVE\u0026#34;, \u0026#34;ProvisionedThroughput\u0026#34;: { \u0026#34;NumberOfDecreasesToday\u0026#34;: 0, \u0026#34;ReadCapacityUnits\u0026#34;: 3000, \u0026#34;WriteCapacityUnits\u0026#34;: 5000 }, \u0026#34;IndexSizeBytes\u0026#34;: 0, \u0026#34;ItemCount\u0026#34;: 0, \u0026#34;IndexArn\u0026#34;: \u0026#34;arn:aws:dynamodb:(region):(accountid):table/logfile_scan/index/GSI_1\u0026#34; } ] } Trong ví dụ này, ItemCount của DynamoDB là 0. DynamoDB tính tổng số mục đã thấy trong API này nhiều lần trong ngày, và có thể bạn sẽ thấy một con số khác so với kết quả đầu ra ở trên. Điều này là bình thường.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.8/3.8.1/",
	"title": "Bước 1 - Tạo và tải bảng InvoiceandBilling",
	"tags": [],
	"description": "",
	"content": "Chạy lệnh AWS CLI để tạo bảng có tên và tạo GSI có tên được phân vùng theo thuộc tính của bảng mẹ:InvoiceAndBilling``GSI_1``SK\naws dynamodb create-table --table-name InvoiceAndBills \\ --attribute-definitions AttributeName=PK,AttributeType=S AttributeName=SK,AttributeType=S \\ --key-schema AttributeName=PK,KeyType=HASH AttributeName=SK,KeyType=RANGE \\ --provisioned-throughput ReadCapacityUnits=100,WriteCapacityUnits=100 \\ --tags Key=workshop-design-patterns,Value=targeted-for-cleanup \\ --global-secondary-indexes \u0026#34;IndexName=GSI_1,\\ KeySchema=[{AttributeName=SK,KeyType=HASH}],\\ Projection={ProjectionType=ALL},\\ ProvisionedThroughput={ReadCapacityUnits=100,WriteCapacityUnits=100}\u0026#34; Đợi cho đến khi bảng hoạt động:\naws dynamodb wait table-exists --table-name InvoiceAndBills Sau đó, tải dữ liệu vào bảng InvoiceAndBills:\npython load_invoice.py InvoiceAndBills ./data/invoice-data.csv "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.6/3.6.1/",
	"title": "Bước 1 - Thêm global secondary index mới vào bảng nhân viên",
	"tags": [],
	"description": "",
	"content": "Thêm một global secondary index mới sử dụng thuộc tính is_manager làm khóa phân vùng cho chỉ mục phụ toàn cầu, được lưu trữ dưới thuộc tính có tên GSI_2_PK. Các chức danh công việc của nhân viên được lưu trữ dưới GSI_2_SK.\nChạy lệnh AWS CLI sau:\naws dynamodb update-table --table-name employees \\ --attribute-definitions AttributeName=GSI_2_PK,AttributeType=S AttributeName=GSI_2_SK,AttributeType=S \\ --global-secondary-index-updates file://gsi_manager.json Đợi cho đến khi global secondary index được tạo. Việc này mất khoảng 5 phút.\nKiểm tra kết quả đầu ra của lệnh sau. Nếu \u0026quot;IndexStatus\u0026quot; là \u0026quot;CREATING\u0026quot;, bạn sẽ phải đợi cho đến khi \u0026quot;IndexStatus\u0026quot; là \u0026quot;ACTIVE\u0026quot; trước khi tiếp tục bước tiếp theo.\naws dynamodb describe-table --table-name employees --query \u0026#34;Table.GlobalSecondaryIndexes[].IndexStatus\u0026#34; Kết quả đầu ra ban đầu sẽ trông như sau:\n[ \u0026#34;CREATING\u0026#34;, \u0026#34;ACTIVE\u0026#34; ] Bạn cũng có thể script lệnh này để chạy mỗi 2 giây bằng cách sử dụng watch.\n# Watch mặc định kiểm tra mỗi 2 giây watch -n 2 \u0026#34;aws dynamodb describe-table --table-name employees --query \\\u0026#34;Table.GlobalSecondaryIndexes[].IndexStatus\\\u0026#34;\u0026#34; Nhấn Ctrl + C để kết thúc watch sau khi global secondary index đã được tạo.\nĐợi cho đến khi chỉ mục mới là ACTIVE trước khi tiếp tục.\n[ \u0026#34;ACTIVE\u0026#34;, \u0026#34;ACTIVE\u0026#34; ] Không tiếp tục cho đến khi IndexStatus là ACTIVE trên cả hai chỉ mục. Truy vấn chỉ mục trước khi nó ACTIVE sẽ dẫn đến lỗi truy vấn.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.3/3.3.1/",
	"title": "Bước 1 - Thực hiện quét tuần tự",
	"tags": [],
	"description": "",
	"content": "Đầu tiên, thực hiện một thao tác Scan đơn giản (tuần tự) để tính tổng số byte được gửi cho tất cả các bản ghi với mã phản hồi khác 200 (response code \u0026lt;\u0026gt; 200). Bạn có thể chạy một thao tác Scan với biểu thức lọc (filter expression) để lọc ra các bản ghi không liên quan. Sau đó, worker ứng dụng sẽ tính tổng giá trị của tất cả các bản ghi trả về mà mã phản hồi khác 200.\nTệp Python, scan_logfile_simple.py, bao gồm lệnh để chạy một thao tác Scan với biểu thức lọc và sau đó tính tổng số byte đã gửi.\nKhối mã sau đây quét bảng.\nfe = \u0026#34;responsecode \u0026lt;\u0026gt; :f\u0026#34; eav = {\u0026#34;:f\u0026#34;: 200} response = table.scan( FilterExpression=fe, ExpressionAttributeValues=eav, Limit=pageSize, ProjectionExpression=\u0026#39;bytessent\u0026#39;) Bạn có thể xem tệp này bằng cách chạy lệnh vim ~/workshop/scan_logfile_simple.py. Nhập :q và nhấn enter để thoát vim.\nLưu ý rằng có một tham số Limit được đặt trong lệnh Scan. Một thao tác Scan đơn lẻ sẽ đọc tối đa số mục được đặt (nếu sử dụng tham số Limit) hoặc tối đa 1 MB dữ liệu, sau đó áp dụng bất kỳ bộ lọc nào vào kết quả bằng cách sử dụng FilterExpression. Nếu tổng số mục đã quét vượt quá giới hạn tối đa được đặt bởi tham số Limit hoặc giới hạn kích thước tập dữ liệu là 1 MB, quá trình quét sẽ dừng lại và kết quả được trả về cho người dùng dưới dạng giá trị LastEvaluatedKey. Giá trị này có thể được sử dụng trong một thao tác tiếp theo để bạn có thể tiếp tục từ nơi đã dừng lại.\nTrong đoạn mã sau, giá trị LastEvaluatedKey trong phản hồi được truyền cho phương thức Scan thông qua tham số ExclusiveStartKey.\nwhile \u0026#39;LastEvaluatedKey\u0026#39; in response: response = table.scan( FilterExpression=fe, ExpressionAttributeValues=eav, Limit=pageSize, ExclusiveStartKey=response[\u0026#39;LastEvaluatedKey\u0026#39;], ProjectionExpression=\u0026#39;bytessent\u0026#39;) for i in response[\u0026#39;Items\u0026#39;]: totalbytessent += i[\u0026#39;bytessent\u0026#39;] Khi trang cuối cùng được trả về, LastEvaluatedKey không còn là một phần của phản hồi, vì vậy bạn biết rằng quá trình quét đã hoàn tất.\nBây giờ, hãy thực thi đoạn mã này.\npython scan_logfile_simple.py logfile_scan Tham số: Tên bảng: logfile_scan\nKết quả đầu ra sẽ trông giống như sau:\nScanning 1 million rows of table logfile_scan to get the total of bytes sent Total bytessent 6054250 in 16.325594425201416 seconds Hãy ghi lại thời gian cần thiết để hoàn tất quá trình quét. Với tập dữ liệu trong bài tập này, một thao tác quét song song sẽ hoàn thành nhanh hơn so với quét tuần tự.\n"
},
{
	"uri": "//localhost:1313/vi/6-leda/6.3/6.3.1/",
	"title": "Bước 1: Kết nối StateLambda",
	"tags": [],
	"description": "",
	"content": "Mục tiêu của bước này là kết nối hàm StateLambda với luồng Kinesis IncomingDataStream như minh họa trong sơ đồ dưới đây. Khi các thông điệp mới có sẵn trong luồng Kinesis, hàm StateLambda sẽ được kích hoạt để xử lý các bản ghi luồng. Mỗi bản ghi luồng chứa một giao dịch đơn lẻ.\nKết nối hàm StateLambda với Kinesis Data Stream Sử dụng AWS Management Console và điều hướng đến dịch vụ AWS Lambda trong bảng điều khiển. Nhấp vào hàm StateLambda để chỉnh sửa cấu hình của nó. Xem hình dưới đây. Tổng quan hàm cho thấy rằng hàm StateLambda chưa có bất kỳ trình kích hoạt nào. Nhấp vào nút Add trigger. Chỉ định cấu hình sau (xem hình bên dưới để biết chi tiết): Trong menu thả xuống đầu tiên, chọn Kinesis làm nguồn dữ liệu. Đối với luồng Kinesis, chọn IncomingDataStream. Đặt Batch size thành 100. Nhấp Add ở góc dưới bên phải để tạo và kích hoạt một ánh xạ nguồn sự kiện trên hàm Lambda. Tại thời điểm này, bạn đã cấu hình một kết nối dựa trên sự kiện giữa Kinesis Data Streams và AWS Lambda. Hàm StateLambda sẽ được kích hoạt mỗi khi có thông điệp mới xuất hiện trong IncomingDataStream. Các thông điệp sẽ được truyền đến hàm Lambda theo từng lô tối đa 100 thông điệp một lần.\nLàm thế nào để biết nó đang hoạt động? Nếu tất cả đã được thực hiện đúng, thì hàm StateLambda sẽ được kích hoạt với các bản ghi luồng từ luồng Kinesis. Do đó, trong vòng một đến hai phút, bạn sẽ có thể thấy các bản ghi từ các lần gọi Lambda dưới mục Monitor trong tab Logs.\nBạn cũng có thể quan sát đầu ra của StateLambda để xác minh kết nối bằng cách xem phần Items trong bảng điều khiển DynamoDB. Để làm điều đó, điều hướng đến dịch vụ DynamoDB trong bảng điều khiển AWS, nhấp vào Items ở bên trái, và chọn StateTable.\nTại giai đoạn này, bạn sẽ thấy nhiều hàng tương tự như hình dưới đây. Số lượng mục trả về có thể khác nhau. Bạn có thể nhấp vào nút màu cam Run nếu muốn làm mới các mục.\n"
},
{
	"uri": "//localhost:1313/vi/6-leda/6.4/6.4.1/",
	"title": "Bước 1: Ngăn chặn trùng lặp tại hàm StateLambda",
	"tags": [],
	"description": "",
	"content": "Mục tiêu của bước này là chỉnh sửa hàm StateLambda để đảm bảo nó không ghi thành công các thông điệp trùng lặp vào các tài nguyên hạ nguồn.\nNghiên cứu mã nguồn của StateLambda Sử dụng AWS Management Console và điều hướng đến dịch vụ AWS Lambda trong console. Nhấp vào hàm StateLambda để chỉnh sửa cấu hình của nó. Nhấp vào tab Code để truy cập mã nguồn của hàm Lambda. Trong trình duyệt mã của Lambda, tìm đoạn mã sau:\ntable.update_item( Key = { constants.STATE_TABLE_KEY: record_id }, UpdateExpression = \u0026#39;SET #VALUE = :new_value,\u0026#39; + \\ \u0026#39;#VERSION = :new_version,\u0026#39; + \\ \u0026#39;#HIERARCHY = :new_hierarchy,\u0026#39; + \\ \u0026#39;#TIMESTAMP = :new_time\u0026#39;, ExpressionAttributeNames={ \u0026#39;#VALUE\u0026#39;: constants.VALUE_COLUMN_NAME, \u0026#39;#VERSION\u0026#39;: constants.VERSION_COLUMN_NAME, \u0026#39;#HIERARCHY\u0026#39;: constants.HIERARCHY_COLUMN_NAME, \u0026#39;#TIMESTAMP\u0026#39;: constants.TIMESTAMP_COLUMN_NAME }, ExpressionAttributeValues={ \u0026#39;:new_version\u0026#39;: record_version, \u0026#39;:new_value\u0026#39;: Decimal(str(record_value)), \u0026#39;:new_hierarchy\u0026#39;: json.dumps(record_hierarchy, sort_keys = True), \u0026#39;:new_time\u0026#39;: Decimal(str(record_time)) } ) Lời gọi phương thức này tạo ra một thao tác UpdateItem với các thuộc tính sau:\nMột thao tác ghi sẽ được thực hiện trên các thuộc tính được liệt kê trong UpdateExpression: Giá trị, phiên bản, hệ thống phân cấp, và dấu thời gian sẽ được thiết lập với các giá trị cung cấp trong ExpressionAttributeValues. Tên thuộc tính được định nghĩa trong ExpressionAttributeNames được lấy từ các hằng số chúng ta đã định nghĩa bên ngoài tệp hàm này. Giá trị của biến STATE_TABLE_KEY chứa tên khóa phân vùng, và giá trị của thuộc tính sẽ là record_id. Đáng chú ý là thao tác ghi này không có kiểm tra điều kiện để ngăn chặn ghi trùng lặp. Chỉnh sửa câu lệnh table.update_item để bao gồm biểu thức điều kiện Bây giờ, hãy so sánh với đoạn mã sau:\ntable.update_item( Key = { constants.STATE_TABLE_KEY: record_id }, ConditionExpression = \u0026#39;attribute_not_exists(\u0026#39; + constants.STATE_TABLE_KEY + \u0026#39;) OR \u0026#39; + constants.VERSION_COLUMN_NAME + \u0026#39;\u0026lt; :new_version\u0026#39;, UpdateExpression = \u0026#39;SET #VALUE = :new_value,\u0026#39; + \\ \u0026#39;#VERSION = :new_version,\u0026#39; + \\ \u0026#39;#HIERARCHY = :new_hierarchy,\u0026#39; + \\ \u0026#39;#TIMESTAMP = :new_time\u0026#39;, ExpressionAttributeNames={ \u0026#39;#VALUE\u0026#39;: constants.VALUE_COLUMN_NAME, \u0026#39;#VERSION\u0026#39;: constants.VERSION_COLUMN_NAME, \u0026#39;#HIERARCHY\u0026#39;: constants.HIERARCHY_COLUMN_NAME, \u0026#39;#TIMESTAMP\u0026#39;: constants.TIMESTAMP_COLUMN_NAME }, ExpressionAttributeValues={ \u0026#39;:new_version\u0026#39;: record_version, \u0026#39;:new_value\u0026#39;: Decimal(str(record_value)), \u0026#39;:new_hierarchy\u0026#39;: json.dumps(record_hierarchy, sort_keys = True), \u0026#39;:new_time\u0026#39;: Decimal(str(record_time)) } ) Đoạn mã ở dòng 5 thêm một điều kiện phức hợp đảm bảo rằng một mục chỉ được chèn nếu nó chưa tồn tại, hoặc nếu có, thì nó chỉ được thay thế nếu mục mới có số phiên bản lớn hơn (ví dụ, là một phiên bản mới hơn của mục). Đây là phiên bản đơn giản hóa của biểu thức điều kiện đó:\nattribute_not_exists(\u0026lsquo;PRIMARY KEY\u0026rsquo;) OR \u0026lsquo;CURRENT VERSION\u0026rsquo; \u0026lt; \u0026lsquo;NEW VERSION\u0026rsquo;\nGiải thích, điều kiện đầu tiên chỉ ra rằng tại thời điểm chèn dữ liệu, bảng không nên chứa một mục với khóa phân vùng pk bằng với record_id nếu không thao tác ghi sẽ thất bại (xem hàm attribute_not_exists), điều này ngụ ý rằng đây là lần đầu tiên một mục/thông điệp như vậy được chèn vào. Sau đó, với sự kết hợp của từ khóa OR, điều kiện nói rằng nếu một hàng đã tồn tại trong bảng và số phiên bản của hàng được chèn lớn hơn hàng hiện tại thì thao tác ghi nên thành công.\nBạn chưa cần thay đổi gì trong mã Lambda của mình, điều này sẽ đến trong ít phút nếu bạn đọc tiếp.\nTại sao nó hoạt động? Biểu thức điều kiện này cho phép chúng ta phát hiện và xử lý các trường hợp khi một thông điệp bị trùng lặp bởi các thành phần đầu nguồn, hoặc nếu một số thông điệp đến không đúng thứ tự. Những tình huống này có thể xảy ra nếu Lambda ở đầu nguồn đưa cùng một thông điệp vào dòng Kinesis nhiều hơn một lần, chẳng hạn. Trong các trường hợp như vậy, lỗi ConditionalCheckFailedException sẽ được đưa ra và không có dữ liệu nào được chèn vào cơ sở dữ liệu. Tiếp theo, chúng ta cần chỉnh sửa mã của mình để xử lý đúng các lỗi này vì chúng hiện được coi là bình thường và mong đợi.\nBắt ngoại lệ ClientError và triển khai thay đổi Chúng ta muốn tránh việc hàm Lambda bị lỗi và sau đó phải khởi động lại, vì vậy chúng ta sẽ thêm một trình xử lý lỗi phù hợp trong trường hợp gặp lỗi khi ghi điều kiện. Đây là một phương pháp tốt nhất để kiểm tra tên của ngoại lệ, ví dụ: e.response['Error']['Code'], để xác định liệu ngoại lệ có bình thường hay chỉ ra một vấn đề sâu hơn.\nĐoạn mã sau đây sẽ bỏ qua lỗi ConditionalCheckFailedException trong khi vẫn đưa ra lỗi cho tất cả các ngoại lệ khác:\ntry: table.update_item( Key = { constants.STATE_TABLE_KEY: record_id }, ConditionExpression = \u0026#39;attribute_not_exists(\u0026#39; + constants.STATE_TABLE_KEY + \u0026#39;) OR \u0026#39; + constants.VERSION_COLUMN_NAME + \u0026#39;\u0026lt; :new_version\u0026#39;, UpdateExpression = \u0026#39;SET #VALUE = :new_value,\u0026#39; + \\ \u0026#39;#VERSION = :new_version,\u0026#39; + \\ \u0026#39;#HIERARCHY = :new_hierarchy,\u0026#39; + \\ \u0026#39;#TIMESTAMP = :new_time\u0026#39;, ExpressionAttributeNames={ \u0026#39;#VALUE\u0026#39;: constants.VALUE_COLUMN_NAME, \u0026#39;#VERSION\u0026#39;: constants.VERSION_COLUMN_NAME, \u0026#39;#HIERARCHY\u0026#39;: constants.HIERARCHY_COLUMN_NAME, \u0026#39;#TIMESTAMP\u0026#39;: constants.TIMESTAMP_COLUMN_NAME }, ExpressionAttributeValues={ \u0026#39;:new_version\u0026#39;: record_version, \u0026#39;:new_value\u0026#39;: Decimal(str(record_value)), \u0026#39;:new_hierarchy\u0026#39;: json.dumps(record_hierarchy, sort_keys = True), \u0026#39;:new_time\u0026#39;: Decimal(str(record_time)) } ) except ClientError as e: if e.response[\u0026#39;Error\u0026#39;][\u0026#39;Code\u0026#39;]==\u0026#39;ConditionalCheckFailedException\u0026#39;: print(\u0026#39;Conditional put failed.\u0026#39; + \\ \u0026#39; This is either a duplicate or a more recent version already arrived.\u0026#39;) print(\u0026#39;Id: \u0026#39;, record_id) print(\u0026#39;Hierarchy: \u0026#39;, record_hierarchy) print(\u0026#39;Value: \u0026#39;, record_value) print(\u0026#39;Version: \u0026#39;, record_version) print(\u0026#39;Timestamp: \u0026#39;, record_time) else: raise e Sao chép đoạn mã trên và thay thế nó vào vị trí của câu lệnh table.update_item(...) hiện có trong mã hàm StateLambda của bạn. Sau đó nhấp vào Deploy để áp dụng các thay đổi.\nThay đổi trên cũng sẽ giúp tránh các ghi trùng lặp khi dịch vụ Lambda thử lại hàm StateLambda sau khi trước đó đã thất bại với một lô thông điệp đến. Với thay đổi này, chúng ta tránh ghi trùng lặp vào StateTable, điều này đảm bảo chúng ta không tạo ra các thông điệp bổ sung trong dòng DynamoDB stream của StateTable.\nLàm sao để biết bạn đã sửa lỗi? Điều hướng đến StateLambda và mở Logs dưới tab Monitor. Kiểm tra các thông báo nhật ký bằng cách nhấp vào ô LogStream liên kết và xác minh rằng bạn thấy chuỗi sau trong các dòng nhật ký: Conditional put failed. This is either a duplicate.... Thông báo này được tạo ra bởi mã xử lý ngoại lệ ở trên. Điều này cho chúng ta biết rằng biểu thức điều kiện đang hoạt động như mong đợi.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.1/1.1.1/",
	"title": "Chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Khởi động stack CloudFormation\nTrong quá trình lab, bạn sẽ tạo các bảng DynamoDB có thể phát sinh chi phí lên đến hàng chục hoặc hàng trăm đô la mỗi ngày. Hãy đảm bảo xóa các bảng DynamoDB bằng cách sử dụng bảng điều khiển DynamoDB, và hãy chắc chắn rằng bạn xóa stack CloudFormation ngay sau khi hoàn thành lab.\nKhởi động mẫu CloudFormation ở miền US West 2 để triển khai các tài nguyên trong tài khoản của bạn: Tùy chọn, tải xuống the YAML template và khởi động nó theo cách của riêng bạn. Nhấp vào *Next trên hộp thoại đầu tiên.\nTrong phần Parameters, lưu ý rằng Timeout được đặt thành 0. Điều này có nghĩa là phiên Cloud9 sẽ không ngủ; bạn có thể muốn thay đổi giá trị này thành một giá trị như 60 để bảo vệ khỏi những khoản phí bất ngờ nếu bạn quên xóa stack khi kết thúc. Giữ nguyên tham số WorkshopZIP và nhấp Next. Leave the WorkshopZIP parameter unchanged and click Next. Cuộn xuống dưới cùng và nhấp Next, sau đó xem lại Mẫu và Tham số. Khi bạn sẵn sàng tạo stack, cuộn xuống dưới cùng, đánh dấu hộp xác nhận việc tạo các tài nguyên IAM, và nhấp vào Create stack. Stack sẽ tạo một phiên bản Cloud9 lab, một role cho instance đó, và một role cho hàm AWS Lambda được sử dụng sau này trong lab. Nó sẽ sử dụng Systems Manager để cấu hình phiên bản Cloud9.\nSau khi stack CloudFormation có trạng thái CREATE_COMPLETE, hãy tiếp tục đến phần tiếp theo.\nTruy cập EC2 tìm kiếm Instance đã được tạo từ stack.\nThực hiện Connect to instance Chạy lệnh aws sts get-caller-identity chỉ để xác minh rằng thông tin xác thực AWS của bạn đã được cấu hình đúng cách. "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.1/",
	"title": "Chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Trong chương này, chúng ta sẽ đề cập đến các yêu cầu cần thiết để bắt đầu với Amazon DynamoDB. Bạn sẽ tạo các bảng DynamoDB và sử dụng môi trường AWS Cloud9 để truy vấn các bảng này.\nKiến trúc triển khai mà bạn sẽ xây dựng trong lab này sẽ như hình dưới đây.\n"
},
{
	"uri": "//localhost:1313/vi/6-leda/6.1/",
	"title": "Chuẩn bị",
	"tags": [],
	"description": "",
	"content": " Chỉ hoàn thành phần này nếu bạn đang chạy workshop trên tài khoản của mình. Nếu bạn đang tham gia một sự kiện do AWS tổ chức (như re:Invent, Immersion Day, v.v.), hãy truy cập Tại một sự kiện do AWS tổ chức\nKhởi tạo CloudFormation Stack Trong quá trình thực hành, bạn sẽ tạo các bảng DynamoDB có thể phát sinh chi phí lên tới hàng chục hoặc hàng trăm đô la mỗi ngày. Hãy đảm bảo bạn xóa các bảng DynamoDB bằng cách sử dụng bảng điều khiển DynamoDB, và chắc chắn rằng bạn xóa CloudFormation stack ngay khi hoàn thành bài thực hành.\nKhởi chạy mẫu CloudFormation ở vùng US West 2 để triển khai tài nguyên trong tài khoản của bạn: Tùy chọn, tải xuống mẫu YAML và khởi chạy theo cách riêng của bạn Nhấp vào Next trên hộp thoại đầu tiên.\nCuộn xuống cuối và nhấp vào Next, sau đó xem lại Template. Khi bạn đã sẵn sàng tạo stack, cuộn xuống dưới cùng, đánh dấu vào ô chấp nhận việc tạo tài nguyên IAM, và nhấp vào Create stack. Stack sẽ tạo các bảng DynamoDB, hàm Lambda, luồng Kinesis, và các vai trò và chính sách IAM sẽ được sử dụng sau đó trong bài thực hành.\nSau khi CloudFormation stack là CREATE_COMPLETE.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.1/",
	"title": "Chuẩn bị",
	"tags": [],
	"description": "",
	"content": " Nửa đầu của hướng dẫn thiết lập này giống hệt cho LADV, LHOL, LMR, LBED, và LGME - tất cả đều sử dụng cùng một mẫu Cloud9. Chỉ thực hiện phần này một lần, và chỉ khi bạn đang chạy nó trên tài khoản của riêng mình. Nếu bạn đã khởi chạy Cloud9 stack trong một lab khác, hãy bỏ qua phần này và chuyển đến mục Khởi chạy zETL CloudFormation stack.\nChỉ hoàn thành phần này nếu bạn đang tự chạy workshop. Nếu bạn đang tham gia một sự kiện do AWS tổ chức (như re:Invent, Immersion Day, v.v.), hãy đi tới Tại một sự kiện AWS.\nKhởi chạy Cloud9 CloudFormation stack Trong quá trình thực hiện lab, bạn sẽ tạo các tài nguyên có thể gây ra chi phí lên đến hàng chục đô la mỗi ngày. Đảm bảo bạn xóa CloudFormation stack ngay khi hoàn thành lab và xác minh tất cả các tài nguyên đã được xóa.\nKhởi chạy mẫu CloudFormation ở khu vực US West 2 để triển khai các tài nguyên trong tài khoản của bạn: Ngoài ra, bạn có thể tải xuống tệp mẫu YAML và khởi chạy theo cách riêng của bạn.\nNhấp vào Next trên hộp thoại đầu tiên.\nTrong phần Parameters, lưu ý rằng Timeout được đặt thành 0. Điều này có nghĩa là instance Cloud9 sẽ không ngủ; bạn có thể thay đổi thủ công thành một giá trị như 60 để tránh chi phí không mong muốn nếu bạn quên xóa stack khi kết thúc.\nGiữ nguyên tham số WorkshopZIP và nhấp vào Next.\nCuộn xuống dưới cùng và nhấp vào Next, sau đó xem lại Template và Parameters. Khi bạn đã sẵn sàng để tạo stack, cuộn xuống dưới cùng, đánh dấu vào ô xác nhận việc tạo tài nguyên IAM và nhấp vào Submit. Stack sẽ tạo một instance Cloud9 lab, một vai trò cho instance và một vai trò cho hàm AWS Lambda được sử dụng sau này trong lab. Nó sẽ sử dụng Systems Manager để cấu hình instance Cloud9.\nSau khi CloudFormation stack có trạng thái CREATE_COMPLETE, tiếp tục với stack tiếp theo. "
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.2/2.2.1/",
	"title": "Định cấu hình quyền OpenSearch Service",
	"tags": [],
	"description": "",
	"content": "Miền OpenSearch Service được triển khai bởi CloudFormation Template sử dụng kiểm soát truy cập chi tiết (Fine-grained access control). Kiểm soát truy cập chi tiết cung cấp thêm các cách kiểm soát truy cập vào dữ liệu của bạn trên Amazon OpenSearch Service. Để cấu hình tích hợp giữa OpenSearch Service, DynamoDB và Bedrock, một số quyền OpenSearch Service sẽ cần được ánh xạ với IAM Role đang được sử dụng.\nCác liên kết đến OpenSearch Dashboards, thông tin đăng nhập, và các giá trị cần thiết được cung cấp trong phần Outputs của DynamoDBzETL CloudFormation Template. Nên để tab Outputs mở trong một tab trình duyệt để dễ dàng tham khảo trong khi theo dõi bài lab.\nTrong môi trường sản xuất, một thực hành tốt là cấu hình các vai trò với quyền tối thiểu cần thiết. Để đơn giản trong lab này, chúng ta sẽ sử dụng vai trò \u0026ldquo;all_access\u0026rdquo; của OpenSearch Service.\nKhông tiếp tục nếu CloudFormation Template chưa hoàn tất triển khai.\nMở tab \u0026ldquo;Outputs\u0026rdquo; của stack có tên dynamodb-opensearch-setup trong CloudFormation Console.\nMở liên kết \u0026ldquo;SecretConsoleLink\u0026rdquo; trong một tab mới. Điều này sẽ đưa bạn đến bí mật trong AWS Secrets Manager chứa thông tin đăng nhập cho OpenSearch. Nhấp vào nút Retrieve secret value để xem tên người dùng và mật khẩu cho OpenSearch Cluster.\nQuay lại tab \u0026ldquo;Outputs\u0026rdquo; của CloudFormation Console và mở liên kết cho OSDashboardsURL trong một tab mới.\nĐăng nhập vào Dashboards với tên người dùng và mật khẩu được cung cấp trong Secrets Manager.\nKhi được nhắc chọn tenant, chọn Global và nhấp vào Confirm. Đóng mọi cửa sổ bật lên.\nMở menu trên cùng bên trái và chọn Security trong phần Management.\nMở tab \u0026ldquo;Roles\u0026rdquo;, sau đó nhấp vào vai trò \u0026ldquo;all_access\u0026rdquo;.\nMở tab \u0026ldquo;Mapped users\u0026rdquo;, sau đó chọn \u0026ldquo;Manage mapping\u0026rdquo;.\nTrong trường \u0026ldquo;Backend roles\u0026rdquo;, nhập Arn được cung cấp trong CloudFormation Stack Outputs. Thuộc tính có tên \u0026ldquo;Role\u0026rdquo; cung cấp Arn chính xác.\nHãy chắc chắn rằng bạn đã xóa mọi ký tự khoảng trắng từ đầu và cuối của ARN để đảm bảo bạn không gặp vấn đề về quyền sau này. Nhấp vào \u0026ldquo;Map\u0026rdquo;.\nXác minh rằng vai trò \u0026ldquo;all_access\u0026rdquo; hiện có một \u0026ldquo;Backend role\u0026rdquo; được liệt kê.\n"
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.3/2.3.1/",
	"title": "Định cấu hình tích hợp",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ cấu hình các kết nối ML và Pipeline trong OpenSearch Service. Các cấu hình này được thiết lập bằng một loạt các yêu cầu POST và PUT được xác thực bằng AWS Signature Version 4 (sig-v4). Sigv4 là cơ chế xác thực tiêu chuẩn được sử dụng bởi các dịch vụ AWS. Mặc dù trong hầu hết các trường hợp, một SDK sẽ tự động xử lý sig-v4, nhưng trong trường hợp này, chúng ta sẽ tự xây dựng các yêu cầu bằng curl.\nĐể tạo một yêu cầu có chữ ký sig-v4, bạn cần một mã thông báo phiên, khóa truy cập và khóa truy cập bí mật. Đầu tiên, bạn sẽ truy xuất các thông tin này từ metadata của Instance Cloud9 của mình bằng script \u0026ldquo;credentials.sh\u0026rdquo; đã cung cấp, script này sẽ xuất các giá trị cần thiết vào các biến môi trường. Trong các bước tiếp theo, bạn cũng sẽ xuất các giá trị khác vào các biến môi trường để dễ dàng thay thế trong các lệnh liệt kê.\nChỉnh sửa credentials.sh Bạn có thể thực hiện chỉnh sửa trên Cloud9/Session manager/VSCode\nỞ trên VSCode bạn cần đăng nhập bằng lệnhsudo su sau đó thực hiện lệnh vim credentials.sh. Với nội dung như dưới đây.\n```bash # Lấy token từ metadata service TOKEN=$(curl -s -X PUT \u0026quot;http://169.254.169.254/latest/api/token\u0026quot; -H \u0026quot;X-aws-ec2-metadata-token-ttl-seconds: 21600\u0026quot;) # Lấy IAM role INSTANCE_ROLE=$(curl -s -H \u0026quot;X-aws-ec2-metadata-token: $TOKEN\u0026quot; http://169.254.169.254/latest/meta-data/iam/security-credentials/) # Lấy thông tin chi tiết về IAM role ROLE_DETAILS=$(curl -s -H \u0026quot;X-aws-ec2-metadata-token: $TOKEN\u0026quot; http://169.254.169.254/latest/meta-data/iam/security-credentials/${INSTANCE_ROLE}) # Trích xuất thông tin từ JSON AccessKeyId=$(echo $ROLE_DETAILS | jq -r '.AccessKeyId') SecretAccessKey=$(echo $ROLE_DETAILS | jq -r '.SecretAccessKey') Token=$(echo $ROLE_DETAILS | jq -r '.Token') Expiration=$(echo $ROLE_DETAILS | jq -r '.Expiration') Region=$(curl -s -H \u0026quot;X-aws-ec2-metadata-token: $TOKEN\u0026quot; http://169.254.169.254/latest/meta-data/placement/region) Role=$(aws sts get-caller-identity | jq -r '.Arn | sub(\u0026quot;sts\u0026quot;;\u0026quot;iam\u0026quot;) | sub(\u0026quot;assumed-role\u0026quot;;\u0026quot;role\u0026quot;) | sub(\u0026quot;/i-[a-zA-Z0-9]+$\u0026quot;;\u0026quot;\u0026quot;)') # Xuất các biến môi trường export METADATA_AWS_ACCESS_KEY_ID=${AccessKeyId} export METADATA_AWS_SECRET_ACCESS_KEY=${SecretAccessKey} export METADATA_AWS_SESSION_TOKEN=${Token} export METADATA_AWS_REGION=${Region} export METADATA_AWS_ROLE=${Role} export METADATA_AWS_EXPIRATION=${Expiration} # Hiển thị thông tin echo \u0026quot;METADATA_AWS_ACCESS_KEY_ID: $AccessKeyId\u0026quot; echo \u0026quot;METADATA_AWS_SECRET_ACCESS_KEY: $SecretAccessKey\u0026quot; echo \u0026quot;METADATA_AWS_SESSION_TOKEN: $Token\u0026quot; echo \u0026quot;METADATA_AWS_REGION: $Region\u0026quot; echo \u0026quot;METADATA_AWS_ROLE: $Role\u0026quot; echo \u0026quot;METADATA_AWS_EXPIRATION: $Expiration\u0026quot; ``` Chạy script credentials.sh để truy xuất và xuất các thông tin xác thực. Các thông tin xác thực này sẽ được sử dụng để ký các yêu cầu API tới cụm OpenSearch. Lưu ý dấu chấm (.) đứng trước \u0026ldquo;./credentials.sh\u0026rdquo;, điều này phải được bao gồm để đảm bảo rằng các thông tin xác thực đã xuất sẽ có sẵn trong shell hiện đang chạy.\n. ./credentials.sh Tiếp theo, xuất một biến môi trường với URL endpoint OpenSearch. URL này được liệt kê trong tab Outputs của CloudFormation Stack với tên \u0026ldquo;OSDomainEndpoint\u0026rdquo;. Biến này sẽ được sử dụng trong các lệnh tiếp theo.\nexport OPENSEARCH_ENDPOINT=\u0026#34;https://search-ddb-os-xxxx-xxxxxxxxxxxxx.us-west-2.es.amazonaws.com\u0026#34; Thực thi lệnh curl sau để tạo kết nối mô hình ML cho OpenSearch.\ncurl --request POST \\ ${OPENSEARCH_ENDPOINT}\u0026#39;/_plugins/_ml/connectors/_create\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --header \u0026#39;Accept: application/json\u0026#39; \\ --header \u0026#34;x-amz-security-token: ${METADATA_AWS_SESSION_TOKEN}\u0026#34; \\ --aws-sigv4 aws:amz:${METADATA_AWS_REGION}:es \\ --user \u0026#34;${METADATA_AWS_ACCESS_KEY_ID}:${METADATA_AWS_SECRET_ACCESS_KEY}\u0026#34; \\ --data-raw \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;Amazon Bedrock Connector: embedding\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The connector to bedrock Titan embedding model\u0026#34;, \u0026#34;version\u0026#34;: 1, \u0026#34;protocol\u0026#34;: \u0026#34;aws_sigv4\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;region\u0026#34;: \u0026#34;\u0026#39;${METADATA_AWS_REGION}\u0026#39;\u0026#34;, \u0026#34;service_name\u0026#34;: \u0026#34;bedrock\u0026#34; }, \u0026#34;credential\u0026#34;: { \u0026#34;roleArn\u0026#34;: \u0026#34;\u0026#39;${METADATA_AWS_ROLE}\u0026#39;\u0026#34; }, \u0026#34;actions\u0026#34;: [ { \u0026#34;action_type\u0026#34;: \u0026#34;predict\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://bedrock-runtime.\u0026#39;${METADATA_AWS_REGION}\u0026#39;.amazonaws.com/model/amazon.titan-embed-text-v1/invoke\u0026#34;, \u0026#34;headers\u0026#34;: { \u0026#34;content-type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;x-amz-content-sha256\u0026#34;: \u0026#34;required\u0026#34; }, \u0026#34;request_body\u0026#34;: \u0026#34;{ \\\u0026#34;inputText\\\u0026#34;: \\\u0026#34;${parameters.inputText}\\\u0026#34; }\u0026#34;, \u0026#34;pre_process_function\u0026#34;: \u0026#34;\\n StringBuilder builder = new StringBuilder();\\n builder.append(\\\u0026#34;\\\\\\\u0026#34;\\\u0026#34;);\\n String first = params.text_docs[0];\\n builder.append(first);\\n builder.append(\\\u0026#34;\\\\\\\u0026#34;\\\u0026#34;);\\n def parameters = \\\u0026#34;{\\\u0026#34; +\\\u0026#34;\\\\\\\u0026#34;inputText\\\\\\\u0026#34;:\\\u0026#34; + builder + \\\u0026#34;}\\\u0026#34;;\\n return \\\u0026#34;{\\\u0026#34; +\\\u0026#34;\\\\\\\u0026#34;parameters\\\\\\\u0026#34;:\\\u0026#34; + parameters + \\\u0026#34;}\\\u0026#34;;\u0026#34;, \u0026#34;post_process_function\u0026#34;: \u0026#34;\\n def name = \\\u0026#34;sentence_embedding\\\u0026#34;;\\n def dataType = \\\u0026#34;FLOAT32\\\u0026#34;;\\n if (params.embedding == null || params.embedding.length == 0) {\\n return params.message;\\n }\\n def shape = [params.embedding.length];\\n def json = \\\u0026#34;{\\\u0026#34; +\\n \\\u0026#34;\\\\\\\u0026#34;name\\\\\\\u0026#34;:\\\\\\\u0026#34;\\\u0026#34; + name + \\\u0026#34;\\\\\\\u0026#34;,\\\u0026#34; +\\n \\\u0026#34;\\\\\\\u0026#34;data_type\\\\\\\u0026#34;:\\\\\\\u0026#34;\\\u0026#34; + dataType + \\\u0026#34;\\\\\\\u0026#34;,\\\u0026#34; +\\n \\\u0026#34;\\\\\\\u0026#34;shape\\\\\\\u0026#34;:\\\u0026#34; + shape + \\\u0026#34;,\\\u0026#34; +\\n \\\u0026#34;\\\\\\\u0026#34;data\\\\\\\u0026#34;:\\\u0026#34; + params.embedding +\\n \\\u0026#34;}\\\u0026#34;;\\n return json;\\n \u0026#34; } ] }\u0026#39; Ghi lại \u0026ldquo;connector_id\u0026rdquo; trả về từ lệnh trước đó. Xuất nó vào một biến môi trường để dễ dàng thay thế trong các lệnh sau.\nexport CONNECTOR_ID=\u0026#39;xxxxxxxxxxxxxx\u0026#39; Chạy lệnh curl tiếp theo để tạo nhóm mô hình (model group).\ncurl --request POST \\ ${OPENSEARCH_ENDPOINT}\u0026#39;/_plugins/_ml/model_groups/_register\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --header \u0026#39;Accept: application/json\u0026#39; \\ --header \u0026#34;x-amz-security-token: ${METADATA_AWS_SESSION_TOKEN}\u0026#34; \\ --aws-sigv4 aws:amz:${METADATA_AWS_REGION}:es \\ --user \u0026#34;${METADATA_AWS_ACCESS_KEY_ID}:${METADATA_AWS_SECRET_ACCESS_KEY}\u0026#34; \\ --data-raw \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;remote_model_group\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;This is an example description\u0026#34; }\u0026#39; Ghi lại \u0026ldquo;model_group_id\u0026rdquo; trả về từ lệnh trước đó. Xuất nó vào một biến môi trường để sử dụng sau này.\nexport MODEL_GROUP_ID=\u0026#39;xxxxxxxxxxxxx\u0026#39; Lệnh curl tiếp theo đăng ký kết nối với nhóm mô hình.\ncurl --request POST \\ ${OPENSEARCH_ENDPOINT}\u0026#39;/_plugins/_ml/models/_register\u0026#39; \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --header \u0026#39;Accept: application/json\u0026#39; \\ --header \u0026#34;x-amz-security-token: ${METADATA_AWS_SESSION_TOKEN}\u0026#34; \\ --aws-sigv4 aws:amz:${METADATA_AWS_REGION}:es \\ --user \u0026#34;${METADATA_AWS_ACCESS_KEY_ID}:${METADATA_AWS_SECRET_ACCESS_KEY}\u0026#34; \\ --data-raw \u0026#39;{ \u0026#34;name\u0026#34;: \u0026#34;Bedrock embedding model\u0026#34;, \u0026#34;function_name\u0026#34;: \u0026#34;remote\u0026#34;, \u0026#34;model_group_id\u0026#34;: \u0026#34;\u0026#39;${MODEL_GROUP_ID}\u0026#39;\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;embedding model\u0026#34;, \u0026#34;connector_id\u0026#34;: \u0026#34;\u0026#39;${CONNECTOR_ID}\u0026#39;\u0026#34; }\u0026#39; Ghi lại \u0026ldquo;model_id\u0026rdquo; và xuất nó.\nexport MODEL_ID=\u0026#39;xxxxxxxxxxxxx\u0026#39; Chạy lệnh sau để xác minh rằng bạn đã xuất thành công connector, model group, và model id.\necho -e \u0026#34;CONNECTOR_ID=${CONNECTOR_ID}\\nMODEL_GROUP_ID=${MODEL_GROUP_ID}\\nMODEL_ID=${MODEL_ID}\u0026#34; Tiếp theo, chúng ta sẽ triển khai mô\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.2/1.2.1/",
	"title": "Đọc dữ liệu mẫu",
	"tags": [],
	"description": "",
	"content": "Trước khi có thể làm bất cứ điều gì, chúng ta cần tìm hiểu về cấu trúc dữ liệu của mình.\nDynamoDB cung cấp API Scan mà bạn có thể gọi bằng lệnh CLI scan. Lệnh Scan sẽ quét toàn bộ bảng và trả về các mục dữ liệu theo từng khối 1MB. Việc quét bảng là cách chậm nhất và tốn kém nhất để lấy dữ liệu ra khỏi DynamoDB; quét một bảng lớn từ CLI có thể sẽ rất phức tạp, nhưng chúng ta biết rằng trong dữ liệu mẫu của chúng ta chỉ có một vài mục, nên có thể thực hiện điều này ở đây. Hãy thử chạy lệnh quét trên bảng ProductCatalog:\naws dynamodb scan --table-name ProductCatalog Sử dụng các phím mũi tên để di chuyển lên và xuống qua phản hồi của lệnh Scan. Nhập :q và nhấn Enter để thoát khỏi chế độ xem khi bạn đã hoàn thành việc xem phản hồi.\nViệc nhập và xuất dữ liệu trong CLI sử dụng định dạng JSON của DynamoDB, được mô tả trong phần API Cấp thấp của DynamoDB trong Hướng dẫn Dành cho Nhà Phát triển.\nChúng ta có thể thấy từ dữ liệu của mình rằng bảng ProductCatalog có hai loại sản phẩm: các mục Sách (Book) và Xe đạp (Bicycle).\nNếu chúng ta muốn đọc chỉ một mục, chúng ta sẽ sử dụng API GetItem mà có thể gọi bằng lệnh CLI get-item. GetItem là cách nhanh nhất và rẻ nhất để lấy dữ liệu ra khỏi DynamoDB vì bạn phải chỉ định đầy đủ Khóa Chính, do đó lệnh được đảm bảo chỉ khớp với tối đa một mục trong bảng.\naws dynamodb get-item \\ --table-name ProductCatalog \\ --key \u0026#39;{\u0026#34;Id\u0026#34;:{\u0026#34;N\u0026#34;:\u0026#34;101\u0026#34;}}\u0026#39; Mặc định, một lần đọc từ DynamoDB sẽ sử dụng đọc nhất quán cuối cùng (eventual consistency) vì các lần đọc nhất quán cuối cùng trong DynamoDB có giá chỉ bằng một nửa so với lần đọc nhất quán mạnh (strongly consistent). Xem thêm thông tin về Tính nhất quán của lần đọc trong Hướng dẫn Dành cho Nhà Phát triển DynamoDB.\nCó nhiều tùy chọn hữu ích cho lệnh get-item, nhưng một số tùy chọn được sử dụng thường xuyên là:\n\u0026ndash;consistent-read: Xác định rằng bạn muốn đọc nhất quán mạnh. \u0026ndash;projection-expression: Xác định rằng bạn chỉ muốn trả về một số thuộc tính nhất định trong yêu cầu. \u0026ndash;return-consumed-capacity: Cho biết mức dung lượng đã được tiêu thụ bởi yêu cầu. Hãy chạy lại lệnh trước đó và thêm một số tùy chọn này vào dòng lệnh:\naws dynamodb get-item \\ --table-name ProductCatalog \\ --key \u0026#39;{\u0026#34;Id\u0026#34;:{\u0026#34;N\u0026#34;:\u0026#34;101\u0026#34;}}\u0026#39; \\ --consistent-read \\ --projection-expression \u0026#34;ProductCategory, Price, Title\u0026#34; \\ --return-consumed-capacity TOTAL Chúng ta có thể thấy từ các giá trị trả về:\n{ \u0026#34;Item\u0026#34;: { \u0026#34;Price\u0026#34;: { \u0026#34;N\u0026#34;: \u0026#34;2\u0026#34; }, \u0026#34;Title\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Book 101 Title\u0026#34; }, \u0026#34;ProductCategory\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Book\u0026#34; } }, \u0026#34;ConsumedCapacity\u0026#34;: { \u0026#34;TableName\u0026#34;: \u0026#34;ProductCatalog\u0026#34;, \u0026#34;CapacityUnits\u0026#34;: 1.0 } } Rằng việc thực hiện yêu cầu này tiêu thụ 1.0 RCU, vì mục này nhỏ hơn 4KB. Nếu chúng ta chạy lại lệnh mà loại bỏ tùy chọn \u0026ndash;consistent-read, chúng ta sẽ thấy rằng các lần đọc nhất quán cuối cùng tiêu thụ dung lượng chỉ bằng một nửa:\naws dynamodb get-item \\ --table-name ProductCatalog \\ --key \u0026#39;{\u0026#34;Id\u0026#34;:{\u0026#34;N\u0026#34;:\u0026#34;101\u0026#34;}}\u0026#39; \\ --projection-expression \u0026#34;ProductCategory, Price, Title\u0026#34; \\ --return-consumed-capacity TOTAL Chúng ta sẽ thấy kết quả đầu ra này:\n{ \u0026#34;Item\u0026#34;: { \u0026#34;Price\u0026#34;: { \u0026#34;N\u0026#34;: \u0026#34;2\u0026#34; }, \u0026#34;Title\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Book 101 Title\u0026#34; }, \u0026#34;ProductCategory\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Book\u0026#34; } }, \u0026#34;ConsumedCapacity\u0026#34;: { \u0026#34;TableName\u0026#34;: \u0026#34;ProductCatalog\u0026#34;, \u0026#34;CapacityUnits\u0026#34;: 0.5 } } "
},
{
	"uri": "//localhost:1313/vi/6-leda/6.5/6.5.1/",
	"title": "Giải pháp",
	"tags": [],
	"description": "",
	"content": "Giải pháp Lab 1 ReduceLambdaPolicy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;ReadFromDynamoDBStream\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34;, \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:ListStreams\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:*:*:table/ReduceTable/stream/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;CreateCloudwatchLogGroup\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;WriteToCloudwatchLogGroup\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:log-group:/aws/lambda/ReduceLambda:*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;WriteToDynamoDBTable\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:UpdateItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:*:*:table/AggregateTable\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;ReadFromParameterTable\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:GetItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:*:*:table/ParameterTable\u0026#34; } ] } Giải pháp Lab 2 Lab 2 StateLambda function complete code # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. # SPDX-License-Identifier: MIT-0 # -------------------------------------------------------------------------------------------------- # Imports # -------------------------------------------------------------------------------------------------- # General Imports import json import time import base64 import random from decimal import Decimal # AWS Imports import boto3 from botocore.exceptions import ClientError # Project Imports import functions import constants # -------------------------------------------------------------------------------------------------- # Lambda Function # -------------------------------------------------------------------------------------------------- def lambda_handler(event, context): # Print Status at Start records = event[\u0026#39;Records\u0026#39;] print(\u0026#39;Invoked StateLambda with \u0026#39; + str(len(records)) + \u0026#39; record(s).\u0026#39;) # Initialize DynamoDB ddb_ressource = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = ddb_ressource.Table(constants.STATE_TABLE_NAME) # Get Failure PCT FAILURE_STATE_LAMBDA_PCT = functions.get_parameter(ddb_ressource, \u0026#34;FAILURE_STATE_LAMBDA_PCT\u0026#34;, 0) # Loop over records for record in records: # Manually Introduced Random Failure if random.uniform(0,100) \u0026lt; FAILURE_STATE_LAMBDA_PCT / len(records): # Raise exception raise Exception(\u0026#39;Manually Introduced Random Failure!\u0026#39;) # Load Record data = json.loads(base64.b64decode(record[\u0026#39;kinesis\u0026#39;][\u0026#39;data\u0026#39;]).decode(\u0026#39;utf-8\u0026#39;)) # Get Entries record_id = data[constants.ID_COLUMN_NAME] record_hierarchy = data[constants.HIERARCHY_COLUMN_NAME] record_value = data[constants.VALUE_COLUMN_NAME] record_version = data[constants.VERSION_COLUMN_NAME] record_time = data[constants.TIMESTAMP_COLUMN_NAME] # If Record is older than 1 Minute -\u0026gt; Ignore it if (time.time() - record_time) \u0026gt; 60: continue # Write to DDB try: table.update_item( Key = { constants.STATE_TABLE_KEY: record_id }, ConditionExpression = \u0026#39;attribute_not_exists(\u0026#39; + constants.STATE_TABLE_KEY + \u0026#39;) OR \u0026#39; + constants.VERSION_COLUMN_NAME + \u0026#39;\u0026lt; :new_version\u0026#39;, UpdateExpression = \u0026#39;SET #VALUE = :new_value,\u0026#39; + \\ \u0026#39;#VERSION = :new_version,\u0026#39; + \\ \u0026#39;#HIERARCHY = :new_hierarchy,\u0026#39; + \\ \u0026#39;#TIMESTAMP = :new_time\u0026#39;, ExpressionAttributeNames={ \u0026#39;#VALUE\u0026#39;: constants.VALUE_COLUMN_NAME, \u0026#39;#VERSION\u0026#39;: constants.VERSION_COLUMN_NAME, \u0026#39;#HIERARCHY\u0026#39;: constants.HIERARCHY_COLUMN_NAME, \u0026#39;#TIMESTAMP\u0026#39;: constants.TIMESTAMP_COLUMN_NAME }, ExpressionAttributeValues={ \u0026#39;:new_version\u0026#39;: record_version, \u0026#39;:new_value\u0026#39;: Decimal(str(record_value)), \u0026#39;:new_hierarchy\u0026#39;: json.dumps(record_hierarchy, sort_keys = True), \u0026#39;:new_time\u0026#39;: Decimal(str(record_time)) } ) except ClientError as e: if e.response[\u0026#39;Error\u0026#39;][\u0026#39;Code\u0026#39;]==\u0026#39;ConditionalCheckFailedException\u0026#39;: print(\u0026#39;Conditional put failed.\u0026#39; + \\ \u0026#39; This is either a duplicate or a more recent version already arrived.\u0026#39;) print(\u0026#39;Id: \u0026#39;, record_id) print(\u0026#39;Hierarchy: \u0026#39;, record_hierarchy) print(\u0026#39;Value: \u0026#39;, record_value) print(\u0026#39;Version: \u0026#39;, record_version) print(\u0026#39;Timestamp: \u0026#39;, record_time) else: raise e # Print Status at End print(\u0026#39;StateLambda successfully processed \u0026#39; + str(len(records)) + \u0026#39; record(s).\u0026#39;) return {\u0026#39;statusCode\u0026#39;: 200} Lab 2 ReduceLambda function complete code # Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. # SPDX-License-Identifier: MIT-0 # -------------------------------------------------------------------------------------------------- # Imports # -------------------------------------------------------------------------------------------------- # General Imports import json import hashlib import random import time # AWS Imports import boto3 from botocore.exceptions import ClientError # Project Imports import functions import constants # -------------------------------------------------------------------------------------------------- # Lambda Function # -------------------------------------------------------------------------------------------------- def lambda_handler(event, context): # Print Status at Start records = event[\u0026#39;Records\u0026#39;] print(\u0026#39;Invoked ReduceLambda with \u0026#39; + str(len(records)) + \u0026#39; Delta message(s).\u0026#39;) # Initialize Dict for Total Delta totals = dict() # Initialize DDB Ressource ddb_ressource = boto3.resource(\u0026#39;dynamodb\u0026#39;) # Keep track of number of batches for timestamp mean batch_count = 0 # Iterate over Messages for record in event[\u0026#39;Records\u0026#39;]: # Aggregate over Batch of Messages the Lambda was invoked with if \u0026#39;NewImage\u0026#39; in record[\u0026#39;dynamodb\u0026#39;]: # Load Message to Dict message = record[\u0026#39;dynamodb\u0026#39;][\u0026#39;NewImage\u0026#39;][\u0026#39;Message\u0026#39;][\u0026#39;S\u0026#39;].replace(\u0026#34;\u0026#39;\u0026#34;,\u0026#39;\u0026#34;\u0026#39;) data = json.loads(message) # Get Batch Count (To Calculate Mean of Timestamp) batch_count += 1 # Iterate over Entries in Message for entry in data: if (entry == constants.TIMESTAMP_GENERATOR_FIRST or entry == constants.TIMESTAMP_GENERATOR_MEAN): continue else: functions.dict_entry_add(totals, entry, data[entry]) # If this batch contains only deletes: Done if not totals: print(\u0026#39;Skipped batch - no new entries.\u0026#39;) return {\u0026#39;statusCode\u0026#39;: 200} # Total Count of New Messages (for Printing) total_new_message_count = totals[constants.MESSAGE_COUNT_NAME] # Update all Values within one single transaction ddb_client = boto3.client(\u0026#39;dynamodb\u0026#39;) # Batch of Items batch = [ { \u0026#39;Update\u0026#39;: { \u0026#39;TableName\u0026#39; : constants.AGGREGATE_TABLE_NAME, \u0026#39;Key\u0026#39; : {constants.AGGREGATE_TABLE_KEY : {\u0026#39;S\u0026#39; : entry}}, \u0026#39;UpdateExpression\u0026#39; : \u0026#34;ADD #val :val \u0026#34;, \u0026#39;ExpressionAttributeValues\u0026#39; : { \u0026#39;:val\u0026#39;: {\u0026#39;N\u0026#39; : str(totals[entry])} }, \u0026#39;ExpressionAttributeNames\u0026#39;: { \u0026#34;#val\u0026#34; : \u0026#34;Value\u0026#34; } } } for entry in totals.keys()] # Calculate hash to ensure this batch hasn\u0026#39;t been processed already: record_list_hash = hashlib.md5(str(records).encode()).hexdigest() response = ddb_client.transact_write_items( TransactItems = batch, ClientRequestToken = record_list_hash ) # Manually Introduced Random Failure if random.uniform(0,100) \u0026lt; functions.get_parameter(ddb_ressource, \u0026#34;FAILURE_REDUCE_LAMBDA_PCT\u0026#34;, 0): # Raise Exception raise Exception(\u0026#39;Manually Introduced Random Failure!\u0026#39;) # Print Status at End print(\u0026#39;ReduceLambda finished. Updates aggregates with \u0026#39; + str(total_new_message_count) + \u0026#39; new message(s) in total.\u0026#39;) return {\u0026#39;statusCode\u0026#39;: 200} "
},
{
	"uri": "//localhost:1313/vi/8-ldc/8.1/",
	"title": "Giỏ hàng bán lẻ",
	"tags": [],
	"description": "",
	"content": "Thử Thách Giỏ Hàng Bán Lẻ Một cửa hàng bán lẻ trực tuyến đã yêu cầu bạn thiết kế lớp lưu trữ dữ liệu và bảng NoSQL cho họ. Trang web phục vụ các khách hàng và các sản phẩm mà họ xem, lưu và mua. Lượng truy cập trang web hiện tại đang thấp, nhưng họ muốn có khả năng phục vụ hàng triệu khách hàng đồng thời.\nKhách hàng tương tác với các sản phẩm có thể có trạng thái ACTIVE, SAVED, hoặc PURCHASED. Một khi sản phẩm được PURCHASED thì sẽ được gán một OrderId. Các sản phẩm có các thuộc tính sau: AccountID, Status (ACTIVE, SAVED, hoặc PURCHASED), CreateTimestamp, và ItemSKU (Tổng kích thước sản phẩm \u0026lt;= 1 KB). Khi khách hàng mở ứng dụng của cửa hàng bán lẻ, họ sẽ xem các sản phẩm ACTIVE trong giỏ hàng của họ, được sắp xếp theo thứ tự sản phẩm được thêm vào gần đây nhất. Người dùng có thể xem các sản phẩm mà họ đã lưu để dùng sau (SAVED), được sắp xếp theo thứ tự gần đây nhất. Người dùng có thể xem các sản phẩm mà họ đã mua (PURCHASED), được sắp xếp theo thứ tự gần đây nhất. Các đội sản phẩm có khả năng thường xuyên truy vấn trên tất cả khách hàng để xác định những người có một sản phẩm cụ thể trong tài khoản của họ với trạng thái là ACTIVE, SAVED, hoặc PURCHASED. Đội Business Intelligence (BI) cần chạy một số truy vấn phức tạp bất kỳ để tạo các báo cáo hàng tuần và hàng tháng. Hãy xây dựng một mô hình dữ liệu NoSQL để đáp ứng phần OLTP (xử lý giao dịch trực tuyến) của công việc. Bạn sẽ đáp ứng yêu cầu của đội BI như thế nào?\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/",
	"title": "LHOL: Hands-on Labs for Amazon DynamoDB",
	"tags": [],
	"description": "",
	"content": "Trong workshop này, bạn sẽ học cách tạo và làm việc với Amazon DynamoDB.\nDưới đây là nội dung mà workshop này bao gồm:\nBắt đầu Khám phá DynamoDB với CLI Khám phá Console DynamoDB Sao lưu LMIG: Mô hình quan hệ \u0026amp; Di chuyển Đối tượng tham gia Workshop này được thiết kế cho các nhà phát triển, kỹ sư và quản trị viên cơ sở dữ liệu tham gia vào việc thiết kế và duy trì các ứng dụng DynamoDB.\nYêu cầu Kiến thức cơ bản về các dịch vụ AWS Trong số các dịch vụ khác, lab này sẽ hướng dẫn bạn sử dụng AWS Cloud9 và AWS Lambda . Hiểu biết cơ bản về DynamoDB Nếu bạn không quen thuộc với DynamoDB hoặc không tham gia lab này như một phần của sự kiện AWS, hãy xem lại tài liệu về \u0026ldquo;What is Amazon DynamoDB? \u0026quot; Khuyến nghị nghiên cứu trước khi tham gia lab Nếu bạn không tham gia một sự kiện AWS và gần đây chưa xem lại các khái niệm thiết kế DynamoDB, chúng tôi đề xuất bạn xem video Advanced Design Patterns for DynamoDB , video này có độ dài khoảng một giờ.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.4/7.4.1/",
	"title": "Mô hình spare GSI",
	"tags": [],
	"description": "",
	"content": "Secondary indexes (Chỉ mục phụ) là công cụ mô hình hóa dữ liệu quan trọng trong DynamoDB. Chúng cho phép bạn tái cấu trúc dữ liệu để phù hợp với các mẫu truy vấn thay thế. Để tạo một chỉ mục phụ, bạn chỉ định khóa chính của chỉ mục, giống như khi bạn đã tạo một bảng trước đó. Lưu ý rằng khóa chính cho global secondary index (chỉ mục phụ toàn cầu) không cần phải duy nhất cho mỗi mục. Sau đó, DynamoDB sao chép các mục vào chỉ mục dựa trên các thuộc tính được chỉ định, và bạn có thể truy vấn nó giống như bạn làm với bảng.\nSử dụng sparse secondary indexes (chỉ mục phụ thưa) là một chiến lược nâng cao trong DynamoDB. Với các chỉ mục phụ, DynamoDB chỉ sao chép các mục từ bảng gốc nếu chúng có các phần tử của khóa chính trong chỉ mục phụ. Các mục không có các phần tử khóa chính sẽ không được sao chép, đó là lý do tại sao các chỉ mục phụ này được gọi là \u0026ldquo;thưa\u0026rdquo;.\nHãy xem cách điều này áp dụng cho chúng ta. Bạn có thể nhớ rằng bạn có hai mẫu truy cập để tìm các trò chơi còn chỗ trống:\nTìm các trò chơi còn chỗ trống (Đọc) Tìm các trò chơi còn chỗ trống theo bản đồ (Đọc) Bạn có thể tạo một global secondary index (GSI) bằng cách sử dụng khóa chính tổng hợp, trong đó partition key (khóa phân vùng) là thuộc tính map của trò chơi và sort key (khóa sắp xếp) là thuộc tính open_timestamp của trò chơi, chỉ ra thời điểm trò chơi được mở.\nPhần quan trọng là khi một trò chơi trở nên đầy, thuộc tính open_timestamp sẽ bị xóa. Khi thuộc tính này bị xóa, trò chơi đã đầy sẽ bị loại khỏi GSI vì nó không có giá trị cho thuộc tính sort key. Đây là cách giữ cho chỉ mục thưa: nó chỉ bao gồm các trò chơi còn chỗ trống có thuộc tính open_timestamp.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.1/",
	"title": "Mở AWS Systems Manager Console",
	"tags": [],
	"description": "",
	"content": " Sau khi bạn đã có quyền truy cập vào Bảng điều khiển quản lý AWS dành cho phòng thực hành, hãy kiểm tra kỹ xem khu vực có chính xác không và tên vai trò WSParticipantRole xuất hiện ở trên cùng bên phải của bảng điều khiển.\nTrong thanh tìm kiếm dịch vụ, tìm kiếm Systems Manager và nhấp vào đó để mở phần AWS Systems Manager của Bảng điều khiển quản lý AWS.\nTrong bảng điều khiển AWS Systems Manager, tìm menu ở bên trái, xác định phần Quản lý nút và chọn Trình quản lý phiên từ danh sách.\nChọn Bắt đầu phiên để khởi chạy phiên shell.\nNhấp vào nút radio để chọn phiên bản EC2 cho phòng thực hành. Nếu bạn thấy không có phiên bản nào, hãy đợi vài phút rồi nhấp vào làm mới. Đợi cho đến khi phiên bản ec2 có tên of sẵn dùng trước khi tiếp tục. Chọn phiên bản.DynamoDBC9\nNhấp vào nút Bắt đầu phiên (Hành động này sẽ mở một tab mới trong trình duyệt của bạn với vỏ màu đen mới).\nTrong vỏ đen mới, chuyển sang tài khoản ubuntu bằng cách chạy sudo su - ubuntu\nsudo su - ubuntu Chạy và chắc chắn rằng nó nói và sau đó thay đổi vào thư mục hội thảo.shopt login_shell``login_shell on\n#Verify login_shell is \u0026#39;on\u0026#39; shopt login_shell #Change into the workshop directory cd ~/workshop/ Đầu ra của các lệnh của bạn trong phiên Trình quản lý phiên sẽ giống như sau:\n$ sudo su - ubuntu :~ $ #Verify login_shell is \u0026#39;on\u0026#39; shopt login_shell #Change into the workshop directory cd ~/workshop/ login_shell on :~/workshop $ "
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Session Management",
	"tags": [],
	"description": "",
	"content": "Amazon DynamoDB Immersion Day Chào mừng bạn đến với AWS Workshop và Lab Content Portal dành cho Amazon DynamoDB , một cơ sở dữ liệu khóa-giá trị và tài liệu mang lại hiệu suất mili giây một chữ số ở mọi quy mô. Tại đây, bạn sẽ tìm thấy bộ sưu tập các hội thảo và nội dung thực hành nhằm giúp bạn hiểu rõ hơn về các tính năng của DynamoDB và các biện pháp thực hành tốt nhất về lập mô hình dữ liệu NoSQL.\n200-level hands on labs (LHOL) bao gồm các bài tập được thiết kế để giúp bạn thích thú với DynamoDB bằng CLI và Bảng điều khiển quản lý AWS. Trang web này cũng bao gồm một hội thảo (LADV) là một tập hợp các hướng dẫn, tập lệnh và dữ liệu hướng dẫn dễ làm theo. Ngoài ra, trang web bao gồm một bộ sưu tập các kịch bản thách thức thiết kế mô hình dữ liệu (LDC) để giúp bạn hiểu các quyết định và sự đánh đổi được đưa ra trong khi xây dựng các mô hình dữ liệu hiệu quả. Nếu bạn đã cảm thấy thoải mái với các chủ đề này và muốn tìm hiểu thêm về các DynamoDB global table, trang web còn có một workshop đa vùng với một tình huống sử dụng thú vị về phát trực tuyến video (LMR).\nKinh nghiệm trước về AWS và cơ sở dữ liệu NoSQL là hữu ích nhưng không bắt buộc để hoàn thành workshop này. Nếu bạn mới làm quen với DynamoDB mà chưa có kinh nghiệm, bạn có thể bắt đầu với Hands-on Labs cho Amazon DynamoDB. Nếu bạn muốn tìm hiểu về các mẫu thiết kế cho DynamoDB, hãy tham khảo các Mẫu Thiết Kế Nâng Cao cho DynamoDB và các kịch bản thách thức thiết kế.\nBạn đang tìm kiếm một thử thách lớn hơn? Ngày hội thảo DynamoDB có một chuỗi hội thảo được thiết kế để bao quát các chủ đề nâng cao. Nếu bạn muốn tìm hiểu sâu về các tập hợp phát trực tuyến với AWS Lambda và DynamoDB Streams, hãy xem xét LEDA. Hoặc nếu bạn muốn giới thiệu CDC dễ dàng hơn, bạn có thể xem xét LCDC. Bạn có muốn tích hợp Generative AI để tạo ra một ứng dụng lý luận nhận biết ngữ cảnh không? Nếu vậy, hãy xem xét LBED, một phòng thực hành lấy danh mục sản phẩm từ DynamoDB và liên tục lập chỉ mục vào OpenSearch Service cho các truy vấn ngôn ngữ tự nhiên được Amazon Bedrock hỗ trợ.\nNội dung:\nLHOL: Hands-on Labs for Amazon DynamoDB LBED: Generative AI with DynamoDB zero-ETL to OpenSearch integration and Amazon Bedrock LADV: Advanced Design Patterns for Amazon DynamoDB LCDC: Change Data Capture for Amazon DynamoDB LMR: Build and Deploy a Global Serverless Application with Amazon DynamoDB LGME: Modeling Game Player Data with Amazon DynamoDB LDC: Design Challenges Contributors to the Immersion Day "
},
{
	"uri": "//localhost:1313/vi/8-ldc/8.1/8.1.1/",
	"title": "Tài liệu tham khảo Retail Cart",
	"tags": [],
	"description": "",
	"content": "Cách giải quyết thách thức này Các mẫu truy cập (access patterns) Các mẫu truy cập trong tình huống này bao gồm:\nChèn và cập nhật các mặt hàng được người dùng đặt trong giỏ hàng. Trả về các mặt hàng liên quan đến người dùng (AccountID), được sắp xếp theo CreateTimestamp và trong phạm vi một Status cụ thể. Trả về các mặt hàng trên nhiều người dùng theo ItemSKU, được sắp xếp theo CreateTimestamp và trong phạm vi một Status cụ thể. Truy vấn ngoại tuyến không theo thời gian thực cho đội ngũ Business Intelligence. Xác định khóa phân vùng khả thi để đáp ứng mẫu truy cập chính: Thuộc tính nào của mặt hàng tăng lên cùng với khối lượng truy cập cao hơn?\nThuộc tính AccountID sẽ tỷ lệ thuận với khối lượng truy cập, vì nhiều người dùng khác nhau sẽ có các hành vi đặt hàng riêng biệt. Tổ chức tự nhiên cho các mục dữ liệu liên quan (để trả về các mục dữ liệu liên quan đến các mẫu truy cập)?\nAccountID có thể là khóa phân vùng tốt cho các mẫu truy cập liên quan đến người dùng. Mỗi tài khoản sẽ chứa các mặt hàng mà người dùng đã đặt trong giỏ hàng. Xem xét các chiều của truy cập: cả truy cập đọc và ghi:\nGhi (write): Mỗi khi người dùng thêm hoặc cập nhật mặt hàng trong giỏ hàng, dữ liệu sẽ cần được ghi lại cho mỗi AccountID. Đọc (read): Người dùng có thể yêu cầu xem các mặt hàng đã thêm vào giỏ hàng theo AccountID và có thể cần truy vấn dựa trên CreateTimestamp và Status. Tổ chức các mục dữ liệu liên quan đến mẫu truy cập chính: Làm thế nào để sắp xếp các mục dữ liệu để trả về theo thứ tự đã sắp xếp? (sort by)\nSử dụng CreateTimestamp làm khóa sắp xếp (sort key). Điều này giúp việc truy vấn các mục theo thứ tự thời gian trở nên hiệu quả hơn. Cấu trúc quan hệ từ tổng quát nhất đến cụ thể hơn:\nAccountID là khóa phân vùng chính, và CreateTimestamp là khóa sắp xếp chính. Điều này giúp truy vấn dữ liệu theo người dùng và các mục trong giỏ hàng theo thời gian. Đáp ứng các mẫu truy cập thứ hai, ba và bốn: Mẫu truy cập thứ hai (OLTP - Online Transaction Processing):\nTrả về các mặt hàng liên quan đến một AccountID cụ thể và được sắp xếp theo CreateTimestamp và Status. Điều này có thể được thực hiện dễ dàng với cấu trúc khóa phân vùng là AccountID và khóa sắp xếp là CreateTimestamp. Mẫu truy cập thứ ba (OLTP):\nTrả về các mặt hàng theo ItemSKU, sắp xếp theo CreateTimestamp và trong phạm vi Status. Để đáp ứng mẫu truy cập này, bạn có thể tạo Global Secondary Index (GSI) với ItemSKU làm khóa phân vùng và CreateTimestamp làm khóa sắp xếp. Mẫu truy cập thứ tư (OLAP - Online Analytical Processing):\nTruy vấn ngoại tuyến cho Business Intelligence có thể không cần thực hiện trực tiếp trên DynamoDB. Bạn có thể xuất dữ liệu ra Amazon S3 và sử dụng các công cụ như Amazon Athena hoặc AWS Glue để thực hiện các phân tích chuyên sâu và tạo báo cáo. Tham khảo hữu ích Best Practices for Using Sort Keys to Organize Data Working with Queries in DynamoDB Using Global Secondary Indexes in DynamoDB How to perform advanced analytics and build visualizations of your Amazon DynamoDB data by using Amazon Athena "
},
{
	"uri": "//localhost:1313/vi/8-ldc/8.2/8.2.1/",
	"title": "Tài liệu tham khảo về thanh toán ngân hàng",
	"tags": [],
	"description": "",
	"content": "Cách giải quyết thách thức này Các mẫu truy cập (access patterns) Các mẫu truy cập trong tình huống này bao gồm:\nChèn thanh toán theo lịch. Trả về các thanh toán theo lịch của người dùng trong vòng 90 ngày tới. Trả về các thanh toán theo lịch của tất cả người dùng cho một ngày cụ thể, với trạng thái (SCHEDULED hoặc PENDING). Xác định khóa phân vùng khả thi để đáp ứng mẫu truy cập chính: Thuộc tính nào của mục thanh toán (AccountID, ScheduledTime, Status, DataBlob) tỷ lệ với mẫu truy cập?\nAccountID: Có thể làm khóa phân vùng (partition key) chính cho các mẫu truy cập dựa trên người dùng, vì mỗi người dùng sẽ có các thanh toán theo lịch riêng. ScheduledTime: Có thể được dùng làm khóa sắp xếp (sort key) để truy vấn các thanh toán theo thời gian. Tổ chức tự nhiên cho các mục thanh toán liên quan (để trả về các mục dữ liệu liên quan đến các mẫu truy cập)?\nAccountID làm khóa phân vùng để liên kết các thanh toán với từng người dùng, và ScheduledTime làm khóa sắp xếp để có thể truy vấn theo thời gian cụ thể. Xem xét các chiều của truy cập: cả truy cập đọc và ghi:\nGhi (write): Mỗi khi có thanh toán mới được lên lịch, hệ thống cần ghi lại các mục thanh toán mới cho người dùng cụ thể (AccountID). Đọc (read): Người dùng cần truy vấn các thanh toán đã lên lịch trong khoảng thời gian cụ thể, ví dụ, các thanh toán trong 90 ngày tới. Tổ chức các mục thanh toán liên quan đến mẫu truy cập chính: Làm thế nào để sắp xếp các mục thanh toán để trả về theo khoảng thời gian đã định? (sort by)\nDùng ScheduledTime làm khóa sắp xếp để có thể truy vấn các thanh toán theo khoảng thời gian 90 ngày tới. Cấu trúc quan hệ từ tổng quát nhất đến cụ thể hơn:\nSử dụng AccountID làm khóa phân vùng và ScheduledTime làm khóa sắp xếp. Điều này sẽ giúp truy vấn thanh toán của một người dùng trong một khoảng thời gian cụ thể. Đáp ứng mẫu truy cập thứ ba (OLTP): Trả về thanh toán theo ngày và trạng thái cụ thể (SCHEDULED hoặc PENDING) cho tất cả người dùng. Để đáp ứng mẫu truy cập này, bạn có thể sử dụng Global Secondary Index (GSI) với ScheduledTime làm khóa phân vùng và Status làm khóa sắp xếp. Điều này cho phép bạn truy vấn các thanh toán theo trạng thái và thời gian cụ thể. Tham khảo hữu ích Best Practices for Using Sort Keys to Organize Data Working with Queries Using Global Secondary Indexes in DynamoDB Write Shard a GSI for Selective Queries in DynamoDB "
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.1/2.1.1/",
	"title": "Tải xuống và xem trước code",
	"tags": [],
	"description": "",
	"content": " Bạn có thể sử dụng Cloud9 hoặc Session Manager.\nTrong bài lab này, bạn sẽ sử dụng các script Bash và Python để tương tác với các dịch vụ AWS. Chạy các lệnh sau trong terminal của bạn để tải xuống và giải nén mã của bài lab này.\ncd ~/environment curl -sL https://amazon-dynamodb-labs.com/assets/OpenSearchPipeline.zip -o OpenSearchPipeline.zip \u0026amp;\u0026amp; unzip -oq OpenSearchPipeline.zip \u0026amp;\u0026amp; rm OpenSearchPipeline.zip Bạn sẽ thấy một thư mục trong trình khám phá tệp của AWS Cloud9 có tên OpenSearchPipeline:\nThư mục OpenSearchPipeline chứa các mục ví dụ sẽ được tải vào một bảng DynamoDB, một script Bash để đơn giản hóa việc quản lý thông tin xác thực khi ký yêu cầu cho OpenSearch, và một script Python để thực hiện truy vấn đến Bedrock.\nBây giờ bạn đã sẵn sàng để bắt đầu lab. Trong module tiếp theo, bạn sẽ hoàn tất cài đặt cho từng dịch vụ trong số ba dịch vụ được sử dụng trong bài lab này trước khi tiến hành tích hợp chúng.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.2/4.2.1/",
	"title": "Tạo bảng DynamoDB",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tạo các bảng DynamoDB mà bạn sẽ sử dụng trong các bài lab cho buổi workshop này.\nTrong các lệnh dưới đây, lệnh AWS CLI create-table được sử dụng để tạo hai bảng mới tên là Orders và OrdersHistory.\nLệnh này sẽ tạo bảng Orders với chế độ dung lượng được cung cấp (provisioned capacity mode) có 5 đơn vị dung lượng đọc (RCU), 5 đơn vị dung lượng ghi (WCU) và một khóa phân vùng tên là id.\nNó cũng sẽ tạo bảng OrdersHistory với chế độ dung lượng được cung cấp (provisioned capacity mode) có 5 RCU, 5 WCU, một khóa phân vùng tên là pk và một khóa sắp xếp tên là sk.\nSao chép các lệnh create-table dưới đây và dán chúng vào terminal của bạn. Thực thi các lệnh để tạo hai bảng tên là Orders và OrdersHistory. aws dynamodb create-table \\ --table-name Orders \\ --attribute-definitions \\ AttributeName=id,AttributeType=S \\ --key-schema \\ AttributeName=id,KeyType=HASH \\ --provisioned-throughput \\ ReadCapacityUnits=5,WriteCapacityUnits=5 \\ --query \u0026#34;TableDescription.TableStatus\u0026#34; aws dynamodb create-table \\ --table-name OrdersHistory \\ --attribute-definitions \\ AttributeName=pk,AttributeType=S \\ AttributeName=sk,AttributeType=S \\ --key-schema \\ AttributeName=pk,KeyType=HASH \\ AttributeName=sk,KeyType=RANGE \\ --provisioned-throughput \\ ReadCapacityUnits=5,WriteCapacityUnits=5 \\ --query \u0026#34;TableDescription.TableStatus\u0026#34; Chạy lệnh dưới đây để xác nhận rằng cả hai bảng đã được tạo.\naws dynamodb wait table-exists --table-name Orders aws dynamodb wait table-exists --table-name OrdersHistory "
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.6/7.6.1/",
	"title": "Thêm chỉ mục đảo ngược",
	"tags": [],
	"description": "",
	"content": "Trong bước này, bạn thêm một chỉ mục đảo ngược vào bảng. Chỉ số đảo ngược được tạo giống như bất kỳ chỉ số phụ toàn cầu (GSI) nào khác.\nTrong mã bạn đã tải xuống, một tập lệnh add_inverted_index.py nằm trong thư mục scripts/. Tập lệnh Python này thêm một chỉ mục đảo ngược vào bảng của bạn.\nimport boto3 dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) try: dynamodb.update_table( TableName=\u0026#39;battle-royale\u0026#39;, AttributeDefinitions=[ { \u0026#34;AttributeName\u0026#34;: \u0026#34;PK\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;SK\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; } ], GlobalSecondaryIndexUpdates=[ { \u0026#34;Create\u0026#34;: { \u0026#34;IndexName\u0026#34;: \u0026#34;InvertedIndex\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;SK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;PK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], \u0026#34;Projection\u0026#34;: { \u0026#34;ProjectionType\u0026#34;: \u0026#34;ALL\u0026#34; }, \u0026#34;ProvisionedThroughput\u0026#34;: { \u0026#34;ReadCapacityUnits\u0026#34;: 1, \u0026#34;WriteCapacityUnits\u0026#34;: 1 } } } ], ) print(\u0026#34;Table \u0026#39;battle-royale\u0026#39; updated successfully.\u0026#34;) except Exception as e: print(\u0026#34;Could not update table. Error:\u0026#34;) print(e) Chỉnh sửa tập lệnh / add_inverted_index.py, đặt cả hai và thành 100 cho .ReadCapacityUnits``WriteCapacityUnits``InvertedIndex\nTrong tập lệnh này, bạn gọi một phương thức trên máy khách DynamoDB. Trong phương pháp này, bạn chuyển thông tin chi tiết về chỉ mục phụ mà bạn muốn tạo, bao gồm lược đồ khóa cho chỉ mục, thông lượng được cung cấp và các thuộc tính để chiếu vào chỉ mục.update_table()\nBạn có thể chọn chạy tập lệnh python hoặc lệnh AWS CLI bên dưới. Cả hai đều được cung cấp để hiển thị các phương pháp tương tác khác nhau với DynamoDB.add_inverted_index.py\nChạy tập lệnh bằng cách nhập lệnh sau vào thiết bị đầu cuối của bạn:\npython scripts/add_inverted_index.py Thiết bị đầu cuối của bạn sẽ hiển thị kết quả cho thấy chỉ mục của bạn đã được tạo thành công.\nTable \u0026#39;battle-royale\u0026#39; updated successfully. Ngoài ra, bạn có thể tạo GSI bằng cách chạy lệnh AWS CLI bên dưới:InvertedIndex\naws dynamodb update-table \\ --table-name battle-royale \\ --attribute-definitions AttributeName=PK,AttributeType=S AttributeName=SK,AttributeType=S \\ --global-secondary-index-updates \\ \u0026#34;[ { \\\u0026#34;Create\\\u0026#34;: { \\\u0026#34;IndexName\\\u0026#34;: \\\u0026#34;InvertedIndex\\\u0026#34;, \\\u0026#34;KeySchema\\\u0026#34;: [ { \\\u0026#34;AttributeName\\\u0026#34;: \\\u0026#34;SK\\\u0026#34;, \\\u0026#34;KeyType\\\u0026#34;: \\\u0026#34;HASH\\\u0026#34; }, { \\\u0026#34;AttributeName\\\u0026#34;: \\\u0026#34;PK\\\u0026#34;, \\\u0026#34;KeyType\\\u0026#34;: \\\u0026#34;RANGE\\\u0026#34; } ], \\\u0026#34;Projection\\\u0026#34;: { \\\u0026#34;ProjectionType\\\u0026#34;: \\\u0026#34;ALL\\\u0026#34; }, \\\u0026#34;ProvisionedThroughput\\\u0026#34;: { \\\u0026#34;ReadCapacityUnits\\\u0026#34;: 100, \\\u0026#34;WriteCapacityUnits\\\u0026#34;: 100 } } } ]\u0026#34; Nếu bạn chọn chạy lệnh AWS CLI, đầu ra sẽ chứa mô tả đầy đủ về bảng bao gồm các chỉ mục hiện có và mới tạo. Bạn sẽ nhận thấy IndexStatus cho chỉ mục sẽ hiển thị dưới dạng CREATING.battle-royale``InvertedIndex\nSẽ mất vài phút để chỉ số phụ mới được điền vào. Bạn cần đợi cho đến khi chỉ mục phụ hoạt động.\nBạn có thể tìm hiểu trạng thái hiện tại của bảng và các chỉ mục của nó bằng một trong hai cách:\nKiểm tra trong Dịch vụ, Cơ sở dữ liệu, DynamoDB trong bảng điều khiển AWS.\nChạy lệnh bên dưới trong Thiết bị đầu cuối Cloud9:\naws dynamodb describe-table --table-name battle-royale --query \u0026#34;Table.GlobalSecondaryIndexes[].IndexStatus\u0026#34; Bạn cũng có thể viết kịch bản lệnh để chạy cứ sau 5 giây bằng cách sử dụng .watch\n# Watch checks every 5 seconds by default watch -n 5 \u0026#34;aws dynamodb describe-table --table-name battle-royale --query \\\u0026#34;Table.GlobalSecondaryIndexes[].IndexStatus\\\u0026#34;\u0026#34; Nhấn Ctrl + C để kết thúc sau khi chỉ mục phụ toàn cục đã được tạo.watch\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.5/7.5.1/",
	"title": "Thêm người dùng vào trò chơi",
	"tags": [],
	"description": "",
	"content": "Mẫu truy cập đầu tiên mà bạn giải quyết trong module này là thêm người dùng mới vào một game.\nKhi thêm một người dùng mới vào game, bạn cần:\nXác nhận rằng hiện chưa có 50 người chơi trong game (mỗi game có tối đa 50 người chơi). Xác nhận rằng người dùng này chưa tham gia game. Tạo một thực thể UserGameMapping mới để thêm người dùng vào game. Tăng thuộc tính people trên thực thể Game để theo dõi số lượng người chơi trong game. Lưu ý rằng để thực hiện tất cả những điều này, bạn cần các hành động ghi trên thực thể Game hiện có và thực thể UserGameMapping mới, cũng như logic điều kiện cho từng thực thể. Đây là loại thao tác hoàn hảo để sử dụng giao dịch DynamoDB vì bạn cần thao tác trên nhiều thực thể trong cùng một yêu cầu và bạn muốn toàn bộ yêu cầu thành công hoặc thất bại cùng nhau.\nTrong mã bạn đã tải xuống, tệp script join_game.py nằm trong thư mục scripts/. Hàm trong tệp này sử dụng giao dịch DynamoDB để thêm người dùng vào game.\nimport boto3 dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) GAME_ID = \u0026#34;c6f38a6a-d1c5-4bdf-8468-24692ccc4646\u0026#34; USERNAME = \u0026#39;vlopez\u0026#39; def join_game_for_user(game_id, username): try: resp = dynamodb.transact_write_items( TransactItems=[ { \u0026#34;Put\u0026#34;: { \u0026#34;TableName\u0026#34;: \u0026#34;battle-royale\u0026#34;, \u0026#34;Item\u0026#34;: { \u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: f\u0026#34;GAME#{game_id}\u0026#34; }, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: f\u0026#34;USER#{username}\u0026#34; }, \u0026#34;game_id\u0026#34;: {\u0026#34;S\u0026#34;: game_id }, \u0026#34;username\u0026#34;: {\u0026#34;S\u0026#34;: username } }, \u0026#34;ConditionExpression\u0026#34;: \u0026#34;attribute_not_exists(SK)\u0026#34;, \u0026#34;ReturnValuesOnConditionCheckFailure\u0026#34;: \u0026#34;ALL_OLD\u0026#34; }, }, { \u0026#34;Update\u0026#34;: { \u0026#34;TableName\u0026#34;: \u0026#34;battle-royale\u0026#34;, \u0026#34;Key\u0026#34;: { \u0026#34;PK\u0026#34;: { \u0026#34;S\u0026#34;: f\u0026#34;GAME#{game_id}\u0026#34; }, \u0026#34;SK\u0026#34;: { \u0026#34;S\u0026#34;: f\u0026#34;#METADATA#{game_id}\u0026#34; }, }, \u0026#34;UpdateExpression\u0026#34;: \u0026#34;SET people = people + :p\u0026#34;, \u0026#34;ConditionExpression\u0026#34;: \u0026#34;people \u0026lt; :limit\u0026#34;, \u0026#34;ExpressionAttributeValues\u0026#34;: { \u0026#34;:p\u0026#34;: { \u0026#34;N\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;:limit\u0026#34;: { \u0026#34;N\u0026#34;: \u0026#34;50\u0026#34; } }, \u0026#34;ReturnValuesOnConditionCheckFailure\u0026#34;: \u0026#34;ALL_OLD\u0026#34; } } ] ) print(f\u0026#34;Đã thêm người dùng: {username} vào game: {game_id}\u0026#34;) return True except Exception as e: print(\u0026#34;Không thể thêm người dùng vào game\u0026#34;) join_game_for_user(GAME_ID, USERNAME) Trong hàm join_game_for_user của script này, phương thức transact_write_items() thực hiện một giao dịch ghi. Giao dịch này có hai thao tác.\nTrong thao tác đầu tiên của giao dịch, bạn sử dụng thao tác Put để chèn một thực thể UserGameMapping mới. Là một phần của thao tác đó, bạn chỉ định điều kiện rằng thuộc tính SK không được tồn tại cho thực thể này. Điều này đảm bảo rằng không có thực thể nào có PK và SK này đã tồn tại. Nếu đã có thực thể như vậy, nghĩa là người dùng này đã tham gia game.\nThao tác thứ hai là một thao tác Update trên thực thể Game để tăng thuộc tính people lên một. Là một phần của thao tác này, bạn thêm một kiểm tra điều kiện rằng giá trị hiện tại của people không lớn hơn 50. Ngay khi có 50 người tham gia game, game đã đầy và sẵn sàng bắt đầu.\nTrước khi thêm vlopez vào game, bạn có thể xác minh số người dùng hiện có trong game bằng cách truy vấn GSI thưa mà chúng ta đã tạo. Trong bảng điều khiển AWS DynamoDB, chọn Explore items ở bên trái và lọc bảng có tên Battle Royale. Chọn Query và sau đó chọn GSI có tên OpenGamesIndex từ danh sách thả xuống. Chỉ định Urban Underground là giá trị cho map (Partition Key) và nhấp vào nút màu cam Run. Bạn sẽ thấy một mục được trả về với giá trị 49 cho thuộc tính people.\nBạn có thể chọn chạy script Python join_game.py hoặc lệnh AWS CLI dưới đây. Cả hai đều được cung cấp để hiển thị các phương pháp khác nhau để tương tác với DynamoDB.\nChạy script này bằng lệnh sau trong terminal của bạn:\npython scripts/join_game.py Đầu ra trong terminal của bạn sẽ cho biết rằng người dùng đã được thêm vào game.\nĐã thêm người dùng: vlopez vào game: c6f38a6a-d1c5-4bdf-8468-24692ccc4646 Bạn có thể quay lại bảng điều khiển DynamoDB và nhấp vào Run một lần nữa để truy vấn GSI và bạn sẽ thấy rằng thuộc tính people bây giờ hiển thị 50.\nLưu ý rằng nếu bạn cố gắng chạy lại script, hàm sẽ thất bại. Người dùng vlopez đã được thêm vào game, vì vậy việc cố gắng thêm người dùng này một lần nữa không thỏa mãn các điều kiện bạn đã chỉ định.\nNgoài ra, bạn cũng có thể gửi giao dịch qua AWS CLI.\nChạy lệnh sau để thêm người dùng ebarton vào game sử dụng bản đồ Juicy Jungle:\naws dynamodb transact-write-items \\ --transact-items \\ \u0026#34;[ { \\\u0026#34;Put\\\u0026#34;: { \\\u0026#34;TableName\\\u0026#34;: \\\u0026#34;battle-royale\\\u0026#34;, \\\u0026#34;Item\\\u0026#34;: { \\\u0026#34;PK\\\u0026#34;: {\\\u0026#34;S\\\u0026#34;: \\\u0026#34;GAME#248dd9ef-6b17-42f0-9567-2cbd3dd63174\\\u0026#34; }, \\\u0026#34;SK\\\u0026#34;: {\\\u0026#34;S\\\u0026#34;: \\\u0026#34;USER#ebarton\\\u0026#34; }, \\\u0026#34;game_id\\\u0026#34;: {\\\u0026#34;S\\\u0026#34;: \\\u0026#34;248dd9ef-6b17-42f0-9567-2cbd3dd63174\\\u0026#34; }, \\\u0026#34;username\\\u0026#34;: {\\\u0026#34;S\\\u0026#34;: \\\u0026#34;ebarton\\\u0026#34; } }, \\\u0026#34;ConditionExpression\\\u0026#34;: \\\u0026#34;attribute_not_exists(SK)\\\u0026#34;, \\\u0026#34;ReturnValuesOnConditionCheckFailure\\\u0026#34;: \\\u0026#34;ALL_OLD\\\u0026#34; } }, { \\\u0026#34;Update\\\u0026#34;: { \\\u0026#34;TableName\\\u0026#34;: \\\u0026#34;battle-royale\\\u0026#34;, \\\u0026#34;Key\\\u0026#34;: { \\\u0026#34;PK\\\u0026#34;: { \\\u0026#34;S\\\u0026#34;: \\\u0026#34;GAME#248dd9ef-6b17-42f0-9567-2cbd3dd63174\\\u0026#34; }, \\\u0026#34;SK\\\u0026#34;: { \\\u0026#34;S\\\u0026#34;: \\\u0026#34;#METADATA#248dd9ef-6b17-42f0-9567-2cbd3dd63174\\\u0026#34; } }, \\\u0026#34;UpdateExpression\\\u0026#34;: \\\u0026#34;SET people = people + :p\\\u0026#34;, \\\u0026#34;ConditionExpression\\\u0026#34;: \\\u0026#34;people \u0026lt; :limit\\\u0026#34;, \\\u0026#34;ExpressionAttributeValues\\\u0026#34;: { \\\u0026#34;:p\\\u0026#34;: { \\\u0026#34;N\\\u0026#34;: \\\u0026#34;1\\\u0026#34; }, \\\u0026#34;:limit\\\u0026#34;: { \\\u0026#34;N\\\u0026#34;: \\\u0026#34;50\\\u0026#34; } }, \\\u0026#34;ReturnValuesOnConditionCheckFailure\\\u0026#34;: \\\u0026#34;ALL_OLD\\\u0026#34; } } ]\u0026#34; Việc thêm giao dịch DynamoDB giúp đơn giản hóa rất nhiều quy trình làm việc xung quanh các thao tác phức tạp như thế này. Nếu không có giao dịch, việc này sẽ yêu cầu nhiều lệnh API với các điều kiện phức tạp và phải hoàn tác thủ công trong trường hợp xảy ra xung đột. Bây giờ, bạn có thể triển khai các thao tác phức tạp như vậy với ít hơn 50 dòng mã.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.3/7.3.1/",
	"title": "Thiết kế khóa chính",
	"tags": [],
	"description": "",
	"content": "Hãy xem xét các thực thể khác nhau như đã đề cập trong phần giới thiệu trước. Trong ứng dụng trò chơi, bạn có các thực thể sau:\nUser (Người dùng)\nGame (Trò chơi)\nUserGameMapping (Bản đồ Người dùng - Trò chơi)\nThực thể UserGameMapping là một bản ghi cho biết một người dùng đã tham gia vào một trò chơi. Có một mối quan hệ nhiều-nhiều giữa User và Game.\nViệc có một bản đồ nhiều-nhiều thường cho thấy rằng bạn muốn thỏa mãn hai mẫu Query (truy vấn), và ứng dụng trò chơi này cũng không ngoại lệ. Bạn có một mẫu truy cập cần tìm tất cả người dùng đã tham gia vào một trò chơi, cũng như một mẫu khác để tìm tất cả các trò chơi mà một người dùng đã chơi.\nNếu mô hình dữ liệu của bạn có nhiều thực thể với mối quan hệ giữa chúng, bạn thường sử dụng khóa chính tổng hợp (composite primary key) với cả giá trị partition key và sort key. Khóa chính tổng hợp cho phép bạn sử dụng khả năng Query trên partition key để thỏa mãn một trong những mẫu truy vấn mà bạn cần. Trong tài liệu DynamoDB, partition key cũng được gọi là HASH và sort key được gọi là RANGE.\nHai thực thể dữ liệu khác — User và Game — không có thuộc tính tự nhiên cho giá trị sort key vì các mẫu truy cập trên User hoặc Game chỉ là tra cứu khóa-giá trị. Vì giá trị sort key là bắt buộc, bạn có thể cung cấp một giá trị điền vào cho sort key.\nVới ý tưởng này, hãy sử dụng mẫu sau cho các giá trị partition key và sort key cho mỗi loại thực thể.\nThực thể Partition Key Sort Key User USER# #METADATA# Game GAME#\u0026lt;GAME_ID\u0026gt; #METADATA#\u0026lt;GAME_ID\u0026gt; UserGameMapping GAME#\u0026lt;GAME_ID\u0026gt; USER# Hãy cùng đi qua bảng trên.\nĐối với thực thể User, giá trị partition key là USER#\u0026lt;USERNAME\u0026gt;. Lưu ý rằng một tiền tố được sử dụng để xác định thực thể và ngăn ngừa bất kỳ xung đột nào có thể xảy ra giữa các loại thực thể.\nĐối với giá trị sort key trên thực thể User, sử dụng một tiền tố tĩnh #METADATA# theo sau là giá trị USERNAME. Đối với giá trị sort key, điều quan trọng là bạn có một giá trị đã biết, như USERNAME. Điều này cho phép thực hiện các hành động trên một mục duy nhất như GetItem, PutItem, và DeleteItem.\nTuy nhiên, bạn cũng muốn một giá trị sort key có các giá trị khác nhau giữa các thực thể User khác nhau để cho phép phân chia đồng đều nếu bạn sử dụng thuộc tính này làm partition key cho một chỉ mục. Vì lý do này, bạn nối thêm USERNAME.\nThực thể Game có thiết kế khóa chính tương tự như thiết kế của thực thể User. Nó sử dụng một tiền tố khác (GAME#) và GAME_ID thay vì USERNAME, nhưng nguyên tắc vẫn giống nhau.\nCuối cùng, UserGameMapping sử dụng cùng partition key như thực thể Game. Điều này cho phép bạn truy xuất không chỉ siêu dữ liệu cho một Game mà còn tất cả người dùng trong một Game trong một truy vấn duy nhất. Bạn sau đó sử dụng thực thể User cho sort key trên UserGameMapping để xác định người dùng nào đã tham gia vào một trò chơi cụ thể.\nTrong bước tiếp theo, bạn sẽ tạo một bảng với thiết kế khóa chính này.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.4/1.4.1/",
	"title": "Tóm tắt về AWS Backup",
	"tags": [],
	"description": "",
	"content": "AWS Backup được thiết kế để giúp bạn tập trung hóa và tự động hóa việc bảo vệ dữ liệu trên các dịch vụ AWS. AWS Backup cung cấp một dịch vụ dựa trên chính sách, được quản lý hoàn toàn và có chi phí hợp lý, giúp đơn giản hóa hơn nữa việc bảo vệ dữ liệu ở quy mô lớn. AWS Backup cho phép bạn triển khai các chính sách sao lưu từ trung tâm để cấu hình, quản lý và kiểm soát hoạt động sao lưu trên các tài khoản AWS và tài nguyên trong tổ chức của bạn, bao gồm các phiên bản Amazon EC2, các ổ đĩa Amazon EBS, các cơ sở dữ liệu Amazon RDS, các bảng Amazon DynamoDB, Amazon EFS, Amazon FSx for Lustre, Amazon FSx for Windows File Server, và các ổ đĩa AWS Storage Gateway.\nHãy hiểu một số thuật ngữ trong AWS Backup:\nBackup vault: một container (kho lưu trữ) mà bạn tổ chức các bản sao lưu của mình.\nBackup plan: một biểu thức chính sách xác định thời điểm và cách thức bạn muốn sao lưu các tài nguyên AWS của mình. Kế hoạch sao lưu được liên kết với một backup vault.\nResource assignment: định nghĩa những tài nguyên nào cần được sao lưu. Bạn có thể chọn tài nguyên theo thẻ (tags) hoặc theo ARN của tài nguyên.\nRecovery point: một snapshot/bản sao lưu của một tài nguyên được sao lưu bởi AWS Backup. Mỗi điểm khôi phục có thể được khôi phục lại với AWS Backup.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.5/1.5.1/",
	"title": "Tổng quan bài tập",
	"tags": [],
	"description": "",
	"content": "Trong module này, bạn sẽ tạo một môi trường để lưu trữ cơ sở dữ liệu MySQL trên Amazon EC2. Phiên bản này sẽ được sử dụng để lưu trữ cơ sở dữ liệu nguồn và mô phỏng phía tại chỗ (on-premise) của kiến trúc di chuyển. Tất cả các tài nguyên để cấu hình cơ sở hạ tầng nguồn được triển khai thông qua mẫu Amazon CloudFormation. Có hai mẫu CloudFormation được sử dụng trong bài tập này, mỗi mẫu sẽ triển khai các tài nguyên sau:\nTài nguyên của CloudFormation MySQL Template:\nOnPrem VPC: Nguồn VPC sẽ đại diện cho môi trường nguồn tại chỗ trong khu vực N. Virginia. VPC này sẽ lưu trữ cơ sở dữ liệu MySQL nguồn trên Amazon EC2. Amazon EC2 MySQL Database: Phiên bản Amazon EC2 với Amazon Linux 2 AMI được cài đặt và chạy MySQL. Load IMDb dataset: Mẫu sẽ tạo cơ sở dữ liệu IMDb trên MySQL và tải các tệp dữ liệu công khai IMDb vào cơ sở dữ liệu. Bạn có thể tìm hiểu thêm về bộ dữ liệu IMDb trong Explore Source Model. Tài nguyên của CloudFormation DMS Instance:\nDMS VPC: VPC di chuyển ở khu vực N. Virginia. VPC này sẽ lưu trữ phiên bản sao chép DMS. Replication Instance: Phiên bản sao chép DMS sẽ hỗ trợ quá trình di chuyển cơ sở dữ liệu từ máy chủ MySQL nguồn trên EC2 sang Amazon DynamoDB. "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.3/1.3.1/",
	"title": "Xem Table Data",
	"tags": [],
	"description": "",
	"content": "Đầu tiên, hãy truy cập vào DynamoDB Console và nhấp vào Tables từ menu bên trái.\nTiếp theo, chọn bảng ProductCatalog và nhấp vào Explore table items ở góc trên bên phải để xem các mục.\nChúng ta có thể thấy trực quan rằng bảng này có Khóa Phân Vùng là Id (thuộc loại Number), không có khóa sắp xếp, và có 8 mục trong bảng. Một số mục là Sách (Books) và một số mục là Xe đạp (Bicycles), và một số thuộc tính như Id, Price, ProductCategory, và Title tồn tại trong mọi Mục, trong khi các thuộc tính đặc trưng cho từng danh mục như Authors hoặc Colors chỉ tồn tại trên một số mục.\nNhấp vào thuộc tính Id có giá trị 101 để mở trình chỉnh sửa mục cho Mục đó. Chúng ta có thể xem và chỉnh sửa tất cả các thuộc tính cho mục này trực tiếp từ giao diện điều khiển. Hãy thử thay đổi Title thành \u0026ldquo;Book 101 Title New and Improved\u0026rdquo;. Nhấp vào Add new attribute (Thêm thuộc tính mới) và đặt tên là Reviewers thuộc loại String set, sau đó nhấp vào Insert a field hai lần để thêm vài mục vào tập hợp đó. Khi bạn hoàn thành, nhấp vào Save changes (Lưu thay đổi).\nBạn cũng có thể sử dụng trình chỉnh sửa mục trong định dạng JSON của DynamoDB (thay vì trình chỉnh sửa dạng Form mặc định) bằng cách nhấp vào JSON ở góc trên bên phải. Định dạng này sẽ trông quen thuộc nếu bạn đã thực hiện phần Khám phá DynamoDB CLI của bài thực hành. Định dạng JSON của DynamoDB được mô tả trong phần API Cấp thấp của DynamoDB trong Hướng dẫn Dành cho Nhà Phát triển.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.2/",
	"title": "Bài tập 1: DynamoDB Capacity Units và Partitioning",
	"tags": [],
	"description": "",
	"content": "Trong bài tập này, bạn sẽ tải dữ liệu vào các bảng DynamoDB được cấp phát với các đơn vị dung lượng đọc/ghi khác nhau, và so sánh thời gian tải cho các bộ dữ liệu khác nhau. Đầu tiên, bạn sẽ tải một bộ dữ liệu nhỏ hơn vào một bảng và ghi lại thời gian thực thi nhanh. Tiếp theo, bạn sẽ tải một bộ dữ liệu lớn hơn vào một bảng bị cấp phát dưới mức để mô phỏng các ngoại lệ do bị giới hạn (throttling). Cuối cùng, bạn sẽ mô phỏng áp lực từ chỉ mục phụ toàn cầu (global secondary index) trên một bảng bằng cách tạo một bảng có dung lượng cấp phát cao hơn và một chỉ mục phụ toàn cầu chỉ có 1 đơn vị dung lượng ghi (WCU). Trong bài tập này, bạn sẽ sử dụng dữ liệu mẫu từ nhật ký truy cập máy chủ web, tương tự như dữ liệu nhật ký máy chủ web được tạo bởi Apache.\n"
},
{
	"uri": "//localhost:1313/vi/8-ldc/8.2/",
	"title": "Bank Payments Scenario",
	"tags": [],
	"description": "",
	"content": "Một ngân hàng đã yêu cầu bạn phát triển một hệ thống backend mới để xử lý các khoản thanh toán đã được lên lịch. Đây chủ yếu là một khối lượng công việc OLTP với các quy trình xử lý hàng loạt hàng ngày. Các mục trong bảng biểu thị các khoản thanh toán được lên lịch giữa các tài khoản. Khi các mục được chèn, chúng được lên lịch vào một ngày cụ thể để xử lý thanh toán. Mỗi ngày, các mục được gửi thường xuyên đến hệ thống giao dịch để xử lý, và trạng thái của chúng sẽ thay đổi thành PENDING. Khi giao dịch thành công, trạng thái của mục được đặt thành PROCESSED và được cập nhật với một mã giao dịch mới.\nKích thước khối lượng công việc: Các tài khoản có thể có nhiều khoản thanh toán được lên lịch cho bất kỳ ngày nào trong tương lai. Các khoản thanh toán có các trường dữ liệu sau: AccountID, ScheduledTime, Status (SCHEDULED, PENDING, hoặc PROCESSED), DataBlob (kích thước mục \u0026lt;= 8 KB). Mỗi ngày, vào lúc 1:00 sáng, có một triệu khoản thanh toán tự động được thêm vào cho ngày đó, và cần hoàn thành trong 30 phút. Mỗi ngày có thêm một triệu khoản thanh toán với trạng thái SCHEDULED, chủ yếu trong khoảng thời gian từ 6:00 sáng đến 6:00 chiều. Trong suốt cả ngày, một công việc hàng loạt sẽ chạy thường xuyên để truy vấn các khoản thanh toán SCHEDULED của ngày hôm nay. Dịch vụ này sẽ gửi các mục SCHEDULED đến hệ thống giao dịch. Khi các mục được gửi đến hệ thống giao dịch, trạng thái thanh toán sẽ được thay đổi thành PENDING. Khi hệ thống giao dịch hoàn tất, trạng thái của mục được thay đổi thành PROCESSED và một mã giao dịch mới sẽ được thêm vào mục. Các mục cần được trả về cho một tài khoản cụ thể mà đã được lên lịch thanh toán trong 90 ngày tới. Hệ thống giao dịch phải truy xuất tất cả các mục cho một ngày cụ thể (ví dụ, hôm nay) trên tất cả các tài khoản. Nó phải có khả năng truy xuất các mục có trạng thái cụ thể là SCHEDULED hoặc PENDING. Thử thách của bạn: Phát triển một mô hình dữ liệu NoSQL cho ngân hàng để đáp ứng các yêu cầu về thanh toán đã được lên lịch. Thử thách bổ sung: Vào cuối mỗi ngày, tất cả các mục đã có trạng thái PROCESSED cần được chuyển sang một bảng lưu trữ lâu dài (do yêu cầu tuân thủ, dữ liệu cần phải nằm trong một bảng riêng biệt). Hãy thiết kế một mô hình dữ liệu thứ hai đáp ứng cùng các yêu cầu truy cập như trên, và thêm một yêu cầu khác là trả về một mục cụ thể liên quan đến mã giao dịch. "
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.5/7.5.2/",
	"title": "Bắt đầu trò chơi",
	"tags": [],
	"description": "",
	"content": "Ngay khi một game có 50 người chơi, người tạo game có thể bắt đầu game để khởi động quá trình chơi. Trong bước này, bạn sẽ học cách xử lý mẫu truy cập này.\nKhi hệ thống backend của ứng dụng nhận được yêu cầu bắt đầu game, bạn cần kiểm tra ba điều:\nGame đã có 50 người đăng ký. Người dùng yêu cầu bắt đầu game là người tạo ra game. Game chưa được bắt đầu. Bạn có thể xử lý mỗi kiểm tra này bằng một điều kiện biểu thức trong yêu cầu cập nhật game. Nếu tất cả các điều kiện này được thỏa mãn, bạn cần cập nhật thực thể theo các cách sau:\nXóa thuộc tính open_timestamp để nó không còn xuất hiện dưới dạng game mở trong GSI thưa (sparse GSI) mà bạn đã tạo trước đó. Thêm thuộc tính start_time để chỉ ra thời điểm game bắt đầu. Trong mã bạn đã tải xuống, tệp script start_game.py nằm trong thư mục scripts/.\nimport datetime import boto3 from entities import Game dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) GAME_ID = \u0026#34;c6f38a6a-d1c5-4bdf-8468-24692ccc4646\u0026#34; CREATOR = \u0026#34;gstanley\u0026#34; def start_game(game_id, requesting_user, start_time): try: resp = dynamodb.update_item( TableName=\u0026#39;battle-royale\u0026#39;, Key={ \u0026#34;PK\u0026#34;: { \u0026#34;S\u0026#34;: f\u0026#34;GAME#{game_id}\u0026#34; }, \u0026#34;SK\u0026#34;: { \u0026#34;S\u0026#34;: f\u0026#34;#METADATA#{game_id}\u0026#34; } }, UpdateExpression=\u0026#34;REMOVE open_timestamp SET start_time = :time\u0026#34;, ConditionExpression=\u0026#34;people = :limit AND creator = :requesting_user AND attribute_not_exists(start_time)\u0026#34;, ExpressionAttributeValues={ \u0026#34;:time\u0026#34;: { \u0026#34;S\u0026#34;: start_time.isoformat() }, \u0026#34;:limit\u0026#34;: { \u0026#34;N\u0026#34;: \u0026#34;50\u0026#34; }, \u0026#34;:requesting_user\u0026#34;: { \u0026#34;S\u0026#34;: requesting_user } }, ReturnValues=\u0026#34;ALL_NEW\u0026#34; ) return Game(resp[\u0026#39;Attributes\u0026#39;]) except Exception as e: print(\u0026#39;Không thể bắt đầu game\u0026#39;) return False game = start_game(GAME_ID, CREATOR, datetime.datetime(2019, 4, 16, 10, 15, 35)) if game: print(f\u0026#34;Đã bắt đầu game: {game}\u0026#34;) Trong script này, hàm start_game tương tự như một hàm bạn sẽ có trong ứng dụng của mình. Nó nhận game_id, requesting_user, và start_time, và thực hiện một yêu cầu để cập nhật thực thể Game để bắt đầu game.\nTham số ConditionExpression trong cuộc gọi update_item() chỉ định các kiểm tra như đã liệt kê trước đó trong bước này — game phải có 50 người, người yêu cầu bắt đầu game phải là người tạo ra game, và game không thể có thuộc tính start_time, tức là game chưa bắt đầu.\nTrong tham số UpdateExpression, bạn có thể thấy các thay đổi mà bạn muốn thực hiện với thực thể. Trước tiên bạn xóa thuộc tính open_timestamp khỏi thực thể, và sau đó bạn đặt thuộc tính start_time thành thời gian bắt đầu của game.\nBạn có thể chọn chạy script Python start_game.py hoặc lệnh AWS CLI dưới đây. Cả hai đều được cung cấp để hiển thị các phương pháp khác nhau để tương tác với DynamoDB.\nChạy script này trong terminal của bạn bằng lệnh sau:\npython scripts/start_game.py Bạn sẽ thấy đầu ra trong terminal của mình cho biết rằng game đã bắt đầu thành công.\nĐã bắt đầu game: Game: c6f38a6a-d1c5-4bdf-8468-24692ccc4646 Map: Urban Underground Thử chạy script một lần nữa trong terminal của bạn. Lần này, bạn sẽ thấy thông báo lỗi chỉ ra rằng bạn không thể bắt đầu game. Điều này là do bạn đã bắt đầu game rồi, vì vậy thuộc tính start_time đã tồn tại. Kết quả là, yêu cầu đã không vượt qua kiểm tra điều kiện trên thực thể.\nNgoài ra, bạn có thể chạy lệnh AWS CLI sau để bắt đầu game:\naws dynamodb update-item \\ --table-name battle-royale \\ --key \\ \u0026#34;{ \\\u0026#34;PK\\\u0026#34;: { \\\u0026#34;S\\\u0026#34;: \\\u0026#34;GAME#c6f38a6a-d1c5-4bdf-8468-24692ccc4646\\\u0026#34; }, \\\u0026#34;SK\\\u0026#34;: { \\\u0026#34;S\\\u0026#34;: \\\u0026#34;#METADATA#c6f38a6a-d1c5-4bdf-8468-24692ccc4646\\\u0026#34; } }\u0026#34; \\ --update-expression \u0026#34;REMOVE open_timestamp SET start_time = :time\u0026#34; \\ --condition-expression \\ \u0026#34;people = :limit AND creator = :requesting_user AND attribute_not_exists(start_time)\u0026#34; \\ --expression-attribute-values \\ \u0026#34;{ \\\u0026#34;:time\\\u0026#34;: { \\\u0026#34;S\\\u0026#34;: \\\u0026#34;2019-04-16T10:15:35\\\u0026#34; }, \\\u0026#34;:limit\\\u0026#34;: { \\\u0026#34;N\\\u0026#34;: \\\u0026#34;50\\\u0026#34; }, \\\u0026#34;:requesting_user\\\u0026#34;: { \\\u0026#34;S\\\u0026#34;: \\\u0026#34;gstanley\\\u0026#34; } }\u0026#34; \\ --return-values \u0026#34;ALL_NEW\u0026#34; Nếu bạn chạy lệnh AWS CLI, bạn sẽ thấy các giá trị mới của mục mà bạn đã cập nhật và bạn sẽ nhận thấy rằng không còn thuộc tính open_timestamp, nhưng có một thuộc tính tên là start_time.\n{ \u0026#34;Attributes\u0026#34;: { \u0026#34;creator\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;gstanley\u0026#34; }, \u0026#34;people\u0026#34;: { \u0026#34;N\u0026#34;: \u0026#34;50\u0026#34; }, \u0026#34;SK\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;#METADATA#c6f38a6a-d1c5-4bdf-8468-24692ccc4646\u0026#34; }, \u0026#34;create_time\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2019-04-16T10:12:54\u0026#34; }, \u0026#34;map\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Urban Underground\u0026#34; }, \u0026#34;start_time\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2019-04-16T10:15:35\u0026#34; }, \u0026#34;PK\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;GAME#c6f38a6a-d1c5-4bdf-8468-24692ccc4646\u0026#34; }, \u0026#34;game_id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;c6f38a6a-d1c5-4bdf-8468-24692ccc4646\u0026#34; } } } Tóm tắt Trong module này, bạn đã thấy cách thỏa mãn hai thao tác ghi nâng cao trong ứng dụng. Đầu tiên, bạn sử dụng giao dịch DynamoDB khi một người dùng tham gia game. Với giao dịch, bạn đã xử lý một thao tác ghi điều kiện phức tạp trên nhiều thực thể trong một yêu cầu duy nhất.\nThứ hai, bạn đã triển khai chức năng cho người tạo game để bắt đầu game khi nó đã sẵn sàng. Trong mẫu truy cập này, bạn đã thực hiện thao tác cập nhật yêu cầu kiểm tra giá trị của ba thuộc tính và cập nhật hai thuộc tính. Bạn có thể diễn đạt logic phức tạp này trong một yêu cầu duy nhất thông qua sức mạnh của các điều kiện và biểu thức cập nhật.\nTrong module tiếp theo, bạn sẽ xem xét mẫu truy cập cuối cùng, liên quan đến việc xem các game đã diễn ra trong ứng dụng.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.1/3.1.2/",
	"title": "Bước 1 - Mở AWS Manager Console",
	"tags": [],
	"description": "",
	"content": " Sau khi bạn đã truy cập vào AWS Management Console cho bài lab, hãy kiểm tra lại xem vùng (region) có đúng không và tên vai trò WSParticipantRole xuất hiện ở góc trên bên phải của console.\nTrong thanh tìm kiếm dịch vụ, tìm Systems Manager và nhấp vào đó để mở phần AWS Systems Manager của AWS Management Console.\nTrong bảng điều khiển AWS Systems Manager, tìm menu ở bên trái, xác định phần Node Management và chọn Session Manager từ danh sách.\nChọn Start session để khởi chạy một phiên shell.\nNhấp vào nút radio để chọn phiên bản EC2 cho bài lab. Nếu bạn không thấy phiên bản nào, chờ vài phút và sau đó nhấn làm mới. Chờ cho đến khi có một phiên bản EC2 với tên DynamoDBC9 khả dụng trước khi tiếp tục. Chọn phiên bản đó.\nNhấp vào nút Start Session (Thao tác này sẽ mở một tab mới trong trình duyệt của bạn với một shell đen mới).\nTrong shell đen mới, chuyển sang tài khoản ubuntu bằng cách chạy sudo su - ubuntu\nsudo su - ubuntu Chạy lệnh shopt login_shell và đảm bảo nó hiển thị login_shell on, sau đó chuyển vào thư mục workshop.\n# Xác minh login_shell là \u0026#39;on\u0026#39; shopt login_shell # Chuyển vào thư mục workshop cd ~/workshop/ Đầu ra của các lệnh trong phiên Session Manager sẽ trông như sau:\n$ sudo su - ubuntu :~ $ # Xác minh login_shell là \u0026#39;on\u0026#39; shopt login_shell # Chuyển vào thư mục workshop cd ~/workshop/ login_shell on :~/workshop $ "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.6/3.6.2/",
	"title": "Bước 2 - Quét bảng nhân viên để tìm người quản lý mà không cần sử dụng sparse global secondary index",
	"tags": [],
	"description": "",
	"content": "Mẫu sparse index (chỉ mục thưa) giúp giảm bớt số lượng dữ liệu cần tìm kiếm, giúp cho các tìm kiếm trên chỉ mục, bằng cách sử dụng API Scan hoặc Query, trở nên hiệu quả hơn. Thay vì phải duyệt qua tất cả dữ liệu trong bảng cơ sở DynamoDB, bạn có thể tạo một sparse index để chứa một phần nhỏ thông tin của bạn nhằm dễ dàng truy vấn và tìm kiếm. Để tìm hiểu thêm về định nghĩa của một DynamoDB sparse index, vui lòng xem tài liệu về các phương pháp tốt nhất của chúng tôi.\nĐể bắt đầu, quét bảng để tìm tất cả các quản lý mà không sử dụng chỉ mục phụ toàn cầu. Thông lượng tiêu thụ sẽ cho chúng ta một cơ sở so sánh sau này trong bài tập. Trong trường hợp này, bạn cần sử dụng biểu thức lọc (filter expression) để chỉ trả về các mục mà thuộc tính is_manager bằng 1, như trong ví dụ mã sau:\nfe = \u0026#34;is_manager = :f\u0026#34; eav = {\u0026#34;:f\u0026#34;: \u0026#34;1\u0026#34;} response = table.scan( FilterExpression=fe, ExpressionAttributeValues=eav, Limit=pageSize ) Chạy script Python sau để tìm tất cả các quản lý mà không sử dụng chỉ mục phụ toàn cầu.\npython scan_for_managers.py employees 100 Tham số:\nTên bảng = employees Kích thước trang = 100 (đây là kích thước phân trang cho thao tác quét). Kết quả đầu ra bao gồm số lượng mục đã quét và thời gian thực thi.\nManagers count: 84. # of records scanned: 4000. Execution time: 0.596132993698 seconds Xem lại số lượng mục đã quét để trả về các giá trị. Giá trị số lượng bản ghi đã quét trong kết quả mẫu trên, 4000, phải khớp với số trong kết quả đầu ra của script của bạn. Nếu bạn nhận được lỗi hoặc sự không nhất quán, hãy đảm bảo bạn đã hoàn thành Bước 1 trong bài tập này và cả hai chỉ mục đều đang ở trạng thái ACTIVE. Hãy thử thay đổi kích thước trang thành một số lớn hơn như 1000. Thời gian thực thi sẽ giảm vì có ít chuyến đi khứ hồi hơn tới DynamoDB. Một cuộc gọi API Scan có thể trả về tối đa 1MB dữ liệu mỗi lần.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.5/3.5.2/",
	"title": "Bước 2 - Tải dữ liệu vào bảng mới",
	"tags": [],
	"description": "",
	"content": "Bây giờ, hãy thực thi một script để nạp dữ liệu từ tệp có tên ./employees.csv vào bảng có tên employees.\npython load_employees.py employees ./data/employees.csv Bản ghi mẫu trong tệp employees.csv trông như sau:\n1000,Nanine Denacamp,Programmer Analyst,Development,San Francisco,CA,1981-09-30,2014-06-01,Senior Database Administrator,2014-01-25 Khi bạn nạp dữ liệu này vào bảng, bạn sẽ nối một số thuộc tính, chẳng hạn như city_dept (ví dụ: San Francisco:Development) vì bạn có một mẫu truy cập trong truy vấn tận dụng thuộc tính đã nối này. Thuộc tính SK cũng là một thuộc tính được tạo ra. Việc nối các thuộc tính này được xử lý trong script Python, script này sẽ lắp ráp bản ghi và sau đó thực thi một lệnh put_item() để ghi bản ghi vào bảng.\nKết quả đầu ra:\n$ python load_employees.py employees ./data/employees.csv employee count: 100 in 3.7393667697906494 employee count: 200 in 3.7162938117980957 ... employee count: 900 in 3.6725080013275146 employee count: 1000 in 3.6174678802490234 RowCount: 1000, Total seconds: 36.70457601547241 Kết quả đầu ra xác nhận rằng 1000 mục đã được chèn vào bảng.\nXem lại bảng employees trong bảng điều khiển DynamoDB (như hiển thị trong ảnh chụp màn hình sau) bằng cách chọn bảng employees và sau đó chọn mục menu Items.\nTrên cùng trang đó, ở ngăn bên phải, chọn [Index] từ menu thả xuống và sau đó nhấp vào Run.\nBây giờ bạn có thể thấy kết quả của thao tác \u0026ldquo;Scan\u0026rdquo; trên một chỉ mục phụ toàn cầu được nạp chồng. Có nhiều loại thực thể khác nhau trong tập kết quả: một mục gốc, một chức danh trước đây, và một chức danh hiện tại. "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.2/3.2.2/",
	"title": "Bước 2 - Tải mẫu data vào bảng",
	"tags": [],
	"description": "",
	"content": "Bây giờ bạn đã tạo bảng, bạn có thể tải một số dữ liệu mẫu vào bảng bằng cách chạy tập lệnh Python sau.\ncd /home/ubuntu/workshop python load_logfile.py logfile ./data/logfile_small1.csv Các tham số trong lệnh trước: 1) Tên bảng = 2) Tên tệp = logfile``logfile_small1.csv\nĐầu ra sẽ giống như sau.\nrow: 100 in 0.780548095703125 row: 200 in 7.2669219970703125 row: 300 in 1.547729730606079 row: 400 in 3.9651060104370117 row: 500 in 3.98996901512146 RowCount: 500, Total seconds: 17.614499807357788 Curious behavior: Bạn có thể tự hỏi tại sao một trong những lần chạy mất hơn năm giây. Xem bước tiếp theo để biết giải thích.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.3/3.3.2/",
	"title": "Bước 2 - Thực hiện Quét song song",
	"tags": [],
	"description": "",
	"content": "Để thực hiện một thao tác Scan song song, mỗi worker ứng dụng gửi yêu cầu Scan của riêng mình với các tham số sau:\nSegment: Đoạn sẽ được quét bởi một worker ứng dụng cụ thể. Mỗi worker nên sử dụng một giá trị khác nhau cho Segment. TotalSegments: Tổng số đoạn cho quá trình quét song song. Giá trị này phải giống với số worker mà ứng dụng của bạn sẽ sử dụng. Hãy xem qua khối mã sau đây cho việc quét song song, từ tệp scan_logfile_parallel.py.\nfe = \u0026#34;responsecode \u0026lt;\u0026gt; :f\u0026#34; eav = {\u0026#34;:f\u0026#34;: 200} response = table.scan( FilterExpression=fe, ExpressionAttributeValues=eav, Limit=pageSize, TotalSegments=totalsegments, Segment=threadsegment, ProjectionExpression=\u0026#39;bytessent\u0026#39; ) Sau lần quét đầu tiên, bạn có thể tiếp tục quét bảng cho đến khi LastEvaluatedKey bằng null.\nwhile \u0026#39;LastEvaluatedKey\u0026#39; in response: response = table.scan( FilterExpression=fe, ExpressionAttributeValues=eav, Limit=pageSize, TotalSegments=totalsegments, Segment=threadsegment, ExclusiveStartKey=response[\u0026#39;LastEvaluatedKey\u0026#39;], ProjectionExpression=\u0026#39;bytessent\u0026#39;) for i in response[\u0026#39;Items\u0026#39;]: totalbytessent += i[\u0026#39;bytessent\u0026#39;] Để chạy đoạn mã này, thực thi lệnh AWS CLI sau:\npython scan_logfile_parallel.py logfile_scan 2 Tham số:\nTên bảng: logfile_scan Số luồng: 2 (đây là số luồng sẽ được thực thi song song và cũng sẽ được sử dụng cho số đoạn). Kết quả đầu ra sẽ trông như sau:\nScanning 1 million rows of the `logfile_scan` table to get the total of bytes sent Total bytessent 6054250 in 8.544446229934692 seconds Thời gian thực thi khi sử dụng quét song song sẽ ngắn hơn so với thời gian thực thi cho quét tuần tự. Sự khác biệt về thời gian thực thi sẽ càng lớn hơn đối với các bảng lớn.\nTóm tắt Trong bài tập này, chúng ta đã minh họa việc sử dụng hai phương pháp quét bảng DynamoDB: tuần tự và song song, để đọc các mục từ một bảng hoặc chỉ mục phụ. Sử dụng Scan một cách cẩn trọng vì nó có thể tiêu thụ một lượng lớn tài nguyên dung lượng. Đôi khi Scan là phù hợp (như khi quét một bảng nhỏ) hoặc không thể tránh khỏi (như khi thực hiện xuất dữ liệu hàng loạt). Tuy nhiên, theo nguyên tắc chung, bạn nên thiết kế ứng dụng của mình để tránh thực hiện quét.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.4/3.4.2/",
	"title": "Bước 2 - Truy vấn GSI bằng các phân đoạn",
	"tags": [],
	"description": "",
	"content": "Để lấy tất cả các bản ghi nhật ký có mã phản hồi 404, bạn cần truy vấn tất cả các phân vùng của chỉ mục phụ toàn cầu bằng cách sử dụng khóa sắp xếp. Bạn có thể làm điều này bằng cách sử dụng các luồng song song trong ứng dụng của mình và sử dụng khóa phân vùng và khóa sắp xếp.\nif date:= \u0026#34;all\u0026#34;: ke = Key(\u0026#39;GSI_1_PK\u0026#39;).eq(\u0026#34;shard#{}\u0026#34;.format(shardid)) \u0026amp; Key(\u0026#39;GSI_1_SK\u0026#39;).begins_with(responsecode) else: ke = Key(\u0026#39;GSI_1_PK\u0026#39;).eq(\u0026#34;shard#{}\u0026#34;.format(shardid)) \u0026amp; Key(\u0026#39;GSI_1_SK\u0026#39;).begins_with(responsecode+\u0026#34;#\u0026#34;+date) response = table.query( IndexName=\u0026#39;GSI_1\u0026#39;, KeyConditionExpression=ke ) Chạy script sau để lấy các mục từ chỉ mục phụ toàn cầu phân mảnh bằng cách chỉ sử dụng khóa phân vùng và mã phản hồi.\npython query_responsecode.py logfile_scan 404 Điều này sẽ truy vấn bảng logfile_scan để lấy các mục có khóa sắp xếp bắt đầu bằng 404. begins_with là một tham số trong KeyConditionExpression của DynamoDB Query như được mô tả trong tài liệu của chúng tôi. Một truy vấn được chạy cho mỗi shard trên GSI và kết quả được đếm trên phía client. Kết quả đầu ra của script sẽ trông như sau:\nRecords with response code 404 in the shardid 0 = 0 Records with response code 404 in the shardid 1 = 1750 Records with response code 404 in the shardid 2 = 2500 Records with response code 404 in the shardid 3 = 1250 Records with response code 404 in the shardid 4 = 1000 Records with response code 404 in the shardid 5 = 1000 Records with response code 404 in the shardid 6 = 1750 Records with response code 404 in the shardid 7 = 1500 Records with response code 404 in the shardid 8 = 3250 Records with response code 404 in the shardid 9 = 2750 Number of records with responsecode 404 is 16750. Query time: 1.5092344284057617 seconds Bạn cũng có thể truy vấn cùng một chỉ mục phụ toàn cầu cho cùng mã phản hồi và chỉ định một ngày cụ thể. Điều này sẽ truy vấn bảng logfile_scan để lấy các mục có khóa sắp xếp bắt đầu bằng 404#2017-07-21.\npython query_responsecode.py logfile_scan 404 --date 2017-07-21 Kết quả đầu ra sẽ trông như sau:\nRecords with response code 404 in the shardid 0 = 0 Records with response code 404 in the shardid 1 = 750 Records with response code 404 in the shardid 2 = 750 Records with response code 404 in the shardid 3 = 250 Records with response code 404 in the shardid 4 = 500 Records with response code 404 in the shardid 5 = 0 Records with response code 404 in the shardid 6 = 250 Records with response code 404 in the shardid 7 = 1000 Records with response code 404 in the shardid 8 = 1000 Records with response code 404 in the shardid 9 = 1000 Number of records with responsecode 404 is 5500. Query time: 1.190359354019165 seconds Tóm tắt Trong bài tập này, chúng ta đã sử dụng một chỉ mục phụ toàn cầu phân mảnh (GSI) để nhanh chóng truy xuất các kết quả đã được sắp xếp, sử dụng các khóa tổng hợp sẽ được đề cập chi tiết hơn trong Bài tập 6 của phòng lab. Sử dụng phương pháp ghi phân mảnh GSI khi bạn cần một chỉ mục được sắp xếp có khả năng mở rộng.\nVí dụ về GSI phân mảnh sử dụng một phạm vi khóa từ 0 đến 9, nhưng trong ứng dụng của bạn, bạn có thể chọn bất kỳ phạm vi nào. Trong ứng dụng của bạn, bạn có thể thêm nhiều shard hơn khi số lượng mục được lập chỉ mục tăng lên. Trong mỗi shard, dữ liệu được sắp xếp trên đĩa theo khóa sắp xếp. Điều này cho phép chúng ta truy xuất nhật ký truy cập máy chủ được sắp xếp theo mã trạng thái và ngày, ví dụ: 404#2017-07-21.\nĐể biết thêm thông tin về cách chọn số lượng shard phù hợp, hãy đọc bài viết Chọn số lượng shard phù hợp cho bảng Amazon DynamoDB quy mô lớn của bạn trên AWS Database Blog.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.7/3.7.2/",
	"title": "Bước 2 - Truy vấn tất cả nhân viên (employees) từ tiểu bang (state)",
	"tags": [],
	"description": "",
	"content": "Bạn có thể sử dụng global secondary index mới để truy vấn bảng. Nếu bạn chỉ sử dụng tiểu bang, truy vấn sẽ không sử dụng thuộc tính khóa sắp xếp. Tuy nhiên, nếu truy vấn có giá trị cho tham số thứ hai, mã sẽ sử dụng thuộc tính GSI_3_SK của global secondary index, chứa cùng giá trị với thuộc tính city_dept, để truy vấn tất cả các giá trị bắt đầu với giá trị tham số.\nẢnh chụp màn hình sau đây hiển thị việc sử dụng các thuộc tính khóa tổng hợp để truy vấn theo thành phố và phòng ban.\nChúng ta có thể thực hiện truy vấn này trong một script Python. Đoạn mã này cho thấy cách một script có thể nhận hai tham số đầu vào (được hiển thị dưới dạng value1 và value2) và tạo một truy vấn đối với global secondary index GSI_3.\nif value2 == \u0026#34;-\u0026#34;: ke = Key(\u0026#39;GSI_3_PK\u0026#39;).eq(\u0026#34;state#{}\u0026#34;.format(value1)) else: ke = Key(\u0026#39;GSI_3_PK\u0026#39;).eq(\u0026#34;state#{}\u0026#34;.format(value1)) \u0026amp; Key(\u0026#39;GSI_3_SK\u0026#39;).begins_with(value2) response = table.query( IndexName=\u0026#39;GSI_3\u0026#39;, KeyConditionExpression=ke ) Chạy script Python sau để truy vấn global secondary index GSI_3 cho tất cả nhân viên ở bang Texas.\npython query_city_dept.py employees TX Kết quả sẽ trông tương tự như sau:\nList of employees . State: TX Name: Bree Gershom. City: Austin. Dept: Development Name: Lida Flescher. City: Austin. Dept: Development Name: Tristam Mole. City: Austin. Dept: Development Name: Malinde Spellman. City: Austin. Dept: Development Name: Giovanni Goutcher. City: Austin. Dept: Development ... Name: Cullie Sheehy. City: San Antonio. Dept: Support Name: Ari Wilstead. City: San Antonio. Dept: Support Name: Odella Kringe. City: San Antonio. Dept: Support Total of employees: 197. Execution time: 0.238062143326 seconds "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.8/3.8.2/",
	"title": "Bước 2 - Xem lại bảng InvoiceAndBills trên bảng điều khiển DynamoDB",
	"tags": [],
	"description": "",
	"content": "Trong bảng điều khiển DynamoDB, mở bảng InvoiceAndBills và chọn tùy chọn menu Items. Từ menu thả xuống, chọn InvoiceAndBills GSI_1 và sau đó Scan bảng.\nTrong kết quả đầu ra, chọn PK để sắp xếp dữ liệu theo thứ tự ngược lại. Chú ý các loại thực thể khác nhau trong cùng một bảng.\nTrong các bước tiếp theo, bạn sẽ truy vấn bảng và truy xuất các loại thực thể khác nhau. Bạn có thể thực hiện các truy vấn này trong bảng điều khiển AWS ngay sau khi bạn truy vấn chúng bằng các script Python để có thêm cái nhìn sâu sắc.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.9/3.9.2/",
	"title": "Bước 2 - Xem lại chính sách AWS IAM cho vai trò IAM",
	"tags": [],
	"description": "",
	"content": "Chúng tôi đã tạo trước vai trò IAM sẽ được sử dụng làm DDBReplicationRoleVai trò thực thi AWS Lambda . Vai trò IAM này cho phép cung cấp một số quyền đối với hàm AWS Lambda mà chúng tôi sẽ cần để sao chép dữ liệu.\nXem lại chính sách sau đây được đính kèm với vai trò IAM.DDBReplicationRole\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34;, \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:ListStreams\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DeleteItem\u0026#34;, \u0026#34;dynamodb:PutItem\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] } Đây là một số quyền được cấp cho hàm Lambda trong chính sách:\nDịch vụ AWS Lambda phải có khả năng gọi DynamoDB Streams và truy xuất bản ghi từ luồng. { \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34;, \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:ListStreams\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } Hàm Lambda có thể đặt và xóa các mục trong bất kỳ bảng DynamoDB nào. { \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DeleteItem\u0026#34;, \u0026#34;dynamodb:PutItem\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } Nhật ký sự kiện được phát hành lên Amazon CloudWatch Logs (nhưng trong phòng thực hành này chúng không khả dụng). { \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } "
},
{
	"uri": "//localhost:1313/vi/6-leda/6.4/6.4.2/",
	"title": "Bước 2: Đảm bảo idempotency của hàm ReduceLambda",
	"tags": [],
	"description": "",
	"content": "Mục tiêu của bước này là chỉnh sửa hàm ReduceLambda để đảm bảo tính idempotency, có nghĩa là các giá trị của bảng hạ nguồn AggregateTable sẽ không thay đổi khi các bản ghi cũ được xử lý lại trong hàm ReduceLambda. Giao dịch DynamoDB cung cấp tính idempotency thông qua tham số ClientRequestToken có thể được cung cấp với thao tác API TransactWriteItems. ClientRequestToken đảm bảo rằng các lần gọi giao dịch tiếp theo với token đã được sử dụng trong 10 phút trước đó sẽ không dẫn đến các cập nhật cho bảng DynamoDB.\nChúng ta tính toán giá trị hash trên tất cả các thông điệp trong batch mà hàm Lambda được gọi để sử dụng làm ClientRequestToken. Lambda đảm bảo rằng hàm được thử lại với cùng một batch thông điệp khi xảy ra lỗi. Do đó, bằng cách đảm bảo rằng tất cả các đường dẫn mã trong hàm Lambda là quyết định, chúng ta có thể đảm bảo tính idempotency của các giao dịch và đạt được quá trình xử lý chỉ một lần ở giai đoạn cuối cùng này của pipeline. Phương pháp này có một điểm yếu vì chúng ta chỉ bảo vệ chống lại các thông điệp được xử lý lại trong một khoảng thời gian 10 phút sau cuộc gọi TransactWriteItems đầu tiên hoàn tất, vì ClientRequestToken chỉ có giá trị trong không quá 10 phút, như được nêu trong tài liệu chính thức.\nĐiều hướng đến dịch vụ AWS Lambda trong AWS Management Console. Nhấp vào hàm ReduceLambda để chỉnh sửa cấu hình của nó. Nhấp vào tab Code để truy cập mã nguồn của hàm Lambda. Tìm đoạn mã sau trong mã nguồn của hàm Lambda:\n# Batch of Items batch = [ { \u0026#39;Update\u0026#39;: { \u0026#39;TableName\u0026#39; : constants.AGGREGATE_TABLE_NAME, \u0026#39;Key\u0026#39; : {constants.AGGREGATE_TABLE_KEY : {\u0026#39;S\u0026#39; : entry}}, \u0026#39;UpdateExpression\u0026#39; : \u0026#34;ADD #val :val \u0026#34;, \u0026#39;ExpressionAttributeValues\u0026#39; : { \u0026#39;:val\u0026#39;: {\u0026#39;N\u0026#39; : str(totals[entry])} }, \u0026#39;ExpressionAttributeNames\u0026#39;: { \u0026#34;#val\u0026#34; : \u0026#34;Value\u0026#34; } } } for entry in totals.keys()] response = ddb_client.transact_write_items( TransactItems = batch ) Đoạn mã này thực hiện các thao tác sau:\nTạo danh sách các từ điển Python chứa các mục tương ứng với các thao tác mục sẽ được xử lý bởi API TransactWriteItems. Để xem tất cả các tùy chọn cho trường bao gồm Update, xem tài liệu API. Cụ thể, mỗi mục Update trong cuộc gọi API thực hiện một thay đổi đối với một mục DynamoDB được khóa bằng entry bằng cách tăng nguyên tử thuộc tính Value lên tổng số đã tính toán. Chỉnh sửa câu lệnh ddb_client.transact_write_items để bao gồm ClientRequestToken Đoạn mã dưới đây có hai chỉnh sửa:\nTính toán thuộc tính ClientRequestToken dưới dạng giá trị hash của tất cả các thông điệp trong batch Lambda. Cung cấp ClientRequestToken như một phần của cuộc gọi API TransactWriteItems của DynamoDB. # Batch of Items batch = [ { \u0026#39;Update\u0026#39;: { \u0026#39;TableName\u0026#39; : constants.AGGREGATE_TABLE_NAME, \u0026#39;Key\u0026#39; : {constants.AGGREGATE_TABLE_KEY : {\u0026#39;S\u0026#39; : entry}}, \u0026#39;UpdateExpression\u0026#39; : \u0026#34;ADD #val :val \u0026#34;, \u0026#39;ExpressionAttributeValues\u0026#39; : { \u0026#39;:val\u0026#39;: {\u0026#39;N\u0026#39; : str(totals[entry])} }, \u0026#39;ExpressionAttributeNames\u0026#39;: { \u0026#34;#val\u0026#34; : \u0026#34;Value\u0026#34; } } } for entry in totals.keys()] # Calculate hash to ensure this batch hasn\u0026#39;t been processed already: record_list_hash = hashlib.md5(str(records).encode()).hexdigest() response = ddb_client.transact_write_items( TransactItems = batch, ClientRequestToken = record_list_hash ) Áp dụng những thay đổi này vào mã nguồn của hàm Lambda, bằng cách chỉnh sửa thủ công hoặc sao chép đoạn mã từ trên:\nTính toán hash trên tất cả các bản ghi trong batch (xem dòng 18 trong đoạn mã trên). Cung cấp hash này cho hàm ddb_client.transact_write_items như một ClientRequestToken (dòng 8 trong đoạn mã trên). Cuối cùng, nhấp vào Deploy để áp dụng các thay đổi. Làm sao để biết nó hoạt động? Kiểm tra bảng xếp hạng của bạn. Nếu tất cả các bước trước đó được hoàn thành thành công, bạn sẽ bắt đầu tích lũy điểm trên 300 điểm. Nếu không, hãy kiểm tra CloudWatch Logs của hàm ReduceLambda để kiểm tra xem có lỗi nào không. Nếu bạn thấy bất kỳ lỗi nào, chúng có thể cung cấp gợi ý về cách khắc phục. Nếu bạn cần trợ giúp, đi đến Summary \u0026amp; Conclusions ở bên trái, sau đó Solutions, và bạn có thể xem mã mong muốn của ReduceLambda.\nNgay cả khi bạn đã làm mọi thứ đúng, tỷ lệ lỗi sẽ không giảm xuống 0! Các lỗi gây ra thủ công vẫn sẽ có, nhưng bây giờ pipeline có thể chịu đựng chúng và vẫn đảm bảo sự tổng hợp nhất quán.\n"
},
{
	"uri": "//localhost:1313/vi/6-leda/6.3/6.3.2/",
	"title": "Bước 2: Kiểm tra MapLambda trigger",
	"tags": [],
	"description": "",
	"content": " Hàm MapLambda đã được kết nối sẵn cho bạn, vì vậy hãy nhanh chóng kiểm tra xem nó hoạt động như mong đợi không!\nKiểm tra xem MapLambda đã được cấu hình trình kích hoạt chính xác để nhận thông điệp từ luồng StateTable:\nĐiều hướng đến dịch vụ AWS Lambda trong AWS Management Console. Nhấp vào hàm MapLambda để xem cấu hình của nó. Xác minh rằng hàm MapLambda có một trình kích hoạt DynamoDB và trình kích hoạt này trỏ đến StateTable (xem hình bên dưới). Làm thế nào để biết nó đang hoạt động? Bất kỳ hàng nào được ghi vào StateTable sẽ kích hoạt hàm MapLambda. Do đó, bạn sẽ có thể thấy các bản ghi cho các lần gọi Lambda.\nNgoài ra, bạn có thể quan sát đầu ra của hàm MapLambda trong bảng DynamoDB ReduceTable. Để làm điều đó, điều hướng đến dịch vụ DynamoDB trong bảng điều khiển AWS, nhấp vào Items ở bên trái, và chọn ReduceTable. Tại giai đoạn này, bạn sẽ thấy nhiều hàng tương tự như hình dưới đây.\nTiếp tục đến: Bước 3.\n"
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.2/",
	"title": "Cấu hình dịch vụ",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ tải dữ liệu vào bảng DynamoDB của mình và cấu hình các tài nguyên OpenSearch Service.\nTrước khi bắt đầu phần này, hãy đảm bảo rằng quá trình thiết lập đã hoàn tất tùy theo cách bạn đang chạy lab này. Quá trình thiết lập sẽ triển khai một số tài nguyên.\nCác phụ thuộc từ Mẫu CloudFormation của Cloud9:\nS3 Bucket: Được sử dụng để lưu trữ xuất dữ liệu ban đầu của DynamoDB cho Zero-ETL Pipeline. IAM Role: Được sử dụng để cấp quyền cho tích hợp pipeline và truy vấn. Cloud9 IDE: Bảng điều khiển để thực thi lệnh, xây dựng tích hợp và chạy các truy vấn mẫu. Các tài nguyên từ Mẫu CloudFormation zETL:\nBảng DynamoDB: Bảng DynamoDB để lưu trữ mô tả sản phẩm. Có tính năng khôi phục theo thời gian (Point-in-time Recovery - PITR) và DynamoDB Streams được bật. Amazon OpenSearch Service Domain: Cụm OpenSearch Service với một nút để nhận dữ liệu từ DynamoDB và hoạt động như một cơ sở dữ liệu vector. "
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.3/7.3.2/",
	"title": "Chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Bây giờ khóa chính đã được thiết kế, hãy tạo một bảng.\nMã mà bạn đã tải xuống trong các bước đầu tiên bao gồm một script Python trong thư mục scripts/ có tên là create_table.py. Nội dung của script Python như sau.\nimport boto3 dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) try: dynamodb.create_table( TableName=\u0026#39;battle-royale\u0026#39;, AttributeDefinitions=[ { \u0026#34;AttributeName\u0026#34;: \u0026#34;PK\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;SK\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; } ], KeySchema=[ { \u0026#34;AttributeName\u0026#34;: \u0026#34;PK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;SK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], ProvisionedThroughput={ \u0026#34;ReadCapacityUnits\u0026#34;: 1, \u0026#34;WriteCapacityUnits\u0026#34;: 1 } ) print(\u0026#34;Table \u0026#39;battle-royale\u0026#39; created successfully.\u0026#34;) except Exception as e: print(\u0026#34;Could not create table. Error:\u0026#34;) print(e) Thay đổi đơn vị dung lượng Chỉnh sửa scripts/create_table.py, đặt cả ReadCapacityUnits và WriteCapacityUnits thành 100 cho bảng battle-royale và lưu tệp.\nScript trên sử dụng thao tác CreateTable (CreateTable) bằng cách sử dụng Boto 3 (Boto 3), AWS SDK cho Python. Thao tác này khai báo hai định nghĩa thuộc tính, đó là các thuộc tính được nhập để sử dụng trong khóa chính. Mặc dù DynamoDB là không có schema (schemaless), bạn phải khai báo tên và loại của các thuộc tính được sử dụng cho khóa chính. Các thuộc tính này phải được bao gồm trong mọi mục được ghi vào bảng và do đó phải được chỉ định khi bạn tạo bảng.\nBởi vì các thực thể khác nhau được lưu trữ trong một bảng duy nhất, bạn không thể sử dụng các tên thuộc tính khóa chính như UserId. Thuộc tính này mang ý nghĩa khác nhau tùy thuộc vào loại thực thể được lưu trữ. Ví dụ, khóa chính cho một người dùng có thể là USERNAME, và khóa chính cho một trò chơi có thể là GAMEID. Do đó, bạn sử dụng các tên chung chung cho các thuộc tính, như PK (cho partition key) và SK (cho sort key).\nSau khi cấu hình các thuộc tính trong sơ đồ khóa, bạn chỉ định throughput được cấp phát (provisioned throughput) (provisioned throughput) cho bảng. DynamoDB có hai chế độ dung lượng: provisioned (cấp phát) và on-demand (theo yêu cầu). Trong chế độ dung lượng cấp phát, bạn chỉ định chính xác lượng throughput đọc và ghi bạn muốn. Bạn phải trả tiền cho dung lượng này dù bạn có sử dụng hay không.\nTrong chế độ dung lượng theo yêu cầu của DynamoDB, bạn trả tiền cho mỗi yêu cầu. Chi phí cho mỗi yêu cầu cao hơn một chút so với khi bạn sử dụng throughput cấp phát đầy đủ, nhưng bạn không phải mất thời gian lập kế hoạch dung lượng hoặc lo lắng về việc bị giới hạn. Chế độ theo yêu cầu hoạt động tốt cho các khối lượng công việc có đột biến hoặc không dự đoán được. Trong lab này, chế độ dung lượng cấp phát được sử dụng.\nBạn có thể chọn chạy script Python create_table.py hoặc lệnh AWS CLI dưới đây. Cả hai đều được cung cấp để hiển thị các phương pháp khác nhau để tương tác với DynamoDB.\nBạn có thể chạy script Python bằng lệnh sau trong Terminal của Cloud9.\npython scripts/create_table.py Script sẽ trả về thông báo này:\nTable \u0026#39;battle-royale\u0026#39; created successfully. Ngoài ra, bạn có thể chạy lệnh AWS CLI từ Terminal của Cloud9.\naws dynamodb create-table \\ --table-name battle-royale \\ --attribute-definitions AttributeName=PK,AttributeType=S AttributeName=SK,AttributeType=S \\ --key-schema AttributeName=PK,KeyType=HASH AttributeName=SK,KeyType=RANGE \\ --provisioned-throughput ReadCapacityUnits=100,WriteCapacityUnits=100 Lệnh CLI sẽ trả về JSON sau:\n{ \u0026#34;TableDescription\u0026#34;: { \u0026#34;AttributeDefinitions\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;PK\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;SK\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; } ], \u0026#34;TableName\u0026#34;: \u0026#34;battle-royale\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;PK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;SK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], \u0026#34;TableStatus\u0026#34;: \u0026#34;CREATING\u0026#34;, \u0026#34;CreationDateTime\u0026#34;: \u0026#34;2023-12-06T13:52:52.187000-06:00\u0026#34;, \u0026#34;ProvisionedThroughput\u0026#34;: { \u0026#34;NumberOfDecreasesToday\u0026#34;: 0, \u0026#34;ReadCapacityUnits\u0026#34;: 1, \u0026#34;WriteCapacityUnits\u0026#34;: 1 }, \u0026#34;TableSizeBytes\u0026#34;: 0, \u0026#34;ItemCount\u0026#34;: 0, \u0026#34;TableArn\u0026#34;: \u0026#34;arn:aws:dynamodb:\u0026lt;AWS Region\u0026gt;:\u0026lt;Account ID\u0026gt;:table/battle-royale\u0026#34;, \u0026#34;TableId\u0026#34;: \u0026#34;\u0026lt;Unique Identifier\u0026gt;\u0026#34;, \u0026#34;DeletionProtectionEnabled\u0026#34;: false } } "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.5/1.5.2/",
	"title": "Định cấu hình môi trường MySQL",
	"tags": [],
	"description": "",
	"content": "Chương này sẽ tạo môi trường nguồn trên AWS như đã thảo luận trong Tổng quan về bài tập. Mẫu CloudFormation được sử dụng dưới đây sẽ tạo VPC nguồn, máy chủ MySQL lưu trữ EC2, cơ sở dữ liệu IMDb và tải tập dữ liệu công khai IMDb vào 6 bảng.\nKhởi chạy mẫu CloudFormation ở US West 2 để triển khai các tài nguyên trong tài khoản của bạn: Tùy chọn, tải xuống mẫu YAML và khởi chạy nó theo cách riêng của bạn Nhấp vào Next Xác nhận Tên ngăn xếp rdbmsmigration và cập nhật các tham số nếu cần (để lại các tùy chọn mặc định nếu có thể) Nhấp vào \u0026ldquo;Tiếp theo\u0026rdquo; hai lần, sau đó chọn \u0026ldquo;Tôi xác nhận rằng AWS CloudFormation có thể tạo tài nguyên IAM có tên tùy chỉnh\u0026rdquo;. Nhấp vào \u0026ldquo;Gửi\u0026rdquo; Ngăn xếp CloudFormation sẽ mất khoảng 5 phút để xây dựng môi trường Đi tới Bảng điều khiển EC2 và đảm bảo cột Kiểm tra trạng thái được thông qua 2/2 lần kiểm tra trước khi chuyển sang bước tiếp theo. Không tiếp tục trừ khi phiên bản MySQL vượt qua cả hai kiểm tra tình trạng, 2/2.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.2/1.2.2/",
	"title": "Đọc Item Collections sử dụng Query",
	"tags": [],
	"description": "",
	"content": "Item Collections là các nhóm Items chia sẻ cùng một Khóa Phân Vùng (Partition Key). Theo định nghĩa, Item Collections chỉ có thể tồn tại trong các bảng có cả Khóa Phân Vùng và Khóa Sắp Xếp (Sort Key). Chúng ta có thể đọc toàn bộ hoặc một phần của một Item Collection bằng cách sử dụng API Query, được gọi bằng lệnh CLI query. Có thể hơi khó hiểu vì từ \u0026ldquo;query\u0026rdquo; thường được sử dụng để chỉ việc \u0026ldquo;đọc dữ liệu từ cơ sở dữ liệu\u0026rdquo;, nhưng trong DynamoDB, \u0026ldquo;query\u0026rdquo; có một ý nghĩa cụ thể: đọc toàn bộ hoặc một phần của một Item Collection.\nKhi gọi API Query, chúng ta phải chỉ định một Biểu thức Điều kiện Khóa (Key Condition Expression). Nếu so sánh với SQL, chúng ta có thể nói \u0026ldquo;đây là phần của câu lệnh WHERE áp dụng cho các thuộc tính Khóa Phân Vùng và Khóa Sắp Xếp\u0026rdquo;. Biểu thức này có thể có một số dạng:\nChỉ giá trị Khóa Phân Vùng của Item Collection. Điều này cho biết chúng ta muốn đọc TẤT CẢ các mục trong bộ sưu tập mục. Giá trị Khóa Phân Vùng và một số loại Điều kiện Khóa Sắp Xếp sẽ khớp với một tập hợp con các hàng trong bộ sưu tập mục. Các điều kiện khóa sắp xếp có thể là =, \u0026lt;, \u0026gt;, \u0026lt;=, \u0026gt;=, BETWEEN, và BEGINS_WITH. Biểu thức Điều kiện Khóa sẽ xác định số lượng RRUs hoặc RCUs mà lệnh Query tiêu thụ. DynamoDB sẽ tính tổng kích thước của tất cả các hàng khớp với Biểu thức Điều kiện Khóa, sau đó chia tổng kích thước đó cho 4KB để tính toán dung lượng tiêu thụ (và sau đó sẽ chia số đó cho hai nếu bạn đang sử dụng chế độ đọc nhất quán cuối cùng).\nChúng ta cũng có thể tùy chọn chỉ định một Biểu thức Lọc (Filter Expression) cho lệnh Query của mình. Nếu so sánh với SQL, chúng ta có thể nói \u0026ldquo;đây là phần của câu lệnh WHERE áp dụng cho các thuộc tính không phải Khóa\u0026rdquo;. Các Biểu thức Lọc sẽ loại bỏ một số mục khỏi Bộ Kết quả trả về bởi lệnh Query, nhưng chúng không ảnh hưởng đến dung lượng tiêu thụ của lệnh Query. Nếu Biểu thức Điều kiện Khóa của bạn khớp với 1.000.000 mục và Biểu thức Lọc giảm bộ kết quả xuống còn 100 mục, bạn vẫn sẽ bị tính phí để đọc tất cả 1.000.000 mục. Nhưng Biểu thức Lọc giảm lượng dữ liệu trả về từ kết nối mạng nên vẫn có lợi cho ứng dụng của chúng ta khi sử dụng Biểu thức Lọc ngay cả khi nó không ảnh hưởng đến giá của lệnh Query.\nBảng ProductCatalog mà chúng ta sử dụng trong các ví dụ trước chỉ có Khóa Phân Vùng, vì vậy hãy xem dữ liệu trong bảng Reply có cả Khóa Phân Vùng và Khóa Sắp Xếp:\naws dynamodb scan --table-name Reply Dữ liệu trong bảng này có thuộc tính Id tham chiếu đến các mục trong bảng Thread. Dữ liệu của chúng ta có hai chủ đề (thread), và mỗi chủ đề có 2 phản hồi (replies). Hãy sử dụng lệnh query CLI để chỉ đọc các mục từ chủ đề 1:\naws dynamodb query \\ --table-name Reply \\ --key-condition-expression \u0026#39;Id = :Id\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:Id\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB#DynamoDB Thread 1\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL Vì Khóa Sắp Xếp trong bảng này là dấu thời gian (timestamp), chúng ta có thể chỉ định Biểu thức Điều kiện Khóa để chỉ trả về các phản hồi trong một chủ đề được đăng sau một thời gian nhất định bằng cách thêm một điều kiện khóa sắp xếp:\naws dynamodb query \\ --table-name Reply \\ --key-condition-expression \u0026#39;Id = :Id and ReplyDateTime \u0026gt; :ts\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:Id\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB#DynamoDB Thread 1\u0026#34;}, \u0026#34;:ts\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;2015-09-21\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL Hãy nhớ rằng chúng ta có thể sử dụng Biểu thức Lọc nếu muốn giới hạn kết quả dựa trên các thuộc tính không phải Khóa. Ví dụ, chúng ta có thể tìm tất cả các phản hồi trong Chủ đề 1 được đăng bởi Người dùng B:\naws dynamodb query \\ --table-name Reply \\ --key-condition-expression \u0026#39;Id = :Id\u0026#39; \\ --filter-expression \u0026#39;PostedBy = :user\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:Id\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB#DynamoDB Thread 1\u0026#34;}, \u0026#34;:user\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;User B\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL Lưu ý rằng trong phản hồi, chúng ta thấy các dòng này:\n\u0026#34;Count\u0026#34;: 1, \u0026#34;ScannedCount\u0026#34;: 2, Điều này cho chúng ta biết rằng Biểu thức Điều kiện Khóa khớp với 2 mục (ScannedCount) và đó là số mục chúng ta phải trả phí để đọc, nhưng Biểu thức Lọc đã giảm kích thước bộ kết quả xuống còn 1 mục (Count).\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.3/1.3.2/",
	"title": "Đọc Item Collections sử dụng Query",
	"tags": [],
	"description": "",
	"content": "Item Collections là các nhóm Items chia sẻ cùng một Khóa Phân Vùng (Partition Key). Theo định nghĩa, Item Collections chỉ có thể tồn tại trong các bảng có cả Khóa Phân Vùng và Khóa Sắp Xếp (Sort Key). Chúng ta có thể đọc toàn bộ hoặc một phần của một Item Collection bằng cách sử dụng API Query, được gọi bằng lệnh CLI query. Có thể hơi khó hiểu vì từ \u0026ldquo;query\u0026rdquo; thường được sử dụng để chỉ việc \u0026ldquo;đọc dữ liệu từ cơ sở dữ liệu\u0026rdquo;, nhưng trong DynamoDB, \u0026ldquo;query\u0026rdquo; có một ý nghĩa cụ thể: đọc toàn bộ hoặc một phần của một Item Collection.\nKhi gọi API Query, chúng ta phải chỉ định một Biểu thức Điều kiện Khóa (Key Condition Expression). Nếu so sánh với SQL, chúng ta có thể nói \u0026ldquo;đây là phần của câu lệnh WHERE áp dụng cho các thuộc tính Khóa Phân Vùng và Khóa Sắp Xếp\u0026rdquo;. Biểu thức này có thể có một số dạng:\nChỉ giá trị Khóa Phân Vùng của Item Collection. Điều này cho biết chúng ta muốn đọc TẤT CẢ các mục trong bộ sưu tập mục. Giá trị Khóa Phân Vùng và một số loại Điều kiện Khóa Sắp Xếp. Hãy khám phá các tùy chọn khác trong Item explorer và tìm hiểu cách thực hiện truy vấn để trả về các phản hồi được sắp xếp từ mới nhất đến cũ nhất. \u0026gt;=, BETWEEN, và BEGINS_WITH. Biểu thức Điều kiện Khóa sẽ xác định số lượng RRUs hoặc RCUs mà lệnh Query tiêu thụ. DynamoDB sẽ tính tổng kích thước của tất cả các hàng khớp với Biểu thức Điều kiện Khóa, sau đó chia tổng kích thước đó cho 4KB để tính toán dung lượng tiêu thụ (và sau đó sẽ chia số đó cho hai nếu bạn đang sử dụng chế độ đọc nhất quán cuối cùng).\nChúng ta cũng có thể tùy chọn chỉ định một Biểu thức Lọc (Filter Expression) cho lệnh Query của mình. Nếu so sánh với SQL, chúng ta có thể nói \u0026ldquo;đây là phần của câu lệnh WHERE áp dụng cho các thuộc tính không phải Khóa\u0026rdquo;. Các Biểu thức Lọc sẽ loại bỏ một số mục khỏi Bộ Kết quả trả về bởi lệnh Query, nhưng chúng không ảnh hưởng đến dung lượng tiêu thụ của lệnh Query. Nếu Biểu thức Điều kiện Khóa của bạn khớp với 1.000.000 mục và Biểu thức Lọc giảm bộ kết quả xuống còn 100 mục, bạn vẫn sẽ bị tính phí để đọc tất cả 1.000.000 mục. Nhưng Biểu thức Lọc giảm lượng dữ liệu trả về từ kết nối mạng nên vẫn có lợi cho ứng dụng của chúng ta khi sử dụng Biểu thức Lọc ngay cả khi nó không ảnh hưởng đến giá của lệnh Query.\nBảng ProductCatalog mà chúng ta sử dụng trong các ví dụ trước chỉ có Khóa Phân Vùng, vì vậy hãy xem dữ liệu trong bảng Reply có cả Khóa Phân Vùng và Khóa Sắp Xếp. Chọn Explore items từ thanh menu bên trái trong phần Tables.\nBạn có thể cần nhấp vào biểu tượng menu hình hamburger để mở rộng menu bên trái nếu nó bị ẩn.\nKhi bạn vào phần Explore Items, bạn cần chọn bảng Reply và sau đó mở rộng hộp Scan/Query items.\nDữ liệu trong bảng này có thuộc tính Id tham chiếu đến các mục trong bảng Thread. Dữ liệu của chúng ta có hai threads, và mỗi thread có 2 phản hồi. Hãy sử dụng chức năng Query để chỉ đọc các mục từ thread 1 bằng cách dán Amazon DynamoDB#DynamoDB Thread 1 vào ô Id (Partition key) và sau đó nhấp vào Run.\nChúng ta có thể thấy rằng có hai mục Reply trong thread DynamoDB Thread 1.\nVì Khóa Sắp Xếp trong bảng này là dấu thời gian (timestamp), chúng ta có thể chỉ định một Biểu thức Điều kiện Khóa để chỉ trả về các phản hồi trong một thread được đăng sau một thời gian nhất định bằng cách thêm một điều kiện khóa sắp xếp, nơi ReplyDateTime lớn hơn 2015-09-21 và nhấp vào Run.\nHãy nhớ rằng chúng ta có thể sử dụng Biểu thức Lọc nếu muốn giới hạn kết quả dựa trên các thuộc tính không phải Khóa. Ví dụ, chúng ta có thể tìm tất cả các phản hồi trong Thread 1 được đăng bởi User B. Xóa điều kiện khóa sắp xếp, và nhấp vào Add filter, sau đó sử dụng PostedBy cho tên Thuộc tính, Điều kiện Equals và Giá trị User B, sau đó nhấp vào Run.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.2/",
	"title": "Khám phá DynamoDB với CLI",
	"tags": [],
	"description": "",
	"content": "Chúng ta sẽ khám phá DynamoDB với AWS CLI bằng cách sử dụng AWS Cloud9 Management Console hoặc Session Manager.\nCấp độ trừu tượng cao nhất trong DynamoDB là một Bảng (trong DynamoDB không có khái niệm về \u0026ldquo;Cơ sở dữ liệu\u0026rdquo; chứa nhiều bảng bên trong như ở các dịch vụ NoSQL hoặc RDBMS khác). Bên trong một Bảng, bạn sẽ chèn các Mục (Items), tương tự như các hàng (row) trong các dịch vụ khác. Các Mục là tập hợp của các Thuộc tính (Attributes), tương tự như các cột (column). Mỗi Mục phải có một Khóa Chính (Primary Key) để nhận diện duy nhất hàng đó (hai Mục không thể chứa cùng một Khóa Chính). Khi tạo bảng, ít nhất bạn phải chọn một thuộc tính làm Khóa Phân Vùng (Partition Key, hay còn gọi là Hash Key) và bạn có thể tùy chọn xác định một thuộc tính khác làm Khóa Sắp Xếp (Sort Key).\nNếu bảng của bạn chỉ có Khóa Phân Vùng, thì Khóa Phân Vùng là Khóa Chính và phải nhận diện duy nhất mỗi mục. Nếu bảng của bạn có cả Khóa Phân Vùng và Khóa Sắp Xếp, thì có thể có nhiều mục có cùng Khóa Phân Vùng, nhưng sự kết hợp giữa Khóa Phân Vùng và Khóa Sắp Xếp sẽ là Khóa Chính và nhận diện duy nhất hàng đó. Nói cách khác, bạn có thể có nhiều mục có cùng Khóa Phân Vùng miễn là Khóa Sắp Xếp của chúng khác nhau. Các mục có cùng Khóa Phân Vùng được gọi là thuộc về cùng một Bộ Sưu Tập Mục (Item Collection).\nĐể biết thêm thông tin, vui lòng đọc về Các Khái Niệm Cơ Bản trong DynamoDB.\nCác thao tác trong DynamoDB tiêu thụ dung lượng từ bảng. Khi bảng sử dụng dung lượng Theo Yêu Cầu (On-Demand), các thao tác đọc sẽ tiêu thụ Đơn vị Yêu cầu Đọc (RRUs) và các thao tác ghi sẽ tiêu thụ Đơn vị Yêu cầu Ghi (WRUs). Khi bảng sử dụng Dung lượng Cung cấp (Provisioned Capacity), các thao tác đọc sẽ tiêu thụ Đơn vị Dung lượng Đọc (RCUs) và các thao tác ghi sẽ tiêu thụ Đơn vị Dung lượng Ghi (WCUs). Để biết thêm thông tin, vui lòng xem Chế độ Dung lượng Đọc/Ghi trong Hướng dẫn Dành cho Nhà Phát triển DynamoDB.\nBây giờ, hãy đi vào shell và khám phá DynamoDB với AWS CLI.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.4/1.4.2/",
	"title": "Khôi phục sao lưu theo thời gian",
	"tags": [],
	"description": "",
	"content": "Khôi phục theo thời gian của DynamoDB, hay còn gọi là \u0026ldquo;PITR\u0026rdquo;, giúp bảo vệ các bảng DynamoDB của bạn khỏi các thao tác ghi hoặc xóa ngoài ý muốn. Với khôi phục theo thời gian, bạn không cần lo lắng về việc tạo, duy trì, hoặc lên lịch sao lưu theo yêu cầu. Ví dụ, giả sử một script thử nghiệm vô tình ghi vào bảng DynamoDB sản xuất. Với khôi phục theo thời gian, bạn có thể khôi phục bảng đó về bất kỳ thời điểm nào trong vòng 35 ngày gần nhất. DynamoDB duy trì các bản sao lưu gia tăng của bảng của bạn. Mặc định, PITR bị tắt.\nCách bật PITR Đầu tiên, truy cập vào DynamoDB Console và nhấp vào Tables từ menu bên. Trong danh sách các bảng, chọn bảng ProductCatalog. Trong tab Backups của bảng ProductCatalog, trong phần Point-in-time recovery, chọn Edit. Chọn Enable Point-in-time-recovery và nhấp vào Save changes. Khôi phục một bảng về một thời điểm Bây giờ giả sử chúng ta có một số bản ghi không mong muốn trong bảng ProductCatalog như được đánh dấu bên dưới.\nLàm theo các bước dưới đây để khôi phục ProductCatalog bằng cách sử dụng Point-in-time-recovery.\nĐăng nhập vào AWS Management Console và mở DynamoDB console. Trong bảng điều hướng ở phía bên trái của giao diện điều khiển, chọn Tables. Trong danh sách các bảng, chọn bảng ProductCatalog. Trong tab Backups của bảng ProductCatalog, trong phần Point-in-time recovery, chọn Restore to point-in-time. Đối với tên bảng mới, nhập ProductCatalogPITR. Để xác nhận thời gian có thể khôi phục, đặt Restore date and time thành Latest restore date. Chọn Restore để bắt đầu quá trình khôi phục. Lưu ý: Bạn có thể khôi phục bảng về cùng một Khu vực AWS hoặc sang một Khu vực khác từ nơi bản sao lưu tồn tại. Bạn cũng có thể loại trừ các chỉ mục phụ không được tạo trên bảng khôi phục mới. Ngoài ra, bạn có thể chỉ định một chế độ mã hóa khác.\nBảng đang được khôi phục sẽ hiển thị với trạng thái Restoring. Sau khi quá trình khôi phục hoàn tất, trạng thái của bảng ProductCatalogPITR sẽ chuyển thành Active.\n"
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.2/2.2.2/",
	"title": "Kích hoạt mô hình Amazon Bedrock",
	"tags": [],
	"description": "",
	"content": "Amazon Bedrock là một dịch vụ được quản lý hoàn toàn, cung cấp các mô hình nền tảng (Foundation Models - FMs) hiệu suất cao từ các công ty AI hàng đầu như AI21 Labs, Anthropic, Cohere, Meta, Mistral AI, Stability AI và Amazon thông qua một API duy nhất, cùng với một loạt các khả năng bạn cần để xây dựng các ứng dụng AI tạo sinh với tính bảo mật, quyền riêng tư và AI có trách nhiệm.\nTrong ứng dụng này, Bedrock sẽ được sử dụng để thực hiện các truy vấn đề xuất sản phẩm bằng ngôn ngữ tự nhiên, sử dụng OpenSearch Service như một cơ sở dữ liệu vector.\nBedrock yêu cầu các mô hình nền tảng (FMs) khác nhau phải được kích hoạt trước khi chúng được sử dụng.\nMở Amazon Bedrock Model Access\nNhấp vào \u0026ldquo;Manage model access\u0026rdquo;\nChọn \u0026ldquo;Titan Embeddings G1 - Text\u0026rdquo; và \u0026ldquo;Claude\u0026rdquo;, sau đó nhấp vào Request model access\nChờ cho đến khi bạn được cấp quyền truy cập vào cả hai mô hình trước khi tiếp tục. Trạng thái Access status phải hiển thị Access granted trước khi chuyển sang bước tiếp theo.\nKhông tiếp tục trừ khi các mô hình cơ sở \u0026ldquo;Claude\u0026rdquo; và \u0026ldquo;Titan Embeddings G1 - Text\u0026rdquo; đã được cấp cho tài khoản của bạn.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.2/",
	"title": "Lập kế hoạch cho mô hình dữ liệu của bạn&#34;",
	"tags": [],
	"description": "",
	"content": "Mô hình hóa dữ liệu là quá trình thiết kế cách một ứng dụng lưu trữ dữ liệu trong một cơ sở dữ liệu nhất định. Với một cơ sở dữ liệu NoSQL như DynamoDB, mô hình hóa dữ liệu khác với mô hình hóa với một cơ sở dữ liệu quan hệ. Một cơ sở dữ liệu quan hệ được xây dựng để linh hoạt và có thể phù hợp với các ứng dụng phân tích. Trong mô hình hóa dữ liệu quan hệ, bạn bắt đầu với các thực thể của mình trước. Khi bạn có một mô hình quan hệ đã được chuẩn hóa, bạn có thể đáp ứng bất kỳ mẫu truy vấn nào bạn cần trong ứng dụng của mình.\nCác cơ sở dữ liệu NoSQL được thiết kế để đạt tốc độ và khả năng mở rộng — không phải linh hoạt. Mặc dù hiệu suất của cơ sở dữ liệu quan hệ có thể giảm sút khi bạn mở rộng quy mô, các cơ sở dữ liệu mở rộng theo chiều ngang như DynamoDB cung cấp hiệu suất nhất quán ở bất kỳ quy mô nào. Một số người dùng DynamoDB có các bảng lớn hơn 100 TB, và hiệu suất đọc và ghi của các bảng này vẫn giống như khi các bảng có kích thước nhỏ hơn 1 GB.\nĐể đạt được kết quả tốt nhất với cơ sở dữ liệu NoSQL như DynamoDB, cần có sự thay đổi tư duy so với cơ sở dữ liệu quan hệ thông thường.\nHãy cùng xem qua một số phương pháp tốt nhất khi mô hình hóa dữ liệu với DynamoDB.\n"
},
{
	"uri": "//localhost:1313/vi/2-lbed/",
	"title": "LBED: Generative AI với rích hợp DynamoDB zero-ETL vào OpenSearch và Amazon Bedrock",
	"tags": [],
	"description": "",
	"content": "Trong workshop này, bạn sẽ có trải nghiệm thực hành thiết lập tích hợp DynamoDB với Amazon OpenSearch Service mà không cần ETL (zero-ETL) để hỗ trợ truy vấn ngôn ngữ tự nhiên của một danh mục sản phẩm. Bạn sẽ tạo một pipeline từ bảng DynamoDB đến OpenSearch Service, tạo một Amazon Bedrock Connector trong OpenSearch Service, và truy vấn Bedrock bằng cách sử dụng OpenSearch Service làm vector store. Cuối buổi học này, bạn sẽ tự tin trong khả năng tích hợp DynamoDB với OpenSearch Service để hỗ trợ các ứng dụng suy luận có ý thức ngữ cảnh.\nKết hợp Amazon DynamoDB với Amazon OpenSearch Service là một mẫu kiến trúc phổ biến cho các ứng dụng cần kết hợp khả năng mở rộng cao và hiệu suất của DynamoDB cho khối lượng công việc giao dịch với các khả năng tìm kiếm và phân tích mạnh mẽ của OpenSearch.\nDynamoDB là một cơ sở dữ liệu NoSQL được thiết kế để có tính sẵn sàng cao, hiệu suất cao và khả năng mở rộng, tập trung vào các hoạt động khóa/giá trị. OpenSearch Service cung cấp các tính năng tìm kiếm nâng cao như tìm kiếm toàn văn, tìm kiếm theo khía cạnh và khả năng truy vấn phức tạp. Khi kết hợp, hai dịch vụ này có thể đáp ứng nhiều trường hợp sử dụng ứng dụng khác nhau.\nWorkshop này sẽ cho phép bạn thiết lập một trường hợp sử dụng như vậy. DynamoDB sẽ là nguồn dữ liệu chính xác cho thông tin danh mục sản phẩm và OpenSearch sẽ cung cấp khả năng tìm kiếm vector để cho phép Amazon Bedrock (một dịch vụ AI tạo sinh) đưa ra các đề xuất sản phẩm.\nLab này tạo ra các tài nguyên OpenSearch Service, DynamoDB, và Secrets Manager. Nếu bạn chạy trong tài khoản riêng của mình, các tài nguyên này sẽ phát sinh chi phí khoảng 30 USD mỗi tháng. Hãy nhớ xóa CloudFormation Stack sau khi hoàn thành lab.\n"
},
{
	"uri": "//localhost:1313/vi/5-lmr/5.2/",
	"title": "Module 1: Triển khai các tài nguyên phụ trợ",
	"tags": [],
	"description": "",
	"content": "Bạn có thể truy cập EC2 Instance hoặc Cloud9 để thực hiện các bước thiết lập.\nCác bước thiết lập Phòng thí nghiệm này yêu cầu một terminal shell với Python3 và AWS Command Line Interface (CLI) đã được cài đặt và cấu hình với thông tin đăng nhập quản trị.\nĐể thiết lập môi trường cho một EC2 Instance: Truy cập EC2 Chọn Instance và kết nối sử dụng session manager Để thiết lập môi trường phát triển AWS Cloud9 của bạn: Chọn Services ở đầu trang, sau đó chọn Cloud9 trong Developer Tools.\nSẽ có một môi trường sẵn sàng sử dụng dưới My environments.\nNhấp vào Open dưới Cloud9 IDE, và IDE của bạn sẽ mở với một ghi chú chào mừng.\nBây giờ bạn sẽ thấy môi trường AWS Cloud9 của mình. Bạn cần làm quen với ba khu vực của bảng điều khiển AWS Cloud9 được hiển thị trong ảnh chụp màn hình sau:\nFile explorer: Ở phía bên trái của IDE, file explorer hiển thị danh sách các tệp trong thư mục của bạn.\nFile editor: Ở phía trên bên phải của IDE, file editor là nơi bạn xem và chỉnh sửa các tệp mà bạn đã chọn trong file explorer.\nTerminal: Ở phía dưới bên phải của IDE, đây là nơi bạn chạy các lệnh để thực thi các mẫu mã.\nXác minh môi trường Chạy aws sts get-caller-identity để xác minh AWS CLI đang hoạt động. Chạy python3 --version để xác minh rằng python3 đã được cài đặt. Môi trường Cloud9 của bạn đã được cấu hình sẵn với boto3, nhưng cho phòng thí nghiệm này, chúng ta cũng sẽ cần AWS Chalice.\nChạy sudo python3 -m pip install chalice để cài đặt AWS Chalice. Bạn có thể thấy một vài dòng WARNING ở gần cuối đầu ra của lệnh, nhưng bạn có thể bỏ qua chúng một cách an toàn.\nChạy curl -O https://amazon-dynamodb-labs.com/assets/global-serverless.zip Chạy unzip global-serverless.zip \u0026amp;\u0026amp; cd global-serverless Để xem các tài nguyên ứng dụng mà chúng ta sẽ triển khai, bạn có thể mở tệp app.py bằng cách điều hướng đến \u0026ldquo;global-serverless/app.py\u0026rdquo; trong file explorer. Mã này định nghĩa các hàm Lambda và các route của API Gateway. Triển khai bảng DynamoDB mới Trong terminal của bạn, chạy: aws dynamodb create-table \\ --region us-west-2 \\ --table-name global-serverless \\ --attribute-definitions \\ AttributeName=PK,AttributeType=S \\ AttributeName=SK,AttributeType=S \\ --key-schema \\ AttributeName=PK,KeyType=HASH \\ AttributeName=SK,KeyType=RANGE \\ --billing-mode PAY_PER_REQUEST \\ --query \u0026#39;{\u0026#34;New Table \u0026#34;:TableDescription.TableArn, \u0026#34;Status \u0026#34;:TableDescription.TableStatus }\u0026#39; Chờ một lát để bảng được tạo. Kiểm tra xem trạng thái bảng thay đổi từ CREATING sang ACTIVE bằng cách chạy lệnh này:\naws dynamodb describe-table \\ --table-name global-serverless \\ --region us-west-2 \\ --query \u0026#39;{TableStatus: Table.TableStatus}\u0026#39; Bảng của chúng ta ở vùng us-west-2 (Oregon). Hãy làm cho nó trở thành một Global Table bằng cách yêu cầu một bản sao ở eu-west-1 (Europe/Dublin). Chạy lệnh này để tạo một bản sao mới ở vùng eu-west-1 (Europe/Dublin):\naws dynamodb update-table --table-name global-serverless --region us-west-2 --cli-input-json \\ \u0026#39;{\u0026#34;ReplicaUpdates\u0026#34;: [ { \u0026#34;Create\u0026#34;: {\u0026#34;RegionName\u0026#34;: \u0026#34;eu-west-1\u0026#34; } } ]}\u0026#39; Kiểm tra xem trạng thái bản sao bảng đã chuyển sang ACTIVE bằng cách chạy lệnh này:\naws dynamodb describe-table \\ --table-name global-serverless \\ --region us-west-2 \\ --query \u0026#39;{TableStatus: Table.TableStatus, Replicas: Table.Replicas}\u0026#39; Tiếp theo, thêm một số dữ liệu vào bảng: Việc ghi vào một Global Table được thực hiện bằng cách ghi vào bất kỳ bảng bản sao vùng nào. Chạy lệnh này để tải các mục thư viện video vào bảng bằng batch-write-item:\naws dynamodb batch-write-item \\ --region us-west-2 \\ --request-items file://sample-data.json Những mục này là cách giao diện người dùng sẽ hiển thị video nào có sẵn để phát trực tuyến.\nXác minh dữ liệu đã được ghi: aws dynamodb get-item \\ --table-name global-serverless \\ --region us-west-2 \\ --key \u0026#39;{\u0026#34;PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;library\u0026#34;}, \u0026#34;SK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;01\u0026#34;}}\u0026#39; Triển khai dịch vụ API backend tới vùng đầu tiên Chạy export AWS_DEFAULT_REGION=us-west-2 để hướng dẫn Chalice triển khai vào us-west-2 cho vùng đầu tiên của chúng ta. Chạy chalice deploy và chờ cơ sở hạ tầng được tạo. Chalice là một framework serverless dựa trên Python. Khi script hoàn thành, nó sẽ báo cáo danh sách các tài nguyên đã triển khai. Sao chép và dán URL của Rest API vào một ghi chú vì bạn sẽ cần nó sau này. Sao chép URL REST API đó và dán vào một tab trình duyệt mới để kiểm tra. Bạn sẽ thấy một phản hồi JSON dạng {ping: \u0026ldquo;ok\u0026rdquo;}. Bạn có thể nhập vào các đường dẫn nhất định vào cuối URL. Thêm từ scan để URL kết thúc với /api/scan. Bạn sẽ thấy một phản hồi JSON đại diện cho kết quả của một lần quét bảng. Ứng dụng web Một ứng dụng web đơn trang tĩnh đã được cung cấp cho bạn.\nhttps://amazon-dynamodb-labs.com/static/global-serverless-application/web/index.html Ứng dụng này cho phép bạn nhập một hoặc nhiều điểm cuối API, và lưu trữ mỗi điểm dưới dạng cookie trình duyệt. Các điểm cuối API được lưu trữ sẽ vẫn ở trong trình duyệt ngay cả khi backend gặp sự cố. Bằng cách này, ứng dụng web có thể tự quyết định về việc chuyển hướng đến một API thay thế nếu có lỗi hoặc không có phản hồi từ API đang sử dụng. Ứng dụng web không chứa mã AWS hoặc thông tin xác thực nào, nó chỉ thực hiện các cuộc gọi HTTP GET đến API cho bạn. Nội dung web của ứng dụng có thể được lưu trữ từ một bucket S3, làm cho sẵn có toàn cầu qua Cloudfront, lưu trữ cục bộ trong Chrome, hoặc chuyển đổi thành một ứng dụng di động. Trong buổi workshop này, chúng ta giả định rằng người dùng luôn có quyền truy cập vào ứng dụng web ngay cả khi các dịch vụ backend trở nên không khả dụng. Các bước:\nTrong ứng dụng web, nhấn nút Add API. Dán vào URL API mà bạn đã tạo trước đó và nhấp OK. Xem lại các nút xuất hiện. Nhấp vào Ping để tạo một yêu cầu đến URL mức cơ bản. Độ trễ của vòng lặp sẽ được hiển thị. Điều này có thể chậm hơn mong đợi do Lambda cold start. Nhấp lại vào Ping và kiểm tra độ trễ. Nhấp vào nút get-item. Điều này sẽ trả về bookmark cho user100 đang xem một chương trình tên là AshlandValley. Nhấp vào các nút forward và back. Chúng sẽ tạo ra các yêu cầu để tăng hoặc giảm bookmark theo 1 giây. Bây giờ bạn có một môi trường thử nghiệm nơi bạn có thể thực hiện đọc và ghi vào một bản ghi DynamoDB thông qua API tùy chỉnh.\nTriển khai stack dịch vụ đến vùng thứ hai, Ireland Chạy export AWS_DEFAULT_REGION=eu-west-1 để hướng dẫn Chalice triển khai vào eu-west-1 cho vùng thứ hai của chúng ta. Chạy chalice deploy và chờ cơ sở hạ tầng được tạo trong eu-west-1. Khi script hoàn thành, nó sẽ báo cáo danh sách các tài nguyên đã triển khai. Lần nữa, ghi lại URL REST API mới vào một ghi chú để sử dụng sau này. Quay lại ứng dụng web. Nhấp vào Add API một "
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.2/4.2.2/",
	"title": "Tải dữ liệu mẫu",
	"tags": [],
	"description": "",
	"content": "Sao chép dữ liệu JSON bên dưới vào tệp có tên Orders.json.\n{ \u0026#34;Orders\u0026#34;: [ { \u0026#34;PutRequest\u0026#34;: { \u0026#34;Item\u0026#34;: { \u0026#34;customer\u0026#34;: { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;799102280\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Salma Otero\u0026#34; }, \u0026#34;address\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;22 Milton Road, Exeter,EX2 6BN\u0026#34; }, \u0026#34;phone\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;+441482133202\u0026#34; } } }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;4514280\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PLACED\u0026#34; }, \u0026#34;items\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23884750\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Metallic Long-Wear Cream Shadow\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;13\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£15.00\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23699354\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Eye Liner\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;8\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£9.00\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23599030\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Bronzing Powder\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£12.00\u0026#34; } } } ] }, \u0026#34;orderDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-01 01:05:54\u0026#34; }, \u0026#34;shipDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-04 18:54:12\u0026#34; } } } }, { \u0026#34;PutRequest\u0026#34;: { \u0026#34;Item\u0026#34;: { \u0026#34;customer\u0026#34;: { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;941852721\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Taylor Burnette\u0026#34; }, \u0026#34;address\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;31 Walkhampton Avenue, Bradwell Common,MK13 8ND\u0026#34; }, \u0026#34;phone\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;+441663724681\u0026#34; } } }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;9844720\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PLACED\u0026#34; }, \u0026#34;items\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;24002126\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Shimmer Wash Eye Shadow\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£13.00\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23607685\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Buffing Grains for Face\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;11\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£8.00\u0026#34; } } } ] }, \u0026#34;orderDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-01 01:49:13\u0026#34; }, \u0026#34;shipDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-06 13:05:33\u0026#34; } } } }, { \u0026#34;PutRequest\u0026#34;: { \u0026#34;Item\u0026#34;: { \u0026#34;customer\u0026#34;: { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;558490551\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Brody Dent\u0026#34; }, \u0026#34;address\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;3 Bailey Lane, Clenchwarton,PE34 4AY\u0026#34; }, \u0026#34;phone\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;+441268381612\u0026#34; } } }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;6421680\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PLACED\u0026#34; }, \u0026#34;items\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23769901\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Hydrating Face Cream\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;8\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£12.00\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23673445\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;EXTRA Repair Serum\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;5\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£10.00\u0026#34; } } } ] }, \u0026#34;orderDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-01 20:39:08\u0026#34; }, \u0026#34;shipDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-04 16:29:36\u0026#34; } } } }, { \u0026#34;PutRequest\u0026#34;: { \u0026#34;Item\u0026#34;: { \u0026#34;customer\u0026#34;: { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;242903240\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Julia Caswell\u0026#34; }, \u0026#34;address\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;81 Alwyn Road, Darlington,DL3 0AS\u0026#34; }, \u0026#34;phone\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;+441305066386\u0026#34; } } }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;9953371\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PLACED\u0026#34; }, \u0026#34;items\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23924636\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Protective Face Lotion\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;9\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£3.00\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23514506\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Nail File\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;13\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£11.00\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23508704\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Kitten Heels Powder Finish Foot Creme\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PURCHASED\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£11.00\u0026#34; } } } ] }, \u0026#34;orderDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-01 00:21:53\u0026#34; }, \u0026#34;shipDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-05 11:48:21\u0026#34; } } } } ] } Tải dữ liệu mẫu vào bảng Đơn hàng bằng lệnh AWS CLI batch-write-em.\naws dynamodb batch-write-item --request-items file://Orders.json Tải thành công sẽ tạo ra một thông báo tương tự như thông báo bên dưới.\nĐầu ra mẫu { \u0026#34;UnprocessedItems\u0026#34;: {} } "
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.3/4.3.2/",
	"title": "Tạo Dead Letter Queue",
	"tags": [],
	"description": "",
	"content": "Nếu hàm Lambda không thể xử lý thành công một bản ghi mà nó nhận được từ DynamoDB stream, dịch vụ Lambda nên ghi thông tin siêu dữ liệu (metadata) của bản ghi lỗi vào hàng đợi chết (Dead Letter Queue - DLQ) để lý do của lỗi có thể được điều tra và giải quyết.\nVì vậy, hãy tạo một Amazon SQS Dead Letter Queue tên là orders-ddbs-dlq cho trigger hàm Lambda của bạn bằng lệnh AWS CLI dưới đây.\naws sqs create-queue --queue-name orders-ddbs-dlq Ví dụ kết quả:\n{ \u0026#34;QueueUrl\u0026#34;: \u0026#34;https://sqs.{aws-region}.amazonaws.com/{aws-account-id}/orders-ddbs-dlq\u0026#34; } Sau đó, bạn sẽ cần ARN của hàng đợi. Sử dụng lệnh dưới đây, sửa đổi URL hàng đợi sau \u0026ndash;queue-url để khớp với kết quả của lệnh trước đó, và sau đó lưu ARN để sử dụng sau này.\naws sqs get-queue-attributes --attribute-names \u0026#34;QueueArn\u0026#34; --query \u0026#39;Attributes.QueueArn\u0026#39; --output text \\ --queue-url \u0026#34;https://sqs.{aws-region}.amazonaws.com/{aws-account-id}/orders-ddbs-dlq\u0026#34; "
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.4/4.4.2/",
	"title": "Tạo Dead Letter Queue",
	"tags": [],
	"description": "",
	"content": "Nếu hàm Lambda không thể xử lý thành công bất kỳ bản ghi nào mà nó nhận được từ Amazon Kinesis, dịch vụ Lambda nên ghi siêu dữ liệu của bản ghi lỗi vào hàng đợi chết (Dead Letter Queue - DLQ) để lý do thất bại có thể được điều tra và khắc phục.\nVì vậy, hãy tạo một Amazon SQS Dead Letter Queue có tên orders-kds-dlq cho trigger của hàm Lambda của bạn bằng cách sử dụng lệnh AWS CLI dưới đây.\naws sqs create-queue --queue-name orders-kds-dlq Ví dụ về kết quả đầu ra:\n{ \u0026#34;QueueUrl\u0026#34;: \u0026#34;https://sqs.{aws-region}.amazonaws.com/{aws-account-id}/orders-kds-dlq\u0026#34; } Như trước đây, bạn sẽ cần ARN của hàng đợi. Sử dụng lệnh dưới đây, thay đổi URL hàng đợi sau \u0026ndash;queue-url để phù hợp với kết quả của lệnh trước đó.\naws sqs get-queue-attributes --attribute-names \u0026#34;QueueArn\u0026#34; --query \u0026#39;Attributes.QueueArn\u0026#39; --output text \\ --queue-url \u0026#34;https://sqs.{aws-region}.amazonaws.com/{aws-account-id}/orders-kds-dlq\u0026#34; "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.1/1.1.2/",
	"title": "Tạo DynamoDB Tables",
	"tags": [],
	"description": "",
	"content": "Bạn có thể truy cập session manager nhập lệnh sudo su sau đó thực hiện các câu lệnh hoặc bạn có thể truy cập cloud9 và thực hiện các câu lệnh tiếp theo\nChúng ta bây giờ sẽ tạo các bảng (và trong bước tiếp theo, tải dữ liệu vào chúng) dựa trên dữ liệu mẫu từ DynamoDB Developer Guide.\nSao chép các lệnh create-table bên dưới và dán chúng vào command prompt, nhấn enter ở lệnh cuối cùng để thực thi nó. Sau đó, hãy sử dụng các lệnh chờ tương ứng bằng cách dán chúng vào cùng một terminal và chạy chúng.\naws dynamodb create-table \\ --table-name ProductCatalog \\ --attribute-definitions \\ AttributeName=Id,AttributeType=N \\ --key-schema \\ AttributeName=Id,KeyType=HASH \\ --provisioned-throughput \\ ReadCapacityUnits=10,WriteCapacityUnits=5 \\ --query \u0026#34;TableDescription.TableStatus\u0026#34; aws dynamodb create-table \\ --table-name Forum \\ --attribute-definitions \\ AttributeName=Name,AttributeType=S \\ --key-schema \\ AttributeName=Name,KeyType=HASH \\ --provisioned-throughput \\ ReadCapacityUnits=10,WriteCapacityUnits=5 \\ --query \u0026#34;TableDescription.TableStatus\u0026#34; aws dynamodb create-table \\ --table-name Thread \\ --attribute-definitions \\ AttributeName=ForumName,AttributeType=S \\ AttributeName=Subject,AttributeType=S \\ --key-schema \\ AttributeName=ForumName,KeyType=HASH \\ AttributeName=Subject,KeyType=RANGE \\ --provisioned-throughput \\ ReadCapacityUnits=10,WriteCapacityUnits=5 \\ --query \u0026#34;TableDescription.TableStatus\u0026#34; aws dynamodb create-table \\ --table-name Reply \\ --attribute-definitions \\ AttributeName=Id,AttributeType=S \\ AttributeName=ReplyDateTime,AttributeType=S \\ --key-schema \\ AttributeName=Id,KeyType=HASH \\ AttributeName=ReplyDateTime,KeyType=RANGE \\ --provisioned-throughput \\ ReadCapacityUnits=10,WriteCapacityUnits=5 \\ --query \u0026#34;TableDescription.TableStatus\u0026#34; Chạy các lệnh chờ. Khi tất cả chúng đều hoàn thành, bạn có thể tiếp tục:\naws dynamodb wait table-exists --table-name ProductCatalog aws dynamodb wait table-exists --table-name Forum aws dynamodb wait table-exists --table-name Thread aws dynamodb wait table-exists --table-name Reply "
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.4/7.4.2/",
	"title": "Tạo sparse GSI",
	"tags": [],
	"description": "",
	"content": "Dưới đây là bản dịch sang tiếng Việt, giữ nguyên các từ chuyên ngành tiếng Anh:\nTrong bước này, bạn tạo chỉ mục thứ cấp toàn cục thưa (global secondary index - GSI) cho các game mở (những game chưa đầy người chơi).\nTạo GSI tương tự như tạo bảng. Trong mã mà bạn đã tải xuống, bạn sẽ tìm thấy tệp script trong thư mục scripts/ có tên add_secondary_index.py.\nimport boto3 dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) try: dynamodb.update_table( TableName=\u0026#39;battle-royale\u0026#39;, AttributeDefinitions=[ { \u0026#34;AttributeName\u0026#34;: \u0026#34;map\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;open_timestamp\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; } ], GlobalSecondaryIndexUpdates=[ { \u0026#34;Create\u0026#34;: { \u0026#34;IndexName\u0026#34;: \u0026#34;OpenGamesIndex\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;map\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;open_timestamp\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], \u0026#34;Projection\u0026#34;: { \u0026#34;ProjectionType\u0026#34;: \u0026#34;ALL\u0026#34; }, \u0026#34;ProvisionedThroughput\u0026#34;: { \u0026#34;ReadCapacityUnits\u0026#34;: 1, \u0026#34;WriteCapacityUnits\u0026#34;: 1 } } } ], ) print(\u0026#34;Bảng \u0026#39;battle-royale\u0026#39; đã được cập nhật thành công.\u0026#34;) except Exception as e: print(\u0026#34;Không thể cập nhật bảng. Lỗi:\u0026#34;) print(e) Thay đổi đơn vị dung lượng\nChỉnh sửa scripts/add_secondary_index.py, đặt cả ReadCapacityUnits và WriteCapacityUnits thành 100 cho OpenGamesIndex. Sau đó, lưu lại tệp.\nKhi các thuộc tính được sử dụng trong khóa chính (primary key) cho bảng hoặc chỉ mục thứ cấp (secondary index), chúng phải được định nghĩa trong AttributeDefinitions. Sau đó, bạn Create một GSI mới trong thuộc tính GlobalSecondaryIndexUpdates. Đối với GSI này, bạn cần chỉ định tên chỉ mục, sơ đồ của khóa chính, thông lượng được cấp phát (provisioned throughput), và các thuộc tính mà bạn muốn đưa vào (projection).\nLưu ý rằng bạn không cần phải chỉ định rằng GSI được sử dụng như một chỉ mục thưa. Điều này chỉ phụ thuộc vào dữ liệu mà bạn đưa vào. Nếu bạn ghi các mục vào bảng mà không có các thuộc tính cho chỉ mục thứ cấp, chúng sẽ không được đưa vào chỉ mục thứ cấp của bạn.\nBạn có thể chọn chạy script Python add_secondary_index.py hoặc lệnh AWS CLI dưới đây. Cả hai đều được cung cấp để cho thấy các phương pháp khác nhau để tương tác với DynamoDB.\nTạo GSI của bạn bằng cách chạy lệnh sau:\npython scripts/add_secondary_index.py Bạn sẽ thấy thông báo sau trong bảng điều khiển:\nBảng \u0026#39;battle-royale\u0026#39; đã được cập nhật thành công. Ngoài ra, bạn có thể tạo GSI bằng cách chạy lệnh AWS CLI dưới đây:\naws dynamodb update-table \\ --table-name battle-royale \\ --attribute-definitions AttributeName=map,AttributeType=S AttributeName=open_timestamp,AttributeType=S \\ --global-secondary-index-updates \\ \u0026#34;[ { \\\u0026#34;Create\\\u0026#34;: { \\\u0026#34;IndexName\\\u0026#34;: \\\u0026#34;OpenGamesIndex\\\u0026#34;, \\\u0026#34;KeySchema\\\u0026#34;: [ { \\\u0026#34;AttributeName\\\u0026#34;: \\\u0026#34;map\\\u0026#34;, \\\u0026#34;KeyType\\\u0026#34;: \\\u0026#34;HASH\\\u0026#34; }, { \\\u0026#34;AttributeName\\\u0026#34;: \\\u0026#34;open_timestamp\\\u0026#34;, \\\u0026#34;KeyType\\\u0026#34;: \\\u0026#34;RANGE\\\u0026#34; } ], \\\u0026#34;Projection\\\u0026#34;: { \\\u0026#34;ProjectionType\\\u0026#34;: \\\u0026#34;ALL\\\u0026#34; }, \\\u0026#34;ProvisionedThroughput\\\u0026#34;: { \\\u0026#34;ReadCapacityUnits\\\u0026#34;: 100, \\\u0026#34;WriteCapacityUnits\\\u0026#34;: 100 } } } ]\u0026#34; Nếu bạn chọn chạy lệnh AWS CLI, bạn sẽ thấy đầu ra như sau:\nLưu ý rằng trạng thái của bảng sẽ hiển thị là UPDATING và trạng thái của chỉ mục sẽ hiển thị là CREATING\n{ \u0026#34;TableDescription\u0026#34;: { \u0026#34;AttributeDefinitions\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;PK\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;SK\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;map\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;open_timestamp\u0026#34;, \u0026#34;AttributeType\u0026#34;: \u0026#34;S\u0026#34; } ], \u0026#34;TableName\u0026#34;: \u0026#34;battle-royale\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;PK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;SK\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], \u0026#34;TableStatus\u0026#34;: \u0026#34;UPDATING\u0026#34;, \u0026#34;CreationDateTime\u0026#34;: \u0026#34;2023-12-06T14:48:31.246000-06:00\u0026#34;, \u0026#34;ProvisionedThroughput\u0026#34;: { \u0026#34;NumberOfDecreasesToday\u0026#34;: 0, \u0026#34;ReadCapacityUnits\u0026#34;: 100, \u0026#34;WriteCapacityUnits\u0026#34;: 100 }, \u0026#34;TableSizeBytes\u0026#34;: 0, \u0026#34;ItemCount\u0026#34;: 0, \u0026#34;TableArn\u0026#34;: \u0026#34;arn:aws:dynamodb:\u0026lt;AWS Region\u0026gt;:\u0026lt;Account ID\u0026gt;:table/battle-royale\u0026#34;, \u0026#34;TableId\u0026#34;: \u0026#34;\u0026lt;Unique ID\u0026gt;\u0026#34;, \u0026#34;BillingModeSummary\u0026#34;: { \u0026#34;BillingMode\u0026#34;: \u0026#34;PROVISIONED\u0026#34;, \u0026#34;LastUpdateToPayPerRequestDateTime\u0026#34;: \u0026#34;2023-12-07T11:11:34.932000-06:00\u0026#34; }, \u0026#34;GlobalSecondaryIndexes\u0026#34;: [ { \u0026#34;IndexName\u0026#34;: \u0026#34;OpenGamesIndex\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ { \u0026#34;AttributeName\u0026#34;: \u0026#34;map\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34;: \u0026#34;open_timestamp\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], \u0026#34;Projection\u0026#34;: { \u0026#34;ProjectionType\u0026#34;: \u0026#34;ALL\u0026#34; }, \u0026#34;IndexStatus\u0026#34;: \u0026#34;CREATING\u0026#34;, \u0026#34;Backfilling\u0026#34;: false, \u0026#34;ProvisionedThroughput\u0026#34;: { \u0026#34;NumberOfDecreasesToday\u0026#34;: 0, \u0026#34;ReadCapacityUnits\u0026#34;: 100, \u0026#34;WriteCapacityUnits\u0026#34;: 100 }, \u0026#34;IndexSizeBytes\u0026#34;: 0, \u0026#34;ItemCount\u0026#34;: 0, \u0026#34;IndexArn\u0026#34;: \u0026#34;arn:aws:dynamodb:\u0026lt;AWS Region\u0026gt;:\u0026lt;Account ID\u0026gt;:table/battle-royale/index/OpenGamesIndex\u0026#34; } ], \u0026#34;DeletionProtectionEnabled\u0026#34;: false } } Sẽ mất vài phút để GSI mới được hoàn thiện. Bạn cần chờ cho đến khi GSI trở nên active. Bạn có thể kiểm tra trạng thái hiện tại của bảng và các chỉ mục của nó bằng cách:\nKiểm tra dưới mục Services, Database, DynamoDB trong AWS console.\nChạy lệnh sau trong Cloud9 Terminal:\naws dynamodb describe-table --table-name battle-royale --query \u0026#34;Table.GlobalSecondaryIndexes[].IndexStatus\u0026#34; Bạn cũng có thể viết lệnh để chạy tự động mỗi 5 giây bằng cách sử dụng watch.\n# Watch kiểm tra mỗi 5 giây theo mặc định watch -n 5 \u0026#34;aws dynamodb describe-table --table-name battle-royale --query \\\u0026#34;Table.GlobalSecondaryIndexes[].IndexStatus\\\u0026#34;\u0026#34; Nhấn Ctrl + C để dừng watch sau khi chỉ mục thứ cấp toàn cục đã được tạo.\nHy vọng bản dịch này giúp bạn dễ dàng hơn trong việc thực hiện quy trình trên.\n"
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.3/2.3.2/",
	"title": "Tạo Zero-ETL Pipeline",
	"tags": [],
	"description": "",
	"content": "Amazon DynamoDB cung cấp tích hợp zero-ETL với Amazon OpenSearch Service thông qua plugin DynamoDB cho OpenSearch Ingestion. Amazon OpenSearch Ingestion cung cấp một trải nghiệm không cần mã (no-code) được quản lý hoàn toàn để nhập dữ liệu vào Amazon OpenSearch Service.\nMở OpenSearch Service Ingestion Pipelines\nNhấp vào \u0026ldquo;Create pipeline\u0026rdquo;\nĐặt tên cho pipeline của bạn và bao gồm cấu hình sau cho pipeline. Cấu hình này chứa nhiều giá trị cần được cập nhật. Các giá trị cần thiết được cung cấp trong phần Outputs của CloudFormation Stack với tên \u0026ldquo;Region\u0026rdquo;, \u0026ldquo;Role\u0026rdquo;, \u0026ldquo;S3Bucket\u0026rdquo;, \u0026ldquo;DdbTableArn\u0026rdquo;, và \u0026ldquo;OSDomainEndpoint\u0026rdquo;.\nversion: \u0026#34;2\u0026#34; dynamodb-pipeline: source: dynamodb: acknowledgments: true tables: # BẮT BUỘC: Cung cấp ARN của bảng DynamoDB - table_arn: \u0026#34;{DDB_TABLE_ARN}\u0026#34; stream: start_position: \u0026#34;LATEST\u0026#34; export: # BẮT BUỘC: Chỉ định tên của một S3 bucket đã tồn tại để DynamoDB ghi các tệp dữ liệu xuất vào s3_bucket: \u0026#34;{S3BUCKET}\u0026#34; # BẮT BUỘC: Chỉ định khu vực của S3 bucket s3_region: \u0026#34;{REGION}\u0026#34; # Tùy chọn thiết lập tên của một tiền tố mà các tệp dữ liệu xuất của DynamoDB được ghi vào trong bucket. s3_prefix: \u0026#34;pipeline\u0026#34; aws: # BẮT BUỘC: Cung cấp vai trò có các quyền cần thiết cho DynamoDB, OpenSearch và S3. sts_role_arn: \u0026#34;{ROLE}\u0026#34; # BẮT BUỘC: Cung cấp khu vực region: \u0026#34;{REGION}\u0026#34; sink: - opensearch: hosts: # BẮT BUỘC: Cung cấp một endpoint AWS OpenSearch, bao gồm cả https:// [ \u0026#34;{OS_DOMAIN_ENDPOINT}\u0026#34; ] index: \u0026#34;product-details-index-en\u0026#34; index_type: custom template_type: \u0026#34;index-template\u0026#34; template_content: | { \u0026#34;template\u0026#34;: { \u0026#34;settings\u0026#34;: { \u0026#34;index.knn\u0026#34;: true, \u0026#34;default_pipeline\u0026#34;: \u0026#34;product-en-nlp-ingest-pipeline\u0026#34; }, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;ProductID\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, \u0026#34;ProductName\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;Category\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;Description\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;Image\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;combined_field\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;product_embedding\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;knn_vector\u0026#34;, \u0026#34;dimension\u0026#34;: 1536, \u0026#34;method\u0026#34;: { \u0026#34;engine\u0026#34;: \u0026#34;nmslib\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;hnsw\u0026#34;, \u0026#34;space_type\u0026#34;: \u0026#34;l2\u0026#34; } } } } } } aws: # BẮT BUỘC: Cung cấp vai trò có các quyền cần thiết cho DynamoDB, OpenSearch và S3. sts_role_arn: \u0026#34;{ROLE}\u0026#34; # BẮT BUỘC: Cung cấp khu vực region: \u0026#34;{REGION}\u0026#34; Dưới phần Network, chọn \u0026ldquo;Public access\u0026rdquo;, sau đó nhấp vào \u0026ldquo;Next\u0026rdquo;.\nNhấp vào \u0026ldquo;Create pipeline\u0026rdquo;.\nChờ cho đến khi pipeline được tạo xong. Điều này sẽ mất khoảng 5 phút hoặc hơn.\nSau khi pipeline được tạo, sẽ mất thêm một thời gian để thực hiện xuất ban đầu từ DynamoDB và nhập vào OpenSearch Service. Sau khi bạn chờ thêm vài phút, bạn có thể kiểm tra xem các mục đã được nhân bản vào OpenSearch hay chưa bằng cách thực hiện truy vấn trong Dev Tools trên OpenSearch Dashboards.\nĐể mở Dev Tools, nhấp vào menu ở góc trên bên trái của OpenSearch Dashboards, cuộn xuống phần Management, sau đó nhấp vào Dev Tools. Nhập truy vấn sau vào ngăn bên trái, sau đó nhấp vào mũi tên \u0026ldquo;play\u0026rdquo;.\nGET /product-details-index-en/_search Bạn có thể gặp phải một số loại kết quả:\nNếu bạn thấy lỗi 404 loại index_not_found_exception, thì bạn cần đợi cho đến khi pipeline ở trạng thái Active. Khi đó, lỗi này sẽ biến mất. Nếu truy vấn của bạn không có kết quả, hãy chờ thêm vài phút cho quá trình nhân bản ban đầu hoàn tất và thử lại. Chỉ tiếp tục khi bạn thấy kết quả như trên, với nội dung phản hồi. Kết quả tìm kiếm có thể khác nhau.\n"
},
{
	"uri": "//localhost:1313/vi/6-leda/6.2/",
	"title": "Tổng quan",
	"tags": [],
	"description": "",
	"content": "Kiến trúc Sau khi thiết lập, hầu hết các thành phần của pipeline tổng hợp dữ liệu đã được cài đặt sẵn cho bạn, như minh họa trong sơ đồ dưới đây. Tuy nhiên, một số liên kết giữa các thành phần liền kề bị thiếu hoặc cấu hình sai! Những kết nối này là trọng tâm của vấn đề mà bạn cần giải quyết.\nWorkshop này bao gồm hai bài thực hành. Mục tiêu của bài thực hành đầu tiên là thiết lập các kết nối giữa các thành phần này và đạt được xử lý dữ liệu đầu cuối, từ IncomingDataStream (Luồng dữ liệu đầu vào) ở bên trái đến AggregateTable (Bảng tổng hợp) ở cuối pipeline.\nTuy nhiên, pipeline mà bạn xây dựng trong bài thực hành đầu tiên không đảm bảo xử lý tin nhắn chính xác từng lần. Do đó, việc đảm bảo xử lý chính xác từng lần là mục tiêu của Bài thực hành 2.\nBài thực hành 1 Sơ đồ dưới đây phác thảo một tập hợp các bước mà bạn cần thực hiện để kết nối tất cả các tài nguyên AWS. Phần Bài thực hành 1 sẽ cung cấp cho bạn thêm thông tin và giải thích cách thực hiện từng bước.\nBài thực hành 2 Trong Bài thực hành 2, chúng ta sẽ nâng cao pipeline để đảm bảo xử lý chính xác từng lần cho bất kỳ tin nhắn nào được nạp vào. Để đảm bảo rằng pipeline của chúng ta có thể chịu đựng các chế độ lỗi khác nhau và đạt được xử lý tin nhắn chính xác từng lần, chúng ta sẽ sửa đổi hai hàm Lambda.\nPhần Bài thực hành 2 sẽ cung cấp cho bạn thêm thông tin và giải thích cách thực hiện từng bước. Bước tiếp theo và cạnh tranh Phần Đi sâu vào Pipeline với ví dụ chứa một giải thích chi tiết về cách dữ liệu được xử lý trong pipeline này. Thông tin này được khuyến khích xem qua nhưng không bắt buộc để hoàn thành workshop.\nĐể làm cho workshop này thêm phần thú vị, khi được thực hiện tại một sự kiện AWS, tất cả các người tham gia sẽ được xếp hạng dựa trên số lượng tin nhắn họ có thể tổng hợp chính xác bằng bảng điểm. Phần Luật chơi phác thảo các quy tắc của trò chơi và cách hàm GeneratorLambda nạp dữ liệu vào đầu pipeline!\nTiếp tục đến: Luật chơi.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.2/",
	"title": "Tổng quan kịch bản",
	"tags": [],
	"description": "",
	"content": "Hãy tưởng tượng bạn có một trang web thương mại điện tử nơi khách hàng đặt hàng cho các mặt hàng khác nhau. Trang web này dựa vào Amazon DynamoDB và yêu cầu ghi lại tất cả các sự kiện từ khi một đơn hàng được đặt cho đến khi mặt hàng được giao.\nYêu cầu của trang web:\nTrạng thái của các đơn hàng đặt trên trang web của bạn có thể là ACTIVE, PLACED, COMPLETE, hoặc CANCELLED. Bạn cần giữ bản hiện tại của các đơn hàng của khách hàng trên bảng cơ sở dữ liệu chính được sử dụng bởi ứng dụng của bạn. Mỗi đơn hàng có thuộc tính status và chứa danh sách một hoặc nhiều mặt hàng. Dưới định dạng JSON, một mục trong bảng đơn hàng có các thuộc tính sau:\n{ \u0026#34;id\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;customer\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;orderDate\u0026#34;: \u0026#34;YYYY-MM-DD hh:mm:ss\u0026#34;, \u0026#34;shipDate\u0026#34;: \u0026#34;YYYY-MM-DD hh:mm:ss\u0026#34;, \u0026#34;items\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;price\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;quantity\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;string\u0026#34; } ] } Bạn sẽ triển khai một giải pháp để đáp ứng yêu cầu này bằng cách sử dụng hai bảng DynamoDB - Orders và OrdersHistory; và một giải pháp streaming để sao chép các thay đổi cấp mục từ bảng Orders sang bảng OrdersHistory.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.6/7.6.2/",
	"title": "Truy xuất trò chơi cho người dùng",
	"tags": [],
	"description": "",
	"content": "Bây giờ bạn đã tạo chỉ mục đảo ngược, hãy sử dụng nó để truy xuất các thực thể Game mà một User đã chơi. Để xử lý điều này, bạn cần truy vấn chỉ mục đảo ngược với User mà bạn muốn xem các thực thể Game của họ.\nTrong mã bạn đã tải xuống, tệp script find_games_for_user.py nằm trong thư mục scripts/.\nimport sys import boto3 from entities import UserGameMapping dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) USERNAME = sys.argv[1] if len(sys.argv) == 2 else \u0026#34;carrpatrick\u0026#34; def find_games_for_user(username): try: resp = dynamodb.query( TableName=\u0026#39;battle-royale\u0026#39;, IndexName=\u0026#39;InvertedIndex\u0026#39;, KeyConditionExpression=\u0026#34;SK = :sk\u0026#34;, ExpressionAttributeValues={ \u0026#34;:sk\u0026#34;: { \u0026#34;S\u0026#34;: f\u0026#34;USER#{username}\u0026#34; } }, ScanIndexForward=True ) except Exception as e: print(\u0026#39;Chỉ mục vẫn đang trong quá trình backfilling. Vui lòng thử lại sau.\u0026#39;) return None return [UserGameMapping(item) for item in resp[\u0026#39;Items\u0026#39;]] games = find_games_for_user(USERNAME) if games: print(f\u0026#34;Các game đã chơi bởi người dùng {USERNAME}:\u0026#34;) for game in games: print(game) Trong script này, bạn có một hàm gọi là find_games_for_user() tương tự như một hàm bạn sẽ có trong ứng dụng game của mình. Hàm này nhận tên người dùng và trả về tất cả các game mà người dùng đã chơi.\nChạy script trong terminal của bạn với lệnh sau:\npython scripts/find_games_for_user.py Script sẽ in ra tất cả các game đã được chơi bởi người dùng carrpatrick.\nCác game đã chơi bởi người dùng carrpatrick: UserGameMapping: 25cec5bf-e498-483e-9a00-a5f93b9ea7c7 Username: carrpatrick Place: SILVER UserGameMapping: c6f38a6a-d1c5-4bdf-8468-24692ccc4646 Username: carrpatrick UserGameMapping: c9c3917e-30f3-4ba4-82c4-2e9a0e4d1cfd Username: carrpatrick Bạn có thể chạy script cho những người dùng khác bằng cách thêm tên người dùng của họ làm tham số dòng lệnh.\nThử chạy script một lần nữa và tìm các game cho người dùng vlopez:\npython scripts/find_games_for_user.py vlopez Đầu ra sẽ trông như thế này:\nCác game đã chơi bởi người dùng vlopez: UserGameMapping: c6f38a6a-d1c5-4bdf-8468-24692ccc4646 Username: vlopez Tóm tắt Trong module này, bạn đã thỏa mãn mẫu truy cập cuối cùng bằng cách truy xuất tất cả các thực thể Game mà một User đã chơi. Để xử lý mẫu truy cập này, bạn đã tạo một chỉ mục thứ cấp sử dụng mẫu chỉ mục đảo ngược để cho phép truy vấn mối quan hệ nhiều-nhiều giữa các thực thể User và Game.\n"
},
{
	"uri": "//localhost:1313/vi/6-leda/6.2/6.2.1/",
	"title": "Tùy chọn - Pipeline Deep Dive",
	"tags": [],
	"description": "",
	"content": " Hiểu cách pipeline hoạt động bên trong được khuyến nghị, tuy nhiên việc đọc trang này không bắt buộc để hoàn thành workshop.\nPhần này giải thích chi tiết cách pipeline hoạt động từ đầu đến cuối. Để có một giải thích đơn giản hơn, tham khảo hình minh họa dưới đây, trong đó chúng tôi chia pipeline thành ba giai đoạn. Đối với mỗi giai đoạn, chúng tôi mô tả đầu vào và đầu ra của giai đoạn.\nGiai đoạn 1: \u0026lsquo;State\u0026rsquo; (Trạng thái) Vấn đề kinh doanh của việc tổng hợp dữ liệu gần như thời gian thực đang được khách hàng đối mặt trong nhiều ngành công nghiệp khác nhau như sản xuất, bán lẻ, trò chơi, tiện ích, và dịch vụ tài chính. Trong workshop này, chúng tôi tập trung vào ngành ngân hàng, và cụ thể là vấn đề tổng hợp rủi ro giao dịch gần như thời gian thực. Thông thường, các tổ chức tài chính liên kết mỗi giao dịch được thực hiện trên sàn giao dịch với một giá trị rủi ro, và bộ phận quản lý rủi ro của ngân hàng cần có cái nhìn nhất quán về tổng giá trị rủi ro được tổng hợp từ tất cả các giao dịch. Trong workshop này, chúng tôi sử dụng cấu trúc sau cho các thông điệp rủi ro:\n{ \u0026#34;RiskMessage\u0026#34;: { \u0026#34;TradeID\u0026#34; : \u0026#34;0d957268-2913-4dbb-b359-5ec5ff732cac\u0026#34;, \u0026#34;Value\u0026#34; : 34624.51, \u0026#34;Version\u0026#34; : 3, \u0026#34;Timestamp\u0026#34; : 1616413258.8997078, \u0026#34;Hierarchy\u0026#34; : {\u0026#34;RiskType\u0026#34;: \u0026#34;Delta\u0026#34;, \u0026#34;Region\u0026#34;: \u0026#34;AMER\u0026#34;, \u0026#34;TradeDesk\u0026#34;: \u0026#34;FXSpot\u0026#34;} } } TradeID: Mã định danh duy nhất cho mỗi thông điệp giao dịch. Value: Giá trị rủi ro (tiền tệ) liên quan đến giao dịch này. Version: Giá trị rủi ro của một giao dịch đôi khi cần phải được sửa đổi ở giai đoạn sau. Thuộc tính này theo dõi phiên bản mới nhất được biết của một giao dịch cụ thể. Timestamp: Thời gian khi giao dịch xảy ra. Hierarchy: Danh sách các thuộc tính liên quan đến giao dịch này. Để mở rộng, điều này bao gồm loại rủi ro, khu vực nơi giao dịch diễn ra, và loại bàn giao dịch thực hiện giao dịch. Những thuộc tính này sẽ được sử dụng để nhóm các giao dịch và tổng hợp dữ liệu. Hãy xem xét một ví dụ khi năm thông điệp rủi ro được nạp vào pipeline, như minh họa trong hình dưới đây. Để dễ hiểu, chúng tôi đã gắn nhãn mỗi thông điệp với một mã định danh từ M1 đến M5. Mỗi thông điệp có một TradeID duy nhất, một giá trị rủi ro Value, và một nhóm thuộc tính phân cấp (như đã giải thích ở trên). Để đơn giản hóa, tất cả các thông điệp có RiskType là \u0026quot;Delta\u0026quot; và thuộc tính Version luôn được đặt là 1.\nPipeline được điều khiển bởi một nguồn dữ liệu đầu vào ghi các bản ghi vào Kinesis Data Stream, và hàm StateLambda được kích hoạt để xử lý các thông điệp này.\nDo tỷ lệ xuất hiện của thông điệp có thể rất cao, nhiều hàm StateLambda sẽ được gọi đồng thời. Điều này có nghĩa là nhiều phiên bản của hàm StateLambda sẽ chạy cùng lúc, mỗi phiên bản xử lý một tập hợp con của các bản ghi. Để tìm hiểu thêm về việc mở rộng hàm Lambda, hãy xem trang tài liệu về mở rộng hàm AWS Lambda, giải thích khái niệm về một phiên bản Lambda. Ví dụ trên cho thấy việc gọi hai phiên bản hàm StateLambda được gắn nhãn là #1 và #2. Phiên bản #1 xử lý thông điệp M1 và M2, trong khi phiên bản #2 xử lý thông điệp M3, M4, và M5.\nTrách nhiệm của hàm StateLambda là bảo tồn tất cả các thông điệp đầu vào bằng cách ghi chúng vào DynamoDB StateTable, và hơn nữa để đảm bảo xử lý chính xác từng lần bằng cách theo dõi mã ID duy nhất của mỗi thông điệp đã được xử lý ở giai đoạn này. Trong ví dụ này, cả hai hàm StateLambda đều ghi các thông điệp tương ứng của chúng vào DynamoDB StateTable. StateTable ở phía dưới của hình lưu trữ các thông điệp rủi ro đầu vào mà không có sửa đổi đáng kể.\nGiai đoạn 2: \u0026lsquo;Reduce\u0026rsquo; (Giảm) Trong Giai đoạn 2, tất cả các hàng được ghi vào StateTable được gửi đến MapLambda để xử lý thêm thông qua một ánh xạ nguồn sự kiện kết nối hàm với luồng DynamoDB của StateTable. DynamoDB Streams đảm bảo rằng mỗi thay đổi mục xuất hiện chính xác một lần, và tất cả các thay đổi đối với một mục cho trước xuất hiện trong các shard luồng theo thứ tự chúng được ghi. Tuy nhiên, nhiều hàm StateLambda ghi vào các khóa khác nhau trong StateTable, và do đó các bản ghi luồng trong luồng bảng có thể không theo thứ tự như thứ tự mà chúng được nạp vào ở Giai đoạn 1.\nĐể xử lý lượng lớn thông điệp đầu vào, nhiều phiên bản MapLambda được gọi để xử lý các thông điệp từ luồng DynamoDB StateTable, tương tự như Giai đoạn 1. Trong ví dụ này, MapLambda #1 lấy các thông điệp M4, M3, và M1 trong khi MapLambda #2 xử lý các thông điệp M5 và M2.\nTrách nhiệm của MapLambda là thực hiện sự tổng hợp ban đầu của các thông điệp, hay cụ thể hơn là thực hiện phép cộng số học dựa trên các thuộc tính thông điệp. Kết quả đầu ra đã được tổng hợp của mỗi hàm MapLambda được ghi vào ReduceTable dưới dạng một hàng duy nhất, như đã thấy trong \u0026ldquo;Trạng thái đầu ra của ReduceTable\u0026rdquo; trong hình trên. Để đơn giản hóa, chúng tôi gọi các hàng này là AM1 và AM2.\nTổng hợp ban đầu hoạt động như thế nào? Hãy xem xét hàng thứ hai, AM2, kết hợp các thông điệp M2 và M5. Dựa trên các thuộc tính thông điệp, thông điệp M2 thuộc về Delta::EMEA::FXSpot, trong khi thông điệp M5 thuộc về Delta::AMER::FXSpot. Điểm chung cho các giao dịch này là cả hai đều thuộc loại rủi ro Delta. Do đó, thuộc tính Delta trong ReduceTable là tổng của cả hai thông điệp, được biểu thị là 100 + 20 = 120. Dưới đây là các thông điệp M2 và M5 ở định dạng JSON để tham khảo.\n{\u0026#34;TradeID\u0026#34; : \u0026#34;8ec2fdcd\u0026#34;, \u0026#34;Value\u0026#34;: 100, \u0026#34;Version\u0026#34;: 1, \u0026#34;Hierarchy\u0026#34; : {\u0026#34;RiskType\u0026#34;: \u0026#34;Delta\u0026#34;, \u0026#34;Region\u0026#34;: \u0026#34;EMEA\u0026#34;, \u0026#34;TradeDesk\u0026#34;: \u0026#34;FXSpot\u0026#34;} } {\u0026#34;TradeID\u0026#34; : \u0026#34;395974a4\u0026#34;, \u0026#34;Value\u0026#34;: 20, \u0026#34;Version\u0026#34;: 1, \u0026#34;Hierarchy\u0026#34; : {\u0026#34;RiskType\u0026#34;: \u0026#34;Delta\u0026#34;, \u0026#34;Region\u0026#34;: \u0026#34;AMER\u0026#34;, \u0026#34;TradeDesk\u0026#34;: \u0026#34;FXSpot\u0026#34;} } Giai đoạn 3: \u0026lsquo;Aggregate\u0026rsquo; (Tổng hợp) Trong Giai đoạn 3, tất cả các hàng được ghi vào ReduceTable được gửi đến ReduceLambda để xử lý thêm thông qua DynamoDB Streams. Trách nhiệm của ReduceLambda là kết hợp thêm các thông điệp đã tổng hợp ban đầu và cập nhật giá trị cuối cùng trong AggregateTable.\nĐiều này được thực hiện trong ba bước:\nHàm ReduceLambda được gọi với một lô thông điệp và đọc trạng thái hiện tại từ AggregateTable Hàm tính toán lại tổng hợp dựa trên lô mục đã tổng hợp trước đó Hàm giảm viết các giá trị đã cập nhật vào AggregateTable Lưu ý: chỉ có một phiên bản của hàm ReduceLambda, được đạt được bằng cách đặt đồng thời dự trữ thành 1. Điều này là mong muốn để tránh xung đột ghi tiềm ẩn khi cập nhật AggregateTable. Từ góc độ hiệu suất, một phiên bản hàm Lambda duy nhất có thể xử lý việc tổng hợp toàn bộ pipeline vì các thông điệp đầu vào đã được tổng hợp trước bởi các hàm MapLambda.\nKết quả cuối cùng trong AggregateTable giống như các yếu tố thuộc tính Hierarchy, và có thể dễ dàng đọc và hiển thị bởi một giao diện người dùng!\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.2/7.2.2/",
	"title": "Xây dựng entity-relationship diagram của bạn",
	"tags": [],
	"description": "",
	"content": "Bước đầu tiên của bất kỳ bài tập mô hình hóa dữ liệu nào là xây dựng một sơ đồ để hiển thị các thực thể trong ứng dụng của bạn và cách chúng liên quan với nhau.\nTrong ứng dụng này, bạn có các thực thể sau:\nUser\nGame\nUserGameMapping\nThực thể User đại diện cho một người dùng trong ứng dụng. Một người dùng có thể tạo nhiều thực thể Game, và người tạo trò chơi sẽ quyết định bản đồ nào được chơi và khi nào trò chơi bắt đầu. Một User có thể tạo nhiều thực thể Game, vì vậy có một mối quan hệ một-nhiều giữa Users và Games.\nCuối cùng, một Game chứa nhiều Users và một User có thể chơi trong nhiều Games khác nhau theo thời gian.\nDo đó, có một mối quan hệ nhiều-nhiều giữa Users và Games. Bạn có thể biểu diễn mối quan hệ này bằng thực thể UserGameMapping.\nVới các thực thể và mối quan hệ này, sơ đồ thực thể-mối quan hệ (ERD) được hiển thị dưới đây.\nTiếp theo, chúng ta sẽ xem xét các mẫu truy cập mà mô hình dữ liệu cần hỗ trợ.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.3/",
	"title": "Bài tập 2: Sequential và Parallel Table Scans",
	"tags": [],
	"description": "",
	"content": "Bài tập này minh họa hai phương pháp quét bảng DynamoDB: tuần tự và song song.\nMặc dù DynamoDB phân phối các mục trên nhiều phân vùng vật lý, một thao tác Scan chỉ có thể đọc một phân vùng tại một thời điểm. Để tìm hiểu thêm, hãy đọc trang tài liệu của chúng tôi về phân vùng và phân phối dữ liệu. Vì lý do này, thông lượng của một thao tác Scan bị giới hạn bởi thông lượng tối đa của một phân vùng đơn lẻ.\nĐể tối đa hóa việc sử dụng dung lượng cấp phát ở mức bảng, hãy sử dụng Scan song song để chia bảng (hoặc chỉ mục phụ) thành nhiều đoạn logic và sử dụng nhiều worker của ứng dụng để quét các đoạn logic này song song. Mỗi worker của ứng dụng có thể là một luồng (thread) trong các ngôn ngữ lập trình hỗ trợ đa luồng (multithreading) hoặc một tiến trình (process) của hệ điều hành. Để tìm hiểu thêm về cách triển khai quét song song, hãy đọc trang tài liệu dành cho nhà phát triển về quét song song của chúng tôi. API Scan không phù hợp với tất cả các mô hình truy vấn, và để biết thêm thông tin về lý do tại sao quét kém hiệu quả hơn truy vấn, vui lòng đọc về tác động hiệu suất của Scan trong tài liệu của chúng tôi.\nSơ đồ dưới đây cho thấy cách một ứng dụng đa luồng thực hiện một Scan song song với ba luồng worker ứng dụng. Ứng dụng tạo ra ba luồng và mỗi luồng gửi một yêu cầu Scan, quét đoạn được chỉ định của nó, lấy dữ liệu mỗi lần 1 MB, và trả dữ liệu về cho luồng chính của ứng dụng.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.1/3.1.3/",
	"title": "Bước 2 - Kiểm tra cài đặt Python và AWS CLI",
	"tags": [],
	"description": "",
	"content": "Chạy lệnh sau để kiểm tra Python trên phiên bản EC2 của bạn:\n#Check the python version: python --version Ra:\nPython 3.10.12 Lưu ý: Phiên bản chính và phụ của Python có thể khác với những gì bạn thấy ở trên\nChạy lệnh sau để kiểm tra AWS CLI trên phiên bản EC2 của bạn:\n#Check the AWS CLI version. aws --version Đầu ra mẫu:\n#Note that your linux kernel version may differ from the example. aws-cli/2.13.26 Python/3.11.6 Linux/6.2.0-1013-aws exe/x86_64.ubuntu.22 prompt/off Đảm bảo bạn có AWS CLI phiên bản 2.x trở lên và python 3.10 trở lên trước khi tiếp tục. Nếu bạn không có các phiên bản này, bạn có thể gặp khó khăn trong việc hoàn thành thành công phòng thí nghiệm.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.6/3.6.3/",
	"title": "Bước 3 - Quét bảng employees để tìm người quản lý bằng cách sử dụng sparse global secondary index",
	"tags": [],
	"description": "",
	"content": "Bước 3 - Quét bảng employees để tìm quản lý bằng cách sử dụng sparse global secondary index Bây giờ, hãy quét chỉ mục phụ toàn cầu mới GSI_2 trên bảng employees. Khi sử dụng chỉ mục thưa mới, chúng ta kỳ vọng sẽ tiêu thụ ít đơn vị dung lượng đọc hơn cho các mục. Chúng ta sẽ sử dụng sparse index như một bộ lọc rất hiệu quả để cải thiện hiệu suất cho mẫu truy cập này.\nresponse = table.scan( Limit=pageSize, IndexName=\u0026#39;GSI_2\u0026#39; ) Chạy lệnh AWS CLI sau để thực hiện thao tác quét này bằng sparse index.\npython scan_for_managers_gsi.py employees 100 Tham số:\nTên bảng = employees Kích thước trang = 100 (đây là kích thước phân trang cho thao tác quét). Kết quả đầu ra bao gồm số lượng mục đã quét và thời gian thực thi.\nNumber of managers: 84. # of records scanned: 84. Execution time: 0.287754058838 seconds Quan sát số lượng mục đã quét và thời gian thực thi khi sử dụng sparse index. So sánh điều này với kết quả đạt được từ thao tác quét trên bảng cơ sở trong Bước 2. Sparse index có ít dữ liệu hơn và hiệu quả hơn.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.2/3.2.3/",
	"title": "Bước 3 - Tải tệp lớn hơn để so sánh thời gian thực thi",
	"tags": [],
	"description": "",
	"content": "Chạy lại tập lệnh, nhưng lần này sử dụng tệp dữ liệu đầu vào lớn hơn.\npython load_logfile.py logfile ./data/logfile_medium1.csv Tham số: 1) Tên bảng = 2) Tên tệp = logfile``logfile_medium1.csv\nĐầu ra sẽ giống như sau. Nó sẽ chạy chậm hơn về cuối và mất từ một đến ba phút để hoàn thành, tùy thuộc vào tốc độ bạn chạy lệnh này sau Bước 2.\nrow: 100 in 0.490761995316 ... row: 2000 in 3.188856363296509 RowCount: 2000, Total seconds: 75.0764648914 HOẶC:\nrow: 100 in 0.490761995316 ... row: 2000 in 18.479122161865234 RowCount: 2000, Total seconds: 133.84829711914062 Xem xét kết quả đầu ra: Bạn sẽ nhận thấy rằng thời gian tải cho mỗi lô 100 hàng thường xuyên vượt quá năm giây. Điều này xảy ra vì trong mỗi lô kéo dài nhiều giây, bạn đang thấy các giới hạn (throttles) khiến SDK Boto3 giảm tốc độ chèn dữ liệu (còn được gọi là exponential backoff - giãn cách theo cấp số nhân). SDK Boto3 đang chờ DynamoDB bổ sung dung lượng cho bảng DynamoDB, việc này xảy ra mỗi giây đối với các bảng có thông lượng được cấp phát. Trong Amazon CloudWatch, các giới hạn này xuất hiện dưới tên chỉ số WriteThrottleEvents.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.9/3.9.3/",
	"title": "Bước 3 - Tạo hàm Lambda",
	"tags": [],
	"description": "",
	"content": "Hàm AWS Lambda này sẽ được gắn vào DynamoDB Stream của bảng logfile để sao chép các thao tác thêm (put) và xóa (delete) mục vào bảng logfile_replica. Mã hàm Lambda đã được cung cấp cho bạn trong tệp ddbreplica_lambda.py. Bạn có thể xem nội dung của script nếu muốn với vim hoặc less.\nNén nội dung của script. Chúng ta sẽ tải nó lên AWS Lambda khi tạo hàm.\nzip ddbreplica_lambda.zip ddbreplica_lambda.py lab_config.py Lấy Amazon Resource Name (ARN) của vai trò IAM đã được tạo sẵn để bạn có thể liên kết nó với hàm Lambda. Chạy lệnh sau để lấy ARN của vai trò được tạo trong quá trình thiết lập lab.\ncat ~/workshop/ddb-replication-role-arn.txt Kết quả đầu ra sẽ trông giống như sau:\narn:aws:iam::\u0026lt;ACCOUNTID\u0026gt;:role/XXXXX-DDBReplicationRole-XXXXXXXXXXX Bây giờ, chạy lệnh sau để tạo hàm Lambda.\naws lambda create-function \\ --function-name ddbreplica_lambda --zip-file fileb://ddbreplica_lambda.zip \\ --handler ddbreplica_lambda.lambda_handler --timeout 60 --runtime python3.7 \\ --description \u0026#34;Sample lambda function for dynamodb streams\u0026#34; \\ --role $(cat ~/workshop/ddb-replication-role-arn.txt) "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.5/3.5.3/",
	"title": "Bước 3 - Truy vấn bảng nhân viên bằng cách sử dụng global secondary index với các thuộc tính quá tải",
	"tags": [],
	"description": "",
	"content": "Bạn có thể truy vấn tất cả nhân viên làm việc tại bang Washington (WA) ở Hoa Kỳ bằng cách chạy script query_employees.py sau đây, bao gồm mã để truy vấn một bảng bằng cách sử dụng phương pháp nạp chồng chỉ mục phụ toàn cầu.\nif attribute == \u0026#39;name\u0026#39;: ke = Key(\u0026#39;GSI_1_PK\u0026#39;).eq(\u0026#39;root\u0026#39;) \u0026amp; Key(\u0026#39;GSI_1_SK\u0026#39;).eq(value) else: ke = Key(\u0026#39;GSI_1_PK\u0026#39;).eq(attribute + \u0026#34;#\u0026#34; + value) response = table.query( IndexName=\u0026#39;GSI_1\u0026#39;, KeyConditionExpression=ke ) Chạy script Python sau để truy xuất các nhân viên làm việc tại bang Washington (WA).\npython query_employees.py employees state \u0026#39;WA\u0026#39; Script sẽ cho bạn kết quả như sau:\nList of employees with WA in the attribute state: Employee name: Alice Beilby - hire date: 2014-12-03 Employee name: Alla Absalom - hire date: 2015-06-25 Employee name: Alvan Heliar - hire date: 2016-05-15 Employee name: Anders Galtone - hire date: 2015-12-22 Employee name: Ashil Hutchin - hire date: 2015-02-11 ... Employee name: Sula Prattin - hire date: 2014-01-11 Employee name: Vittoria Edelman - hire date: 2014-10-01 Employee name: Willie McCuthais - hire date: 2015-05-27 Total of employees: 46. Execution time: 0.13477110862731934 seconds Bạn có thể thử truy vấn một bang khác của Hoa Kỳ bằng cách thay đổi tham số cuối cùng của lệnh. Lệnh sau truy vấn tất cả nhân viên làm việc tại bang Texas.\npython query_employees.py employees state \u0026#39;TX\u0026#39; Nếu bạn muốn truy vấn các bang khác, hãy nhấp vào đây để mở danh sách các bang của Hoa Kỳ có dữ liệu trong bảng.\nSử dụng cùng truy vấn này, bạn có thể truy vấn nhân viên theo chức danh công việc. Chạy lệnh sau làm ví dụ.\npython query_employees.py employees current_title \u0026#39;Software Engineer\u0026#39; Lệnh trên sẽ cho bạn kết quả sau:\nList of employees with Software Engineer in the attribute current_title: Employee name: Alice Beilby - hire date: 2014-11-03 Employee name: Anetta Byrne - hire date: 2017-03-15 Employee name: Ardis Panting - hire date: 2015-08-06 Employee name: Chris Randals - hire date: 2016-10-27 Employee name: Constantine Barendtsen - hire date: 2016-06-10 Employee name: Eudora Janton - hire date: 2015-01-05 Employee name: Florella Allsep - hire date: 2015-03-31 Employee name: Horatius Trangmar - hire date: 2013-10-21 Employee name: Korey Daugherty - hire date: 2016-11-03 Employee name: Lenka Luquet - hire date: 2014-10-01 Employee name: Leonora Hyland - hire date: 2016-06-14 Employee name: Lucretia Ruffell - hire date: 2015-07-04 Employee name: Malcolm Adiscot - hire date: 2014-04-17 Employee name: Melodie Sebire - hire date: 2013-08-27 Employee name: Menard Ogborn - hire date: 2014-06-27 Employee name: Merwyn Petters - hire date: 2014-06-19 Employee name: Niels Buston - hire date: 2014-10-30 Employee name: Noelani Studde - hire date: 2015-03-30 Total of employees: 18. Execution time: 0.11937260627746582 seconds Bạn cũng có thể thử một chức danh khác, như trong lệnh Python sau.\npython query_employees.py employees current_title \u0026#39;IT Support Manager\u0026#39; Nếu bạn muốn biết danh sách tất cả các chức danh có sẵn, nhấp vào đây!\nSử dụng cùng truy vấn với một thay đổi nhỏ, bạn có thể truy vấn nhân viên theo tên, như trong lệnh sau.\npython query_employees.py employees name \u0026#39;Dale Marlin\u0026#39; Lệnh trên sẽ cho bạn kết quả sau:\nList of employees with Dale Marlin in the attribute name: Employee name: Dale Marlin - hire date: 2014-10-19 Total of employees: 1. Execution time: 0.1274700164794922 seconds Tóm tắt Chúc mừng, bạn đã hoàn thành bài tập này và minh họa cách thiết kế nạp chồng khóa chỉ mục phụ toàn cầu có thể hỗ trợ nhiều mẫu truy cập. Sử dụng mẫu này để phù hợp với các loại thực thể khác nhau trong cùng một bảng DynamoDB và giữ khả năng truy vấn dữ liệu trên các khóa phân vùng khác nhau với chỉ mục phụ toàn cầu. Trong bài tập tiếp theo, bạn sẽ tìm hiểu về Sparse Global Secondary Indexes!\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.8/3.8.3/",
	"title": "Bước 3 - Truy vấn chi tiết hóa đơn của bảng",
	"tags": [],
	"description": "",
	"content": "Chạy tập lệnh sau để truy vấn chi tiết hóa đơn của bảng.\npython query_invoiceandbilling.py InvoiceAndBills \u0026#39;I#1420\u0026#39; ========================================================= Invoice ID:I#1420, BillID:B#2485, BillAmount:$135,986.00 , BillBalance:$28,322,352.00 Invoice ID:I#1420, BillID:B#2823, BillAmount:$592,769.00 , BillBalance:$8,382,270.00 Invoice ID:I#1420, Customer ID:C#1420 Invoice ID:I#1420, InvoiceStatus:Cancelled, InvoiceBalance:$28,458,338.00 , InvoiceDate:10/31/17, InvoiceDueDate:11/20/17 ========================================================= Xem lại chi tiết hóa đơn, chi tiết khách hàng và chi tiết hóa đơn. Lưu ý cách kết quả hiển thị mối quan hệ giữa ID hóa đơn, ID khách hàng và thực thể ID hóa đơn.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.7/3.7.3/",
	"title": "Bước 3 - Truy vấn tất cả nhân viên (employees) của một thành phố (city)",
	"tags": [],
	"description": "",
	"content": "Bạn có một global secondary index mới mà bạn có thể sử dụng để truy vấn nhân viên theo thành phố. Chạy lệnh Python sau để liệt kê tất cả nhân viên theo bộ phận ở Dallas, Texas.\npython query_city_dept.py employees TX --citydept Dallas Kết quả sẽ giống như sau.\nList of employees . State: TX Name: Grayce Duligal. City: Dallas. Dept: Development Name: Jere Vaughn. City: Dallas. Dept: Development Name: Valeria Gilliatt. City: Dallas. Dept: Development ... Name: Brittani Hunn. City: Dallas. Dept: Support Name: Oby Peniello. City: Dallas. Dept: Support Total of employees: 47. Execution time: 0.21702003479 seconds "
},
{
	"uri": "//localhost:1313/vi/6-leda/6.3/6.3.3/",
	"title": "Bước 3: Kết nối ReduceLambda",
	"tags": [],
	"description": "",
	"content": "Mục tiêu của bước cuối cùng trong Lab 1 Mục tiêu của bước cuối cùng trong Lab 1 là cấu hình chính xác hàm ReduceLambda, kết nối nó với DynamoDB stream của ReduceTable, và đảm bảo rằng tổng số liệu được ghi vào AggregateTable. Khi hoàn thành thành công bước này, bạn sẽ bắt đầu tích lũy điểm trên bảng xếp hạng.\nCấu hình Lambda concurrency Chúng ta bắt đầu bằng cách thiết lập concurrency (đồng thời) của hàm ReduceLambda thành 1. Điều này đảm bảo rằng chỉ có một instance hoạt động của hàm ReduceLambda tại bất kỳ thời điểm nào. Điều này cần thiết để tránh xung đột ghi, nơi mà nhiều instance cố gắng cập nhật AggregateTable cùng một lúc. Từ góc độ hiệu suất, một instance Lambda duy nhất có thể xử lý việc tổng hợp của toàn bộ pipeline vì các thông điệp đến đã được tổng hợp trước bởi các hàm MapLambda.\nĐiều hướng đến dịch vụ AWS Lambda trong AWS Management Console. Nhấp vào hàm ReduceLambda để chỉnh sửa cấu hình của nó (xem hình bên dưới). Mở tab Configuration, sau đó chọn Concurrency ở phía bên trái. Nhấp vào nút Edit ở góc trên bên phải, chọn Reserve concurrency và nhập 1. Sau khi nhấp vào Save, cấu hình của bạn sẽ trông giống như hình dưới đây. Kết nối ReduceLambda với stream của ReduceTable Tiếp theo, chúng ta muốn kết nối hàm ReduceLambda với DynamoDB stream của ReduceTable.\nBảng tổng quan về hàm cho thấy hàm ReduceLambda chưa có trigger. Nhấp vào nút Add trigger. Cấu hình như sau:\nTrong danh sách thả xuống, chọn DynamoDB làm nguồn dữ liệu. Trong bảng DynamoDB, chọn ReduceTable. Đặt Batch size là 1000. Nhấp vào nút Add ở góc dưới bên phải.\nBạn sẽ thấy một lỗi! Trước khi có thể kích hoạt trigger này, chúng ta cần thêm quyền IAM cho hàm Lambda này.\nThêm quyền IAM cần thiết Thông báo lỗi trên cho biết hàm ReduceLambda không có đủ quyền để đọc từ stream của ReduceTable. Mặc dù chúng ta đã gán các vai trò IAM với các quyền cần thiết cho các hàm StateLambda và MapLambda, nhưng giờ là lúc bạn cần làm điều này cho hàm ReduceLambda:\nGiữ tab Lambda console hiện tại mở trên trang bạn nhận được lỗi IAM khi cố gắng thêm trigger vào hàm ReduceLambda. Bạn sẽ cần nó mở để thử lại yêu cầu. Mở một tab trình duyệt mới, đi đến dịch vụ AWS Lambda và chọn hàm ReduceLambda. Điều hướng đến tab Configuration và nhấp vào Permissions. Bạn sẽ thấy vai trò thực thi Lambda có tên là ReduceLambdaRole. Nhấp vào vai trò này để chỉnh sửa nó. Bây giờ bạn đã được chuyển hướng đến dịch vụ IAM, nơi bạn thấy chi tiết của vai trò ReduceLambdaRole. Có một chính sách liên kết với vai trò này, đó là ReduceLambdaPolicy. Mở rộng để xem các quyền hiện tại của hàm ReduceLambda. Bây giờ, nhấp vào nút Edit để thêm các quyền bổ sung. Chỉnh sửa chính sách IAM Đã có sẵn một quyền IAM cho DynamoDB: điều này cần thiết để đảm bảo workshop hoạt động như mong đợi. Đừng bị nhầm lẫn bởi điều này và xin đừng xóa các quyền mà chúng tôi đã cấp! Tất cả các hàm Lambda cần có quyền truy cập vào ParameterTable để kiểm tra tiến độ hiện tại của lab và các chế độ lỗi tương ứng.\nTrước tiên, chúng ta cần thêm quyền để hàm ReduceLambda có thể đọc các thông điệp từ stream của ReduceTable. Nhấp vào Add new statement Đối với Service, chọn DynamoDB Dưới Access level - read, chọn bốn ô sau: DescribeStream, GetRecords, GetShardIterator, và ListStreams Bây giờ chúng ta cần liên kết các quyền này với các tài nguyên cụ thể (ví dụ: chúng ta muốn hàm ReduceLambda chỉ có thể đọc từ ReduceTable). Do đó, dưới Add a resource, nhấp vào Add. Sau đó trong Resource type chọn stream. Tiếp theo, điền vào các thông tin sau:\n{Region} - Lab mặc định sử dụng us-west-2, nhưng hãy xác nhận vùng của bạn và đảm bảo điền đúng {Account} - ID tài khoản AWS. Bạn có thể đặt dấu sao (*) nếu không muốn lấy ID tài khoản chính xác. {TableName} - Tên bảng phải là ReduceTable {StreamLabel} - Thêm dấu sao * để hỗ trợ bất kỳ nhãn stream nào. Nhãn stream là một định danh duy nhất cho một stream DynamoDB. Cuối cùng, nhấp vào Add resource. Bạn đã cấp quyền cho hàm ReduceLambda đọc từ stream của ReduceTable, nhưng vẫn còn nhiều việc cần làm. Hãy chắc chắn xóa tất cả các dấu ngoặc nhọn khỏi ARN của bạn trước khi nhấp vào Add resource\nNếu chúng ta không thực hiện thêm thay đổi nào, hàm ReduceLambda sẽ không thể cập nhật kết quả cuối cùng trong AggregateTable. Chúng ta cần chỉnh sửa chính sách để thêm các quyền bổ sung cho phép truy cập UpdateItem cho hàm.\nNhấp vào Add new statement Đối với Service, chọn DynamoDB Dưới Access level - read or write, chọn hộp kiểm UpdateItem Lại, chúng ta muốn liên kết các quyền này với một tài nguyên cụ thể: Chúng ta muốn hàm ReduceLambda chỉ có thể ghi vào AggregateTable. Do đó, nhấp vào Add a resource và trong danh sách thả xuống Resource type chọn table. Tiếp theo, nhập các giá trị cho Region (sử dụng cùng một vùng như trước), Account (cân nhắc sử dụng dấu sao *), và TableName (lần này là AggregateTable). Nhấp Add resource. Cuối cùng, nhấp Next và sau đó Save changes ở góc dưới bên phải. Thử lại kết nối ReduceLambda với stream của ReduceTable Nếu tất cả các bước trên được thực hiện đúng, bạn sẽ có thể kết nối hàm ReduceLambda với DynamoDB stream của ReduceTable bằng cách chuyển lại sang tab mở và thử nhấp vào Add một lần nữa. Bạn có thể cần đợi vài giây để các thay đổi chính sách IAM được truyền tải.\nNếu bạn không thể thêm trigger, điều này có thể do cấu hình sai của chính sách IAM. Nếu bạn cần trợ giúp, hãy đi tới Summary \u0026amp; Conclusions ở bên trái, sau đó Solutions, và bạn sẽ thấy chính sách ReduceLambdaPolicy mong muốn.\nLàm sao để biết nó hoạt động? Nếu mọi thứ được thực hiện đúng, thì DynamoDB stream của ReduceTable sẽ kích hoạt hàm ReduceLambda. Do đó, bạn sẽ thấy nhật ký cho mỗi lần gọi Lambda trong tab Monitor -\u0026gt; Logs.\nMột cách khác để kiểm tra xem nó có hoạt động hay không là quan sát các mục được ghi bởi ReduceLambda vào bảng DynamoDB AggregateTable. Để làm điều đó, điều hướng đến dịch vụ DynamoDB trong AWS console, nhấp vào Items ở bên trái, và chọn AggregateTable. Tại thời điểm này, bạn sẽ thấy nhiều hàng tương tự như hình dưới đây.\nAWS Event: Nếu các bước 1, 2 và 3 của Lab 1 được hoàn thành thành công, bạn sẽ bắt đầu ghi điểm trong vòng một đến hai phút. Hãy kiểm tra bảng xếp hạng! Yêu cầu người điều hành phòng lab cung cấp liên kết đến bảng xếp hạng.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.3/",
	"title": "Cập nhật IAM Role",
	"tags": [],
	"description": "",
	"content": "Luồng DynamoDB ghi lại chuỗi thay đổi cấp độ mục theo thứ tự thời gian xảy ra trên bảng DynamoDB. Sau khi bật, thông tin về tất cả các thay đổi cấp mặt hàng sẽ được ghi lại và lưu trữ trong tối đa 24 giờ.\nCác thay đổi đối với các mục trên bảng DynamoDB đã bật luồng được ghi lại gần như theo thời gian thực để có thể sử dụng các sự kiện làm trình kích hoạt cho các ứng dụng dựa trên sự kiện tiêu thụ dữ liệu từ luồng DynamoDB của bạn.\nTrong chương này, bạn kích hoạt luồng DynamoDB trên bảng Đơn hàng và triển khai hàm AWS Lambda sao chép các thay đổi từ bảng Đơn hàng sang bảng Lịch sử đơn hàng mỗi khi một mục được cập nhật trên bảng Đơn hàng.\nCác giải pháp kết quả được hiển thị trong hình dưới đây.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.3/",
	"title": "Khám phá DynamoDB Console",
	"tags": [],
	"description": "",
	"content": "Trong bài thực hành này, chúng ta sẽ khám phá phần DynamoDB của AWS Management Console. Hiện có hai phiên bản của giao diện điều khiển và mặc dù bạn luôn có thể nhấp vào \u0026ldquo;Revert to the current console\u0026rdquo; (Quay lại giao diện điều khiển hiện tại), chúng ta sẽ làm việc với phiên bản V2 của giao diện điều khiển.\nCấp độ trừu tượng cao nhất trong DynamoDB là một Bảng (trong DynamoDB không có khái niệm về \u0026ldquo;Cơ sở dữ liệu\u0026rdquo; chứa nhiều bảng bên trong như ở các dịch vụ NoSQL hoặc RDBMS khác). Bên trong một Bảng, bạn sẽ chèn các Mục (Items), tương tự như các hàng (row) trong các dịch vụ khác. Các Mục là tập hợp của các Thuộc tính (Attributes), tương tự như các cột (column). Mỗi Mục phải có một Khóa Chính (Primary Key) để nhận diện duy nhất hàng đó (hai Mục không thể chứa cùng một Khóa Chính). Khi tạo bảng, ít nhất bạn phải chọn một thuộc tính làm Khóa Phân Vùng (Partition Key, hay còn gọi là Hash Key) và bạn có thể tùy chọn xác định một thuộc tính khác làm Khóa Sắp Xếp (Sort Key).\nNếu bảng của bạn chỉ có Khóa Phân Vùng, thì Khóa Phân Vùng là Khóa Chính và phải nhận diện duy nhất mỗi mục. Nếu bảng của bạn có cả Khóa Phân Vùng và Khóa Sắp Xếp, thì có thể có nhiều mục có cùng Khóa Phân Vùng, nhưng sự kết hợp giữa Khóa Phân Vùng và Khóa Sắp Xếp sẽ là Khóa Chính và nhận diện duy nhất hàng đó. Nói cách khác, bạn có thể có nhiều mục có cùng Khóa Phân Vùng miễn là Khóa Sắp Xếp của chúng khác nhau. Các mục có cùng Khóa Phân Vùng được gọi là thuộc về cùng một Bộ Sưu Tập Mục (Item Collection).\nĐể biết thêm thông tin, vui lòng đọc về Các Khái Niệm Cơ Bản trong DynamoDB.\nCác thao tác trong DynamoDB tiêu thụ dung lượng từ bảng. Khi bảng sử dụng dung lượng Theo Yêu Cầu (On-Demand), các thao tác đọc sẽ tiêu thụ Đơn vị Yêu cầu Đọc (RRUs) và các thao tác ghi sẽ tiêu thụ Đơn vị Yêu cầu Ghi (WRUs). Khi bảng sử dụng Dung lượng Cung cấp (Provisioned Capacity), các thao tác đọc sẽ tiêu thụ Đơn vị Dung lượng Đọc (RCUs) và các thao tác ghi sẽ tiêu thụ Đơn vị Dung lượng Ghi (WCUs). Để biết thêm thông tin, vui lòng xem Chế độ Dung lượng Đọc/Ghi trong Hướng dẫn Dành cho Nhà Phát triển DynamoDB.\nBây giờ hãy đi vào shell và khám phá DynamoDB Console.\n"
},
{
	"uri": "//localhost:1313/vi/6-leda/6.3/",
	"title": "Lab 1: Kết nối pipeline",
	"tags": [],
	"description": "",
	"content": "Hãy tìm hiểu sâu về các nguồn dữ liệu phát trực tuyến với AWS Lambda! Trong bài thực hành đầu tiên này, bạn sẽ xử lý dữ liệu phát trực tuyến để tạo một pipeline xử lý dữ liệu từ đầu đến cuối. Bạn sẽ sử dụng Amazon Kinesis, AWS Lambda, Amazon DynamoDB và một trong những tính năng mạnh mẽ của nó là DynamoDB Streams để thực hiện điều này. Chúng ta sẽ dành thời gian để giải thích một số tính năng chính của các dịch vụ này.\nAmazon DynamoDB Amazon DynamoDB là một cơ sở dữ liệu NoSQL có khả năng mở rộng theo chiều ngang lớn, được thiết kế để có độ trễ chỉ vài mili giây với hầu như không có giới hạn về quy mô, cả về thông lượng lẫn lưu trữ. DynamoDB cung cấp bảo mật tích hợp, sao lưu liên tục, sao chép tự động đa vùng, bộ nhớ đệm trong bộ nhớ, và các công cụ xuất dữ liệu.\nSơ đồ này cho thấy các tính năng và tích hợp của DynamoDB:\nNếu bạn muốn tìm hiểu thêm bạn có thể xem lại trang tính năng của DynamoDB trên aws.amazon.com\nDynamoDB Streams DynamoDB Streams cung cấp một tập hợp các thay đổi có thứ tự từ bảng DynamoDB của bạn trong vòng 24 giờ sau khi các mục được ghi. Đây là một dịch vụ thu thập dữ liệu thay đổi (CDC), và khi bạn bật luồng trên bảng, các thay đổi sẽ bắt đầu chảy vào luồng. Các thay đổi mục của DynamoDB xuất hiện chính xác một lần trong luồng, và thay đổi này thường bao gồm bản sao cũ và mới của mục, nhưng bạn có thể chọn có một trong hai, hoặc chỉ có khóa mục. Dịch vụ này bền bỉ và có khả năng sẵn sàng cao. Mặc dù tên gọi tương tự như Kinesis Data Streams, DynamoDB Streams có một lộ trình hoàn toàn khác, đội ngũ kỹ sư khác, và hạm đội máy chủ khác.\nMột stream DynamoDB được tạo thành từ nhiều shard. Một shard chứa danh sách các thay đổi theo thứ tự thời gian từ một DynamoDB partition. Các thay đổi mục được đưa vào shard dưới dạng stream records. Hãy cùng giải thích các thuật ngữ này:\nStream: Một luồng DynamoDB Streams đơn, chứa dữ liệu CDC từ một bảng DynamoDB duy nhất. Luồng có thể được bật hoặc tắt, và tại thời điểm bật, bạn có thể chọn liệu bản sao cũ và mới của mục có được giữ lại, chỉ một trong hai hoặc chỉ có khóa. Mỗi luồng có một ID duy nhất gọi là stream label. DynamoDB partition: Một phân vùng là một phần lưu trữ cho một bảng, được hỗ trợ bởi ổ đĩa thể rắn (SSD) và tự động sao chép qua nhiều Vùng Sẵn Sàng (AZ) trong một Vùng AWS. Mỗi mục DynamoDB sẽ nằm trên chính xác một phân vùng, nhưng phân vùng được sao chép ba chiều để đảm bảo tính bền bỉ và khả năng sẵn sàng. Các thay đổi từ một phân vùng DynamoDB được sao chép vào một shard luồng trong chưa đến một giây. Shard: Một shard luồng giữ các bản ghi luồng. Một luồng bao gồm nhiều shard luồng. Trong DynamoDB, một phân vùng sẽ ghi vào chính xác một shard luồng, và hai cái này không nên bị nhầm lẫn với nhau. Một shard luồng có thể mở (có thể thêm các bản ghi luồng mới) hoặc đóng (không thể thêm bản ghi luồng mới). Một shard luồng đóng được định nghĩa là một shard có EndingSequenceNumber, trong khi một shard luồng mở không có EndingSequenceNumber. Để tìm hiểu thêm về các shard và nguồn gốc shard, hãy xem tài liệu của chúng tôi về Đọc và Xử lý một Luồng. Stream record: Một thay đổi đơn lẻ trên bảng DynamoDB. Bất kỳ thao tác tạo, cập nhật, hoặc xóa nào trên bảng đều có thể tạo ra một bản ghi luồng miễn là mục thực sự bị thay đổi. Nếu bạn xóa một mục không tồn tại hoặc \u0026ldquo;cập nhật\u0026rdquo; một mục nhưng không có thay đổi nào đối với thuộc tính của nó, thì không tạo ra bản ghi luồng. Một bản ghi có dấu thời gian ApproximateCreationDateTime chính xác đến mili giây gần nhất để sắp xếp trên tất cả các shard cùng với số thứ tự chỉ có thể được sử dụng để sắp xếp bên trong shard. Các bản ghi luồng và các loại nội dung (NEW_IMAGE | OLD_IMAGE | NEW_AND_OLD_IMAGES | KEYS_ONLY) được giải thích trong tài liệu StreamRecord của chúng tôi. Dòng dõi shard của DynamoDB Streams Khi đã trôi qua 4 giờ, khi một shard đạt đến kích thước xác định trước tính bằng byte, hoặc khi một phân vùng DynamoDB chia tách, một shard sẽ đóng lại và shard mới được tạo ra. Ngoại trừ các shard đầu tiên được tạo ra khi bật luồng, tất cả các shard đều có một shard cha. Để một khách hàng như Lambda có thể truy xuất các bản ghi luồng, họ phải xác định dòng dõi shard bằng cách truy xuất tất cả thông tin về các shard bằng cách sử dụng ID shard cha để tìm xem các shard nào là cũ nhất và shard nào là mới nhất.\nHãy xem xét một bảng DynamoDB với 4 phân vùng. Các shard được thay đổi sau mỗi 4 giờ, cho mỗi phân vùng. Như bạn có thể biết, có một ánh xạ 1:1 giữa một shard mở và một phân vùng DynamoDB. Khi luồng đã được bật trong 24 giờ (thời gian lưu giữ dài nhất cho dữ liệu luồng), sẽ có [(4 phân vùng) * (24 giờ / 4 giờ mỗi shard)] = 24 shard luồng. Tại bất kỳ thời điểm nào, chỉ có bốn shard mở và phần còn lại sẽ đóng. Khi bạn kết nối một hàm Lambda với luồng này, sẽ có bốn phiên bản Lambda.\nHãy dành thời gian để giải thích kết nối này và định nghĩa một phiên bản Lambda là gì.\nTriggers của AWS Lambda AWS Lambda là một dịch vụ tính toán không máy chủ, dựa trên sự kiện cho phép bạn chạy mã cho hầu như bất kỳ loại ứng dụng hoặc dịch vụ backend nào mà không cần cung cấp hoặc quản lý máy chủ. Lambda hỗ trợ nhiều trình kích hoạt bao gồm Kinesis Data Streams và DynamoDB. Trong bài thực hành này, bạn sẽ kết nối một số hàm với các nguồn phát trực tuyến, thiết lập kích thước batch và mức đồng thời. Vì lý do này, chúng tôi sẽ dành thời gian để giải thích cách chúng hoạt động.\nDịch vụ Lambda hỗ trợ trình kích hoạt Lambda function thông qua cái gọi là event source mapping. Khi một hàm Lambda được kết nối với một nguồn phát trực tuyến, bạn chọn bắt đầu với các bản ghi cũ nhất trong luồng hay mới nhất bằng cách đặt StartingPosition trong event source mapping. Sau đó, dịch vụ Lambda bắt đầu truy vấn luồng. Dịch vụ truy vấn Lambda sau đó chuyển các batch bản ghi (kích thước được xác định bởi BatchSize trong event source mapping) cho một Lambda instance. Bạn có thể giới hạn số lượng phiên bản Lambda đồng thời bằng cách sử dụng reserved concurrency.\nLambda function: Từ tài liệu: Một hàm là một tài nguyên mà bạn có thể gọi để chạy mã của mình trong Lambda. Một hàm có mã để xử lý các sự kiện mà bạn truyền vào hàm hoặc các dịch vụ AWS khác gửi đến hàm. Trong bài thực hành này, chúng tôi có ba hàm Lambda dưới sự kiểm soát của bạn. Reserved concurrency: Đồng thời được dự trữ đảm bảo số lượng phiên bản đồng thời tối đa cho hàm. Bạn có thể dự trữ đồng thời để ngăn hàm của bạn sử dụng tất cả các đồng thời có sẵn trong tài khoản hoặc làm quá tải các tài nguyên hạ lưu. Trong bài thực hành này, chúng tôi thay đổi mức đồng thời của một hàm thành 1. Lambda instance: Một phiên bản duy nhất (một container đang chạy) của một hàm Lambda. Thông qua đồng thời được dự trữ với các nguồn phát trực tuyến, số lượng phiên bản Lambda đang chạy đồng thời có thể được kiểm soát, tuy nhiên bạn không có quyền kiểm soát số lượng tổng thể các phiên bản. Với các nguồn phát trực tuyến như DynamoDB, Lambda mặc định tạo một phiên bản cho mỗi shard luồng quan trọng. Event source mapping: Bản đồ nguồn sự kiện là kết nối logic giữa một nguồn dữ liệu và một hàm Lambda. Khi bạn thêm một trigger vào hàm Lambda trong bài thực hành, bảng điều khiển gọi CreateEventSourceMapping để liên kết nguồn phát trực tuyến với hà m Lambda. Tài liệu API cung cấp nhiều tùy chọn, nhưng chúng tôi sẽ chỉ ra ba tùy chọn thú vị:\nBatchSize: Số lượng bản ghi luồng tối đa mà Lambda cung cấp cho phiên bản hàm Lambda khi nó được gọi. Hàm Lambda sẽ cần xử lý các bản ghi đó và trả về chúng một cách kịp thời. Kích thước batch là 1 sẽ rất không hiệu quả do chi phí quản lý việc gọi hàm. Giá trị tối đa là 1.000 cho DynamoDB Streams. StartingPosition: Vị trí trong một luồng để bắt đầu đọc. Với TRIM_HORIZON, Lambda sẽ bắt đầu đọc từ dữ liệu cũ nhất trong luồng. Với LATEST, Lambda sẽ bắt đầu đọc từ các shard mới nhất (các shard luồng mở, như đã định nghĩa ở trên). Như đã đề cập trước đó, có một phiên bản Lambda cho mỗi shard quan trọng. Theo thời gian, có thể có nhiều shard được thêm vào một luồng, trong trường hợp đó, số lượng phiên bản đang chạy sẽ tăng lên để phù hợp với số lượng shard quan trọng. Lambda sẽ khám phá dòng dõi shard để nó có thể quyết định shard nào là quan trọng để bắt đầu (shard cũ nhất, hoặc shard mới nhất tùy thuộc vào cài đặt tham số này). Trong bài thực hành này, chúng ta sẽ sử dụng cài đặt LATEST. ParallelizationFactor: Số lượng phiên bản Lambda để tạo ra trên mỗi shard luồng. Mặc định là 1, nhưng bạn có thể tăng lên 10 phiên bản trên mỗi shard. Với giá trị lớn hơn 1, dịch vụ Lambda sử dụng một sơ đồ băm nhất quán để đảm bảo các khóa mục DynamoDB giống nhau được truyền đến cùng một phiên bản, duy trì thứ tự của shard luồng. ParallelizationFactor thực chất là \u0026ldquo;chia shard\u0026rdquo; một shard luồng để tăng tốc độ xử lý khi mã hàm Lambda của bạn không hiệu quả hoặc nhiệm vụ của mã phức tạp hoặc chậm để hoàn thành. Chúng tôi không đặt giá trị này trong bài thực hành. "
},
{
	"uri": "//localhost:1313/vi/3-ladv/",
	"title": "LADV: Advanced Design Patterns for Amazon DynamoDB",
	"tags": [],
	"description": "",
	"content": "Trong hội thảo này, bạn xem xét Amazon DynamoDB design patterns và best practices hay nhất để xây dựng các ứng dụng có khả năng mở rộng cao, được tối ưu hóa về hiệu suất và chi phí. Hội thảo này thực hiện các mẫu thiết kế này bằng cách sử dụng các tập lệnh Python. Kết thúc hội thảo này, bạn sẽ có kiến thức để xây dựng và giám sát các ứng dụng DynamoDB có thể phát triển đến mọi quy mô và quy mô.\nĐây là những gì hội thảo này bao gồm:\nStart here: Getting Started Exercise 1: DynamoDB Capacity Units and Partitioning Exercise 2: Sequential and Parallel Table Scans Exercise 3: Global Secondary Index Write Sharding Exercise 4: Global Secondary Index Key Overloading Exercise 5: Sparse Global Secondary Indexes Exercise 6: Composite Keys Exercise 7: Adjacency Lists Exercise 8: Amazon DynamoDB Streams and AWS Lambda "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.2/1.2.3/",
	"title": "Làm việc với Table Scans",
	"tags": [],
	"description": "",
	"content": "Như đã đề cập trước đó, API Scan có thể được gọi bằng lệnh CLI scan. Lệnh Scan sẽ quét toàn bộ bảng và trả về các mục theo từng khối 1MB.\nAPI Scan tương tự như API Query ngoại trừ việc vì chúng ta muốn quét toàn bộ bảng chứ không chỉ một Item Collection duy nhất, do đó không có Biểu thức Điều kiện Khóa (Key Condition Expression) cho Scan. Tuy nhiên, bạn có thể chỉ định một Biểu thức Lọc (Filter Expression) để giảm kích thước bộ kết quả (mặc dù nó sẽ không giảm lượng dung lượng đã tiêu thụ).\nVí dụ, chúng ta có thể tìm tất cả các phản hồi trong bảng Reply được đăng bởi Người dùng A:\naws dynamodb scan \\ --table-name Reply \\ --filter-expression \u0026#39;PostedBy = :user\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:user\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;User A\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL Lưu ý rằng trong phản hồi, chúng ta thấy các dòng này:\n\u0026#34;Count\u0026#34;: 3, \u0026#34;ScannedCount\u0026#34;: 4, Điều này cho chúng ta biết rằng lệnh Scan đã quét tất cả 4 mục (ScannedCount) trong bảng và đó là số mục chúng ta phải trả phí để đọc, nhưng Biểu thức Lọc đã giảm kích thước bộ kết quả xuống còn 3 mục (Count).\nĐôi khi, khi quét dữ liệu, sẽ có nhiều dữ liệu hơn mức có thể phù hợp trong phản hồi nếu lệnh scan đạt giới hạn 1MB ở phía máy chủ, hoặc có thể còn nhiều mục hơn so với tham số \u0026ndash;max-items đã chỉ định. Trong trường hợp đó, phản hồi của lệnh scan sẽ bao gồm một NextToken mà chúng ta có thể sử dụng trong lệnh scan tiếp theo để tiếp tục từ vị trí đã dừng. Ví dụ, trong lệnh scan trước đó, chúng ta biết rằng có 3 mục trong bộ kết quả. Hãy chạy lại lệnh này nhưng giới hạn số mục tối đa là 2:\naws dynamodb scan \\ --table-name Reply \\ --filter-expression \u0026#39;PostedBy = :user\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:user\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;User A\u0026#34;} }\u0026#39; \\ --max-items 2 \\ --return-consumed-capacity TOTAL Chúng ta có thể thấy trong phản hồi có một dòng:\n\u0026#34;NextToken\u0026#34;: \u0026#34;eyJFeGNsdXNpdmVTdGFydEtleSI6IG51bGwsICJib3RvX3RydW5jYXRlX2Ftb3VudCI6IDJ9\u0026#34; Vì vậy, chúng ta có thể gọi lại lệnh scan, lần này truyền giá trị NextToken vào tham số \u0026ndash;starting-token:\naws dynamodb scan \\ --table-name Reply \\ --filter-expression \u0026#39;PostedBy = :user\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:user\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;User A\u0026#34;} }\u0026#39; \\ --max-items 2 \\ --starting-token eyJFeGNsdXNpdmVTdGFydEtleSI6IG51bGwsICJib3RvX3RydW5jYXRlX2Ftb3VudCI6IDJ9 \\ --return-consumed-capacity TOTAL "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.3/1.3.3/",
	"title": "Làm việc với Table Scans",
	"tags": [],
	"description": "",
	"content": "API Scan có thể được gọi bằng lệnh CLI scan. Lệnh Scan sẽ quét toàn bộ bảng và trả về các mục theo từng khối 1MB.\nAPI Scan tương tự như API Query, ngoại trừ việc chúng ta muốn quét toàn bộ bảng thay vì chỉ một Item Collection duy nhất, do đó không có Biểu thức Điều kiện Khóa (Key Condition Expression) cho lệnh Scan. Tuy nhiên, bạn có thể chỉ định một Biểu thức Lọc (Filter Expression) để giảm kích thước của bộ kết quả (mặc dù nó sẽ không giảm lượng dung lượng đã tiêu thụ).\nHãy xem dữ liệu trong bảng Reply có cả Khóa Phân Vùng và Khóa Sắp Xếp. Chọn Explore items từ thanh menu bên trái.\nBạn có thể cần nhấp vào biểu tượng menu hình hamburger để mở rộng menu bên trái nếu nó bị ẩn.\nKhi bạn vào phần Explore Items, bạn cần chọn bảng Reply và sau đó mở rộng hộp Scan/Query items.\nVí dụ, chúng ta có thể tìm tất cả các phản hồi trong bảng Reply được đăng bởi User A.\nBạn sẽ thấy 3 mục Reply được đăng bởi User A.\n"
},
{
	"uri": "//localhost:1313/vi/8-ldc/8.3/",
	"title": "Links: NoSQL Design: Tài liệu tham khảo",
	"tags": [],
	"description": "",
	"content": "Tài liệu tham khảo cho thiết kế DynamoDB Thiết kế mô hình dữ liệu DynamoDB: Làm việc với truy vấn trong DynamoDB (Working with Queries in DynamoDB) Mẫu thiết kế nâng cao cho DynamoDB (Advanced Design Patterns for DynamoDB) Thực tiễn tốt nhất khi thiết kế và kiến trúc với DynamoDB (DynamoDB Best Practices for Designing and Architecting with DynamoDB) Thực tiễn tốt nhất khi sử dụng khóa sắp xếp để tổ chức dữ liệu (Best Practices for Using Sort Keys to Organize Data) Sử dụng Global Secondary Index trong DynamoDB (Using Global Secondary Indexes in DynamoDB) Thực tiễn tốt nhất để quản lý mối quan hệ nhiều-nhiều (Best Practices for Managing Many-to-Many Relationships) Hiểu về hệ thống phân tán và DynamoDB: DynamoDB bên trong: Cách chúng tôi xây dựng cơ sở dữ liệu siêu quy mô (Amazon DynamoDB Under the Hood: How We Built a Hyper-Scale Database) DynamoDB hoạt động như thế nào (Amazon DynamoDB: How It Works) Các công cụ liên quan đến DynamoDB: NoSQL Workbench cho Amazon DynamoDB (NoSQL Workbench for Amazon DynamoDB) EMR-DynamoDB-Connector: Truy cập dữ liệu lưu trữ trong DynamoDB với Apache Hadoop, Apache Hive, và Apache Spark (EMR-DynamoDB-Connector: Access data stored in Amazon DynamoDB with Apache Hadoop, Apache Hive, and Apache Spark) Khóa học trực tuyến: A Cloud Guru: Đào sâu vào Amazon DynamoDB (Amazon DynamoDB Deep Dive) A Cloud Guru: Mô hình dữ liệu DynamoDB (Amazon DynamoDB Data Modeling) edX: Amazon DynamoDB: Xây dựng ứng dụng điều khiển cơ sở dữ liệu NoSQL (Amazon DynamoDB: Building NoSQL Database-Driven Applications) "
},
{
	"uri": "//localhost:1313/vi/5-lmr/5.3/",
	"title": "Module 2: Khám phá Global Tables",
	"tags": [],
	"description": "",
	"content": "Tổng quan về ứng dụng Chúc mừng! Hiện tại bạn đã có một stack ứng dụng serverless chạy tại cả Oregon và Ireland. Các stack mà bạn triển khai với Chalice mỗi cái đều chứa các thành phần cốt lõi sau:\nDịch vụ web Amazon API Gateway phản hồi các lệnh gọi HTTP GET và chuyển tiếp chúng đến hàm Lambda. Hàm AWS Lambda thực hiện các yêu cầu đọc và ghi đến bảng DynamoDB bằng Python. Vai trò AWS IAM để cấp các quyền cần thiết. Sau đó, bạn đã sử dụng AWS Command Line Interface để triển khai một DynamoDB Global Table có tên global-serverless và điền vào đó một số mục. Những mục này đại diện cho các bản ghi bookmark có thể được thiết lập để ghi lại và truy xuất tiến trình mà khách hàng đã đạt được khi xem nội dung video. Ngoài ra còn có các mục đại diện cho một danh mục nội dung video có sẵn.\nChi tiết về DynamoDB Global Table Thiết kế Bookmark Bảng của chúng ta có khóa chính hai phần bao gồm một Partition Key và một Sort Key, được đặt tên là PK và SK. Mỗi bản ghi bookmark sẽ có UserID của người xem làm giá trị PK, và một giá trị ContentID trong SK để chỉ ra video mà họ đang xem. Thuộc tính thứ ba, gọi là Bookmark, sẽ ghi lại tiến trình. Ứng dụng sẽ thực hiện các cập nhật định kỳ cho thuộc tính Bookmark này khi chương trình được xem. Nếu người dùng dừng lại và sau đó quay lại sau, một lệnh gọi Get-Item có thể xác định vị trí bookmark, đọc giá trị Bookmark, và xếp hàng cho trình phát video đến đúng điểm để khách hàng tiếp tục xem.\nHiệu suất Sao chép Khi stack ứng dụng ở Oregon thực hiện các lệnh gọi tới DynamoDB, nó kết nối tới bảng DynamoDB trong cùng vùng. Chúng ta có thể gọi bảng cục bộ này là một bản sao vùng vì nó tham gia vào sao chép Global Tables. Ghi vào bất kỳ bản sao vùng nào sẽ được dịch vụ DynamoDB phát hiện và hình ảnh mục mới sẽ được gửi và áp dụng cho tất cả các bản sao vùng khác. Mục tiêu của Global Tables là đưa tất cả các bản sao đến trạng thái giống nhau càng nhanh càng tốt. Người gọi như hàm Lambda của chúng ta ở Oregon không cần phải biết về các vùng khác và không kết nối đến bất kỳ điểm cuối toàn cầu nào vì không có điểm cuối nào như vậy.\nCác thao tác ghi vào một bảng bản sao được xác nhận thành công với người gọi với hiệu suất tương tự như một bảng không phải là Global Table, thường là trong vòng 10 mili giây.\nKhoảng cách giữa Oregon và Ireland là 4500 dặm (7000 km). Thông tin truyền với tốc độ ánh sáng sẽ vượt qua khoảng cách này trong 24 ms.\nThời gian DynamoDB cần để sao chép các thay đổi đến các vùng khác có thể thay đổi, nhưng thường là từ 1-2 giây. Thống kê ReplicationLatency trong Cloudwatch theo dõi thời gian cần thiết để sao chép các mục.\nKiểm tra các trường hợp cạnh trong ứng dụng web Hãy chứng minh rằng sao chép Global Tables đang hoạt động.\nNhấp vào nút cộng + trong vùng đầu tiên và chú ý rằng giá trị bookmark mới được hiển thị. Nhấp vào Get-Item trong vùng thứ hai và so sánh giá trị với bookmark trong vùng đầu tiên. Nếu chúng giống nhau, điều đó có nghĩa là Global Tables đã áp dụng trạng thái mới cho tất cả các vùng. Lặp lại các bước 1 và 2 nhanh nhất có thể. Mục tiêu là kiểm tra bookmark trong vùng thứ hai trước khi việc sao chép hoàn tất. Vì sao chép có thể diễn ra trong khoảng một giây, bạn sẽ phải nhanh chóng để phát hiện điều này. Nếu bạn làm được, thì nhấp lại vào Get-Item và giá trị đã đồng bộ hóa sẽ được hiển thị.\nLưu ý ứng dụng giữ một bộ đếm thời gian sau mỗi lần cập nhật, do đó bạn có thể xem đã bao nhiêu giây trôi qua khi thực hiện đọc tiếp theo.\nTạo một xung đột Có một trường hợp cạnh với Global Tables xảy ra khi các thao tác ghi vào cùng một mục diễn ra đồng thời ở các vùng khác nhau. Nếu các thao tác ghi xung đột trong khoảng 1-2 giây của quá trình sao chép đang diễn ra, DynamoDB sẽ phát hiện điều này là một Xung đột và đưa ra quyết định về thao tác ghi nào sẽ thắng trong xung đột. Các dấu thời gian của các bản cập nhật được so sánh và thao tác ghi sau trở thành người chiến thắng. Thao tác ghi trước đó bị bỏ qua như thể nó chưa từng xảy ra.\nỞ vùng thứ nhất, nhấp vào Get-Item và ghi lại giá trị bookmark hiện tại. Tiếp theo, nhấp vào nút cộng. Ở vùng thứ hai, ngay lập tức nhấp vào nút trừ. Kiểm tra kỹ đầu ra. Vùng thứ hai có thay đổi giá trị trở lại giá trị ban đầu không? Nếu có, thì không có xung đột. Bản cập nhật đầu tiên đã sao chép hoàn toàn trước khi bản cập nhật thứ hai bắt đầu. Nếu bản cập nhật thứ hai đã giảm bookmark thấp hơn giá trị ban đầu, điều đó cho thấy ĐÃ có xung đột và bản cập nhật đầu tiên đã bị hoàn tác. Bạn có thể đọc thêm về DynamoDB Global Tables trong chương cuối của buổi workshop này hoặc trong Tài liệu về Global Tables.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.4/1.4.3/",
	"title": "Sao lưu theo yêu cầu",
	"tags": [],
	"description": "",
	"content": "Bạn có thể sử dụng khả năng sao lưu theo yêu cầu của DynamoDB để tạo các bản sao lưu toàn bộ của các bảng để lưu giữ lâu dài và lưu trữ cho các nhu cầu tuân thủ quy định. Bạn có thể sao lưu và khôi phục dữ liệu bảng bất cứ lúc nào chỉ với một lần nhấp trên AWS Management Console hoặc với một lệnh gọi API duy nhất. Các hành động sao lưu và khôi phục được thực hiện mà không ảnh hưởng đến hiệu suất hoặc tính khả dụng của bảng.\nĐầu tiên, truy cập vào DynamoDB Console và nhấp vào Tables từ menu bên. Chọn bảng ProductCatalog. Trong tab Backups của bảng ProductCatalog, chọn Create backup. Đảm bảo rằng ProductCatalog là tên bảng nguồn. Chọn Customize settings và sau đó chọn Backup with DynamoDB. Nhập tên ProductCatalogBackup. Nhấp vào Create backup để tạo bản sao lưu. Khi bản sao lưu đang được tạo, trạng thái sao lưu được đặt là Creating. Sau khi sao lưu hoàn tất, trạng thái sao lưu chuyển sang Available.\nKhôi phục sao lưu Truy cập vào DynamoDB Console và nhấp vào Tables từ menu bên. Chọn bảng ProductCatalog. Chọn tab Backups. Trong danh sách các bản sao lưu, chọn ProductCatalogBackup. Chọn Restore. Nhập ProductCatalogODRestore làm tên bảng mới. Xác nhận tên bản sao lưu và các chi tiết khác của bản sao lưu. Chọn Restore để bắt đầu quá trình khôi phục. Bảng đang được khôi phục sẽ hiển thị với trạng thái Creating. Sau khi quá trình khôi phục hoàn tất, trạng thái của bảng ProductCatalogODRestore sẽ chuyển thành Active. Để xóa một bản sao lưu Quy trình sau đây cho thấy cách sử dụng giao diện điều khiển để xóa ProductCatalogBackup. Bạn chỉ có thể xóa bản sao lưu sau khi bảng ProductCatalogODRestore đã hoàn tất khôi phục.\nTruy cập vào DynamoDB Console và nhấp vào Tables từ menu bên. Chọn bảng ProductCatalog. Chọn tab Backups. Trong danh sách các bản sao lưu, chọn ProductCatalogBackup. Nhấp vào Delete: Cuối cùng, nhập từ Delete và nhấp vào Delete để xóa bản sao lưu.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.3/",
	"title": "Sử dụng cốt lõi: hồ sơ người dùng và trò chơi",
	"tags": [],
	"description": "",
	"content": "Trong mô-đun trước, các mẫu truy cập của ứng dụng trò chơi đã được xác định. Trong mô-đun này, khóa chính (primary key) cho bảng DynamoDB được xác định và các mẫu truy cập cốt lõi được xử lý.\nKhi thiết kế khóa chính cho một bảng DynamoDB, hãy ghi nhớ các phương pháp tốt nhất sau: Bắt đầu với các thực thể khác nhau trong bảng của bạn. Nếu bạn đang lưu trữ nhiều loại dữ liệu khác nhau trong một bảng duy nhất—chẳng hạn như nhân viên, phòng ban, khách hàng, và đơn hàng—hãy đảm bảo khóa chính của bạn có cách để xác định rõ ràng từng thực thể và cho phép thực hiện các hành động cốt lõi trên các mục riêng lẻ. Sử dụng tiền tố để phân biệt giữa các loại thực thể. Sử dụng tiền tố để phân biệt giữa các loại thực thể có thể ngăn chặn xung đột và hỗ trợ trong việc truy vấn. Ví dụ, nếu bạn có cả khách hàng và nhân viên trong cùng một bảng, khóa chính cho một khách hàng có thể là CUSTOMER#\u0026lt;CUSTOMERID\u0026gt;, và khóa chính cho một nhân viên có thể là EMPLOYEE#\u0026lt;EMPLOYEEID\u0026gt;. Tập trung vào các hành động trên một mục đầu tiên, sau đó thêm các hành động trên nhiều mục nếu có thể. Đối với một khóa chính, điều quan trọng là bạn có thể đáp ứng các tùy chọn đọc và ghi trên một mục duy nhất bằng cách sử dụng các API cho mục đơn lẻ: GetItem (GetItem), PutItem (PutItem), UpdateItem (UpdateItem), và DeleteItem (DeleteItem). Bạn cũng có thể đáp ứng các mẫu đọc trên nhiều mục với khóa chính bằng cách sử dụng Query (Query). Nếu không, bạn có thể thêm một chỉ mục phụ để xử lý các trường hợp sử dụng Query. Với các phương pháp tốt nhất này, hãy thiết kế khóa chính cho bảng ứng dụng trò chơi và thực hiện một số hành động cơ bản.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.1/1.1.3/",
	"title": "Tải Data mẫu",
	"tags": [],
	"description": "",
	"content": "Thực hiện lệnh sudo su\nDownload và unzip data mẫu:\ncurl -O https://amazon-dynamodb-labs.com/static/hands-on-labs/sampledata.zip unzip sampledata.zip Load data mẫu sử dụng the batch-write-item CLI:\naws dynamodb batch-write-item --request-items file://ProductCatalog.json aws dynamodb batch-write-item --request-items file://Forum.json aws dynamodb batch-write-item --request-items file://Thread.json aws dynamodb batch-write-item --request-items file://Reply.json Sau mỗi lần tải dữ liệu, bạn sẽ nhận được thông báo này cho biết không có mục nào chưa được xử lý.\n{ \u0026#34;UnprocessedItems\u0026#34;: {} } Ví dụ output "
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.3/7.3.3/",
	"title": "Tải dữ liệu hàng loạt",
	"tags": [],
	"description": "",
	"content": "Trong bước này, bạn sẽ tải một lượng lớn dữ liệu vào DynamoDB mà bạn đã tạo trong bước trước. Điều này có nghĩa là trong các bước tiếp theo, bạn sẽ có dữ liệu mẫu để sử dụng.\nTrong thư mục scripts/, bạn sẽ tìm thấy một tệp có tên là items.json. Tệp này chứa 835 mục ví dụ được tạo ngẫu nhiên cho lab này. Những mục này bao gồm các thực thể User, Game, và UserGameMapping. Hãy mở tệp này nếu bạn muốn xem một số mục ví dụ.\nThư mục scripts/ cũng có một tệp gọi là bulk_load_table.py đọc các mục trong tệp items.json và ghi chúng hàng loạt vào bảng DynamoDB. Dưới đây là nội dung của tệp:\nimport json import boto3 dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(\u0026#39;battle-royale\u0026#39;) items = [] with open(\u0026#39;scripts/items.json\u0026#39;, \u0026#39;r\u0026#39;) as f: for row in f: items.append(json.loads(row)) with table.batch_writer() as batch: for item in items: batch.put_item(Item=item) Trong script này, thay vì sử dụng client cấp thấp trong Boto 3, bạn sử dụng một đối tượng Resource cấp cao hơn. Đối tượng Resource cung cấp một giao diện dễ dàng hơn để sử dụng các API của AWS. Đối tượng Resource hữu ích trong tình huống này vì nó chia lô các yêu cầu. Thao tác BatchWriteItem chấp nhận tối đa 25 mục trong một yêu cầu. Đối tượng Resource xử lý việc chia lô đó cho bạn thay vì buộc bạn phải chia dữ liệu thành các yêu cầu có 25 mục hoặc ít hơn.\nChạy script bulk_load_table.py và tải dữ liệu vào bảng của bạn bằng cách chạy lệnh sau trong terminal:\npython scripts/bulk_load_table.py Bạn có thể đảm bảo rằng tất cả dữ liệu của bạn đã được tải vào bảng bằng cách chạy thao tác Scan và lấy số lượng.\naws dynamodb scan --table-name battle-royale --select COUNT --return-consumed-capacity TOTAL Điều này sẽ hiển thị kết quả sau:\n{ \u0026#34;Count\u0026#34;: 835, \u0026#34;ScannedCount\u0026#34;: 835, \u0026#34;ConsumedCapacity\u0026#34;: { \u0026#34;CapacityUnits\u0026#34;: 14.5, \u0026#34;TableName\u0026#34;: \u0026#34;battle-royale\u0026#34;, \u0026#34;Table\u0026#34;: { \u0026#34;CapacityUnits\u0026#34;: 14.5 } } } Bạn nên thấy Count là 835, cho biết rằng tất cả các mục của bạn đã được tải thành công.\nBạn cũng có thể duyệt bảng bằng cách điều hướng đến Services -\u0026gt; Database -\u0026gt; DynamoDB trong AWS console.\nTrong bước tiếp theo, bạn sẽ thấy cách truy xuất nhiều loại thực thể trong một yêu cầu duy nhất, điều này có thể giảm tổng số yêu cầu mạng mà bạn thực hiện trong ứng dụng và cải thiện hiệu suất ứng dụng.\n"
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.2/2.2.3/",
	"title": "Tải DynamoDB Data",
	"tags": [],
	"description": "",
	"content": "Tiếp theo, bạn sẽ tải dữ liệu sản phẩm mẫu vào bảng DynamoDB của mình. Các pipeline sẽ chuyển dữ liệu này vào OpenSearch Service ở các bước sau.\nTải và Xem xét Dữ liệu Quay lại Cloud9 IDE. Nếu bạn vô tình đóng IDE, bạn có thể tìm kiếm dịch vụ trong AWS Management Console hoặc sử dụng URL Cloud9IDE được tìm thấy trong phần Outputs của CloudFormation stack.\nTải dữ liệu mẫu vào bảng DynamoDB của bạn.\ncd ~/environment/OpenSearchPipeline aws dynamodb batch-write-item --request-items=file://product_en.json Tiếp theo, điều hướng đến phần DynamoDB của AWS Management Console và nhấp vào Explore items, sau đó chọn bảng ProductDetails. Đây là nơi mà thông tin sản phẩm cho bài tập này xuất phát. Xem qua tên các sản phẩm để có ý tưởng về loại truy vấn ngôn ngữ tự nhiên mà bạn có thể muốn thực hiện sau khi kết thúc lab.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.4/4.4.3/",
	"title": "Tạo hàm Lambda",
	"tags": [],
	"description": "",
	"content": "Tạo một hàm Lambda để sao chép các bản ghi đã thay đổi từ DynamoDB streams của bảng Orders sang bảng OrdersHistory.\nMở AWS Management Console và truy cập vào trang tổng quan dịch vụ Lambda. Trong mục Functions, nhấp vào Create function. Chọn Author from scratch. Đặt create-order-history-kds làm tên hàm. Chọn Python 3.11 làm runtime. Mở rộng phần Change default execution role. Chọn Create a new role from AWS policy templates. Đặt create-order-history-kds-execution-role làm tên vai trò. Chọn Simple microservice permissions từ menu tùy chọn Policy templates. Nhấp vào Create function và chờ để được chuyển hướng đến bảng điều khiển AWS Lambda cho hàm vừa được tạo. Thay thế nội dung của lambda_function.py bằng mã hàm dưới đây. import os import boto3 import datetime from aws_lambda_powertools import Logger from aws_lambda_powertools.utilities.data_classes import event_source, KinesisStreamEvent from botocore.exceptions import ClientError table_name = os.getenv(\u0026#34;ORDERS_HISTORY_DB\u0026#34;) logger = Logger() client = boto3.client(\u0026#39;dynamodb\u0026#39;) def store_history_record(old_order_image): logger.debug({\u0026#34;Saving order history\u0026#34;}) # Đặt giá trị cho khóa phân vùng - pk, và khóa sắp xếp - sk; cho bảng OrderHistory # trước khi ghi bản ghi vào bảng OrderHistory. pk = old_order_image[\u0026#34;id\u0026#34;] sk = str(datetime.datetime.now()) old_order_image[\u0026#34;pk\u0026#34;] = pk old_order_image[\u0026#34;sk\u0026#34;] = { \u0026#34;S\u0026#34;: sk } logger.debug({\u0026#34;old_image\u0026#34;: old_order_image}) try: response = client.put_item( TableName=table_name, Item=old_order_image ) logger.debug({\u0026#34;operation\u0026#34;: \u0026#34;table.put_item\u0026#34;, \u0026#34;response\u0026#34;: response}) except ClientError as err: logger.error({\u0026#34;operation\u0026#34;: \u0026#34;store_history_record\u0026#34;, \u0026#34;details\u0026#34;: err}) raise Exception(err) @event_source(data_class=KinesisStreamEvent) def lambda_handler(event: KinesisStreamEvent, context): logger.debug({\u0026#34;operation\u0026#34;: \u0026#34;lambda_handler\u0026#34;, \u0026#34;event\u0026#34;: event, \u0026#34;context\u0026#34;: context}) kinesis_record = next(event.records).kinesis data = kinesis_record.data_as_json() if data[\u0026#34;eventName\u0026#34;] == \u0026#34;MODIFY\u0026#34; or data[\u0026#34;eventName\u0026#34;] == \u0026#34;REMOVE\u0026#34;: logger.debug({\u0026#34;data\u0026#34;: data}) if \u0026#34;dynamodb\u0026#34; in data: if \u0026#34;Keys\u0026#34; in data[\u0026#34;dynamodb\u0026#34;]: if \u0026#34;id\u0026#34; not in data[\u0026#34;dynamodb\u0026#34;][\u0026#34;Keys\u0026#34;]: raise ValueError(\u0026#34;Expected partition key attribute - \u0026#39;id\u0026#39; not found.\u0026#34;) if \u0026#34;OldImage\u0026#34; in data[\u0026#34;dynamodb\u0026#34;]: store_history_record(data[\u0026#34;dynamodb\u0026#34;][\u0026#34;OldImage\u0026#34;]) Phần này giải thích mã hàm:\nSố dòng Mô tả 8 - 11 Lấy tên bảng Orders History DynamoDB từ một biến môi trường, khởi tạo logger cho hàm Lambda, sau đó tạo một client boto3 để tương tác với các bảng DynamoDB. 19 - 24 Tạo một mục mới cho bảng Orders History sử dụng ảnh cũ của một mục được cập nhật trên bảng Orders. Đặt khóa phân vùng cho mục mới là id của đơn hàng được cập nhật, sau đó đặt khóa sắp xếp cho mục mới là thời gian hiện tại. 27 - 35 Ghi mục mới vào bảng Orders History. Ném ra một ngoại lệ nếu mục không được ghi thành công vào bảng. 42 - 48 Xử lý các ảnh cũ của sự kiện cập nhật mục và sự kiện xóa mục nhận được từ luồng dữ liệu Orders Kinesis. Hàm Lambda này nhận các sự kiện từ luồng dữ liệu Orders Kinesis và ghi chúng vào bảng OrdersHistory của DynamoDB.\nVì chúng ta chỉ cần ghi lại các thay đổi đối với các mục trên bảng Orders, hàm Lambda được cài đặt để chỉ xử lý các sự kiện luồng Kinesis cho các mục đã được sửa đổi và xóa từ bảng Orders.\nTriển khai các thay đổi mã cho hàm của bạn bằng cách chọn Deploy. "
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.3/4.3.3/",
	"title": "Tạo Lambda Function",
	"tags": [],
	"description": "",
	"content": "Tạo một hàm Lambda để sao chép các bản ghi đã thay đổi từ DynamoDB streams của bảng Orders sang bảng OrdersHistory.\nMở AWS Management Console và truy cập vào bảng điều khiển Lambda Service. Trong phần Functions, nhấp vào Create function. Chọn Author from scratch. Đặt create-order-history-ddbs làm tên hàm. Chọn một phiên bản Python làm runtime. Mở rộng phần Change default execution role. Chọn Create a new role from AWS policy templates. Đặt create-order-history-ddbs-execution-role làm tên vai trò (role). Chọn Simple microservice permissions từ menu tùy chọn Policy templates. Nhấp vào Create function và chờ để được chuyển hướng đến bảng điều khiển AWS Lambda cho hàm vừa tạo.\nThay thế nội dung của lambda_function.py bằng mã hàm dưới đây.\nimport os import boto3 import datetime from aws_lambda_powertools import Logger from aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import ( DynamoDBStreamEvent, DynamoDBRecordEventName ) from botocore.exceptions import ClientError table_name = os.getenv(\u0026#34;ORDERS_HISTORY_DB\u0026#34;) logger = Logger() dynamodb = boto3.resource(\u0026#39;dynamodb\u0026#39;) table = dynamodb.Table(table_name) def store_history_record(old_item_image): logger.debug({\u0026#34;operation\u0026#34;: \u0026#34;store_history_record\u0026#34;, \u0026#34;old_image\u0026#34;: old_item_image}) # Set a value for the partition key - pk, and sort key - sk; for the OrdersHistory table # before writing the record to the OrdersHistory table. pk = old_item_image[\u0026#34;id\u0026#34;] sk = str(datetime.datetime.now()) old_item_image[\u0026#34;pk\u0026#34;] = pk old_item_image[\u0026#34;sk\u0026#34;] = sk try: response = table.put_item( Item=old_item_image ) logger.debug({\u0026#34;operation\u0026#34;: \u0026#34;table.put_item\u0026#34;, \u0026#34;response\u0026#34;: response}) except ClientError as err: logger.error({\u0026#34;operation\u0026#34;: \u0026#34;store_history_record\u0026#34;, \u0026#34;details\u0026#34;: err}) raise Exception(err) def lambda_handler(event, context): logger.debug({\u0026#34;operation\u0026#34;: \u0026#34;lambda_handler\u0026#34;, \u0026#34;event\u0026#34;: event, \u0026#34;context\u0026#34;: context}) event: DynamoDBStreamEvent = DynamoDBStreamEvent(event) for record in event.records: if record.event_name == DynamoDBRecordEventName.MODIFY or record.event_name == DynamoDBRecordEventName.REMOVE: logger.debug({\u0026#34;record\u0026#34;: record}) if \u0026#34;id\u0026#34; in record.dynamodb.keys: store_history_record(record.dynamodb.old_image) else: raise ValueError(\u0026#34;Expected partition key attribute - \u0026#39;id\u0026#39; not found.\u0026#34;) Số dòng Mô tả 11 - 15 Lấy tên bảng Orders History DynamoDB từ một biến môi trường, tạo một logger cho hàm Lambda và sau đó tạo một resource boto3 để tương tác với bảng Orders History DynamoDB. 23 - 26 Tạo một mục mới cho bảng Orders History sử dụng hình ảnh cũ của một mục đã được cập nhật trên bảng Orders. Đặt khóa phân vùng cho mục mới thành id của đơn hàng đã cập nhật và đặt khóa sắp xếp cho mục mới thành thời gian hiện tại. 28 - 35 Ghi mục mới vào bảng Orders History. Ném ra ngoại lệ nếu mục không được ghi thành công vào bảng. 42 - 45 Xử lý hình ảnh cũ của sự kiện cập nhật mục và sự kiện xóa mục nhận được từ bảng Orders DynamoDB thông qua DynamoDB streams. Hàm Lambda này nhận các sự kiện từ DynamoDB streams và ghi các mục mới vào bảng DynamoDB, cụ thể là bảng OrdersHistory.\nVì chúng ta chỉ cần ghi lại các thay đổi đối với các mục trên bảng Orders, hàm Lambda được thiết lập để chỉ xử lý các sự kiện stream cho các mục đã được sửa đổi và xóa từ bảng Orders.\nTriển khai các thay đổi mã cho hàm của bạn bằng cách chọn Deploy. Đừng thực thi hàm Lambda mà bạn vừa tạo. Cần có thêm cấu hình để thiết lập hoạt động đúng cách. Bạn sẽ cập nhật cấu hình hàm Lambda trong bước tiếp theo.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.5/1.5.3/",
	"title": "Tạo tài nguyên DMS",
	"tags": [],
	"description": "",
	"content": "Hãy tạo các tài nguyên DMS cho workshop.\nTruy cập vào IAM console \u0026gt; Roles \u0026gt; Create Role Dưới phần \u0026ldquo;Select trusted entity\u0026rdquo;, chọn “AWS service”, sau đó trong mục “Use case”, chọn “DMS” từ danh sách thả xuống và nhấp vào nút radio “DMS”. Sau đó nhấp “Next”. Trong phần \u0026ldquo;Add permissions\u0026rdquo;, sử dụng hộp tìm kiếm để tìm chính sách “AmazonDMSVPCManagementRole” và chọn nó, sau đó nhấp “Next”. Trong mục \u0026ldquo;Name, review, and create\u0026rdquo;, thêm tên vai trò chính xác là dms-vpc-role và nhấp vào Create role. Không tiếp tục nếu bạn chưa tạo vai trò IAM.\nKhởi chạy mẫu CloudFormation tại khu vực US West 2 để triển khai các tài nguyên vào tài khoản của bạn: Tùy chọn, tải xuống mẫu YAML và khởi chạy theo cách của bạn. Nhấp vào Next Xác nhận tên Stack là dynamodbmigration và giữ nguyên các tham số mặc định (chỉnh sửa nếu cần thiết)\nNhấp “Next” hai lần Chọn “I acknowledge that AWS CloudFormation might create IAM resources with custom names.” Nhấp vào Submit. Mẫu CloudFormation sẽ mất khoảng 15 phút để xây dựng một môi trường sao chép. Bạn nên tiếp tục làm lab trong khi stack đang được tạo trong nền.\nĐừng chờ đợi quá trình tạo stack hoàn tất. Hãy tiếp tục làm lab và để nó tự tạo trong nền.\n"
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.3/",
	"title": "Tích hợp",
	"tags": [],
	"description": "",
	"content": "Trong phần này, bạn sẽ cấu hình tích hợp giữa các dịch vụ. Đầu tiên, bạn sẽ thiết lập các kết nối ML (Machine Learning) và Pipeline trong OpenSearch Service, sau đó thiết lập kết nối zero ETL để di chuyển dữ liệu đã ghi vào DynamoDB sang OpenSearch. Khi các tích hợp này đã được thiết lập, bạn có thể ghi các bản ghi vào DynamoDB làm nguồn dữ liệu chính của mình và sau đó tự động có dữ liệu đó sẵn sàng để truy vấn trong các dịch vụ khác.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.4/7.4.3/",
	"title": "Truy vấn sparse GSI",
	"tags": [],
	"description": "",
	"content": "Bây giờ bạn đã cấu hình GSI, hãy sử dụng nó để thỏa mãn một số mẫu truy cập.\nĐể sử dụng chỉ mục thứ cấp, có hai API có sẵn: Query và Scan. Với Query, bạn phải chỉ định khóa phân vùng (partition key), và nó sẽ trả về kết quả mục tiêu. Với Scan, bạn không cần chỉ định khóa phân vùng và thao tác này sẽ quét toàn bộ bảng của bạn. Trong DynamoDB, quét dữ liệu (Scan) thường không được khuyến khích trừ trong những trường hợp cụ thể vì chúng truy cập mọi mục trong cơ sở dữ liệu. Nếu bạn có một lượng lớn dữ liệu trong bảng, việc quét có thể mất rất nhiều thời gian. Ở bước tiếp theo, bạn sẽ thấy tại sao quét lại là một công cụ mạnh mẽ khi sử dụng với các chỉ mục thưa (sparse indexes).\nBạn có thể sử dụng API Query trên chỉ mục thứ cấp toàn cục (GSI) mà bạn đã tạo ở bước trước để tìm tất cả các game mở theo tên bản đồ. GSI được phân vùng bởi tên map, cho phép bạn truy vấn có mục tiêu để tìm các game mở.\nTrong mã bạn đã tải xuống, tệp find_open_games_by_map.py có trong thư mục scripts/.\nimport sys import boto3 from entities import Game dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) MAP_NAME = sys.argv[1] if len(sys.argv) == 2 else \u0026#34;Green Grasslands\u0026#34; def find_open_games_by_map(map_name): resp = dynamodb.query( TableName=\u0026#39;battle-royale\u0026#39;, IndexName=\u0026#34;OpenGamesIndex\u0026#34;, KeyConditionExpression=\u0026#34;#map = :map\u0026#34;, ExpressionAttributeNames={ \u0026#34;#map\u0026#34;: \u0026#34;map\u0026#34; }, ExpressionAttributeValues={ \u0026#34;:map\u0026#34;: { \u0026#34;S\u0026#34;: map_name }, }, ScanIndexForward=True ) games = [Game(item) for item in resp[\u0026#39;Items\u0026#39;]] return games games = find_open_games_by_map(MAP_NAME) print(f\u0026#34;Open games for map: {MAP_NAME}:\u0026#34;) for game in games: print(game) Trong script trên, hàm find_open_games_by_map tương tự như một hàm mà bạn sẽ có trong ứng dụng của mình. Hàm này nhận một tên bản đồ và thực hiện truy vấn trên OpenGamesIndex để tìm tất cả các game mở cho bản đồ đó. Sau đó, nó lắp ráp các thực thể trả về thành các đối tượng Game có thể sử dụng trong ứng dụng của bạn.\nThực thi script này bằng cách chạy lệnh sau trong terminal:\npython scripts/find_open_games_by_map.py Terminal sẽ hiển thị đầu ra với bốn game mở cho bản đồ Green Grasslands.\nOpen games for map: Green Grasslands: Game: 14c7f97e-8354-4ddf-985f-074970818215 Map: Green Grasslands Game: 3d4285f0-e52b-401a-a59b-112b38c4a26b Map: Green Grasslands Game: 683680f0-02b0-4e5e-a36a-be4e00fc93f3 Map: Green Grasslands Game: 0ab37cf1-fc60-4d93-b72b-89335f759581 Map: Green Grasslands Bạn có thể chạy lại script Python và sử dụng một tên bản đồ cụ thể. Hãy thử chạy mã dưới đây cho bản đồ có tên là Dirty Desert.\npython scripts/find_open_games_by_map.py \u0026#34;Dirty Desert\u0026#34; Terminal sẽ hiển thị đầu ra với ba game mở cho bản đồ Dirty Desert.\nOpen games for map: Dirty Desert: Game: d06af94a-2363-441d-a69b-49e3f85e748a Map: Dirty Desert Game: 873aaf13-0847-4661-ba26-21e0c66ebe64 Map: Dirty Desert Game: fe89e561-8a93-4e08-84d8-efa88bef383d Map: Dirty Desert Ngoài ra, bằng cách sử dụng PartiQL, bạn có thể chạy ngôn ngữ truy vấn tương thích SQL để truy xuất các mục từ bảng và chỉ mục của DynamoDB.\nBạn có thể truy cập trình chỉnh sửa PartiQL từ menu bên trái sau khi điều hướng đến dịch vụ DynamoDB trong AWS console dưới mục Services, Database, DynamoDB, và chạy một truy vấn để nhận được kết quả tương tự.\nTrong cửa sổ truy vấn, bạn có thể chạy câu lệnh SQL dưới đây. Bạn sẽ thấy bốn game mở cho bản đồ Green Grasslands giống như trên:\nSELECT * FROM \u0026#34;battle-royale\u0026#34;.\u0026#34;OpenGamesIndex\u0026#34; WHERE map = \u0026#39;Green Grasslands\u0026#39; Bạn có thể thay đổi tên bản đồ trong câu lệnh WHERE để xem các game mở cho các bản đồ khác. Ví dụ, hãy kiểm tra xem có bao nhiêu game mở cho bản đồ có tên là Juicy Jungle.\nSELECT * FROM \u0026#34;battle-royale\u0026#34;.\u0026#34;OpenGamesIndex\u0026#34; WHERE map = \u0026#39;Juicy Jungle\u0026#39; "
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.2/7.2.3/",
	"title": "Xem lại Access Patterns",
	"tags": [],
	"description": "",
	"content": "Hãy cùng xem xét các mẫu truy cập khác nhau mà chúng ta cần mô hình hóa dữ liệu.\nXem xét các mẫu truy cập hồ sơ người dùng Người dùng của ứng dụng trò chơi cần tạo hồ sơ người dùng. Những hồ sơ này bao gồm dữ liệu như tên người dùng, ảnh đại diện, thống kê trò chơi, và các thông tin khác về mỗi người dùng. Trò chơi hiển thị các hồ sơ người dùng khi một người dùng đăng nhập. Các người dùng khác có thể xem hồ sơ của một người dùng để xem xét thống kê trò chơi và các chi tiết khác.\nKhi một người dùng chơi các trò chơi, thống kê trò chơi sẽ được cập nhật để phản ánh số lượng trò chơi mà người dùng đã chơi, số lượng trò chơi mà người dùng đã thắng, và số lần tiêu diệt kẻ địch của người dùng.\nDựa trên thông tin này, bạn có ba mẫu truy cập:\nTạo hồ sơ người dùng (Ghi) Cập nhật hồ sơ người dùng (Ghi) Lấy hồ sơ người dùng (Đọc) Xem xét các mẫu truy cập trước trò chơi Trò chơi là một trò chơi trực tuyến nhiều người chơi tương tự như Fortnite hoặc PUBG. Người chơi có thể tạo một trò chơi trên một bản đồ cụ thể, và các người chơi khác có thể tham gia trò chơi đó. Khi đã có 50 người chơi tham gia, trò chơi sẽ bắt đầu và không thể thêm người chơi nào khác.\nKhi tìm kiếm các trò chơi để tham gia, người chơi có thể muốn chơi trên một bản đồ cụ thể. Những người chơi khác có thể không quan tâm đến bản đồ và chỉ muốn duyệt các trò chơi mở trên tất cả các bản đồ.\nDựa trên thông tin này, bạn có bảy mẫu truy cập sau:\nTạo trò chơi (Ghi) Tìm các trò chơi mở (Đọc) Tìm các trò chơi mở theo bản đồ (Đọc) Xem trò chơi (Đọc) Xem người chơi trong trò chơi (Đọc) Tham gia trò chơi cho một người dùng (Ghi) Bắt đầu trò chơi (Ghi) Các mẫu truy cập trong trò chơi và sau trò chơi Cuối cùng, hãy xem xét các mẫu truy cập trong và sau khi kết thúc trò chơi.\nTrong trò chơi, người chơi cố gắng tiêu diệt các người chơi khác với mục tiêu trở thành người chơi cuối cùng còn lại. Ứng dụng theo dõi số lần tiêu diệt của mỗi người chơi trong trò chơi cũng như thời gian sống sót của người chơi trong trò chơi. Nếu một người chơi là một trong ba người chơi cuối cùng sống sót trong trò chơi, người chơi sẽ nhận được huy chương vàng, bạc hoặc đồng cho trò chơi đó.\nSau đó, người chơi có thể muốn xem lại các trò chơi trước đây mà họ đã chơi hoặc các trò chơi mà người chơi khác đã chơi.\nDựa trên thông tin này, bạn có ba mẫu truy cập:\nCập nhật trò chơi cho người dùng (Ghi) Cập nhật trò chơi (Ghi) Tìm tất cả các trò chơi trước đây cho một người dùng (Đọc) Đánh giá Bây giờ bạn đã xác định được tất cả các mẫu truy cập cho ứng dụng trò chơi. Trong các mô-đun tiếp theo, bạn sẽ triển khai các mẫu truy cập này bằng cách sử dụng DynamoDB.\nLưu ý rằng giai đoạn lập kế hoạch có thể cần vài lần lặp lại. Bắt đầu với một ý tưởng tổng quát về các mẫu truy cập mà ứng dụng của bạn cần. Xác định khóa chính, chỉ mục phụ, và các thuộc tính trong bảng của bạn. Quay lại từ đầu và đảm bảo rằng tất cả các mẫu truy cập của bạn đều được đáp ứng. Khi bạn tự tin rằng giai đoạn lập kế hoạch đã hoàn tất, tiến tới giai đoạn triển khai.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.1/3.1.4/",
	"title": "Bước 3 - Kiểm tra cài đặt boto3",
	"tags": [],
	"description": "",
	"content": "Boto3 là Bộ công cụ phát triển phần mềm (SDK) của Amazon Web Services (AWS) dành cho Python, cho phép các nhà phát triển Python xây dựng ứng dụng sử dụng các dịch vụ của AWS.\nTrong cửa sổ shell của EC2, chạy python để mở một bảng điều khiển tương tác với lệnh đầu tiên, sau đó sao chép và dán đoạn mã Python sau:\n# Mở Python: python # Chạy đoạn mã này: import boto3 ddb = boto3.client(\u0026#39;dynamodb\u0026#39;) ddb.describe_limits() Bạn sẽ thấy kết quả sau:\n{u\u0026#39;TableMaxWriteCapacityUnits\u0026#39;: 40000, u\u0026#39;TableMaxReadCapacityUnits\u0026#39;: 40000, u\u0026#39;AccountMaxReadCapacityUnits\u0026#39;: 80000, \u0026#39;ResponseMetadata\u0026#39;: {\u0026#39;RetryAttempts\u0026#39;: 0, \u0026#39;HTTPStatusCode\u0026#39;: 200, \u0026#39;RequestId\u0026#39;: \u0026#39;BFMGAS4P48I3DJTP5NU22QRDDJVV4KQNSO5AEMVJF66Q9ASUAAJG\u0026#39;, \u0026#39;HTTPHeaders\u0026#39;: {\u0026#39;x-amzn-requestid\u0026#39;: \u0026#39;BFMGAS4P48I3DJTP5NU22QRDDJVV4KQNSO5AEMVJF66Q9ASUAAJG\u0026#39;, \u0026#39;content-length\u0026#39;: \u0026#39;143\u0026#39;, \u0026#39;server\u0026#39;: \u0026#39;Server\u0026#39;, \u0026#39;connection\u0026#39;: \u0026#39;keep-alive\u0026#39;, \u0026#39;x-amz-crc32\u0026#39;: \u0026#39;3062975651\u0026#39;, \u0026#39;date\u0026#39;: \u0026#39;Tue, 31 Dec 2020 00:00:00 GMT\u0026#39;, \u0026#39;content-type\u0026#39;: \u0026#39;application/x-amz-json-1.0\u0026#39;}}, u\u0026#39;AccountMaxWriteCapacityUnits\u0026#39;: 80000} Để đóng bảng điều khiển Python, gõ:\nquit() "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.9/3.9.4/",
	"title": "Bước 4 - Bật luồng DynamoDB",
	"tags": [],
	"description": "",
	"content": "Bây giờ chúng ta đã tạo một hàm AWS Lambda để xử lý các bản ghi từ DynamoDB Streams, chúng ta cần kích hoạt DynamoDB Stream trên bảng logfile. Trong bước tiếp theo, chúng ta sẽ kết nối stream với hàm Lambda.\nChúng ta sẽ kích hoạt stream trên bảng logfile. Khi một stream được kích hoạt, bạn có thể chọn liệu DynamoDB sao chép mục mới, mục cũ, cả mục cũ và mới, hoặc chỉ khóa phân vùng và khóa sắp xếp của một mục đã được tạo, cập nhật, hoặc xóa. Để biết thêm thông tin về các tùy chọn khác nhau, bạn có thể xem tài liệu về StreamSpecification, liệt kê các tùy chọn như sau: NEW_IMAGE, OLD_IMAGE, NEW_AND_OLD_IMAGES, hoặc KEYS_ONLY.\nKích hoạt DynamoDB Streams cho bảng logfile với tùy chọn NEW_IMAGE, bao gồm \u0026ldquo;Toàn bộ mục, như nó xuất hiện sau khi được sửa đổi, được ghi vào stream\u0026rdquo; theo tài liệu liên kết ở trên.\naws dynamodb update-table --table-name \u0026#39;logfile\u0026#39; --stream-specification StreamEnabled=true,StreamViewType=NEW_IMAGE Lấy ARN đầy đủ cho DynamoDB Streams trong kết quả. Chúng ta sẽ cần nó cho bước tiếp theo.\naws dynamodb describe-table --table-name \u0026#39;logfile\u0026#39; --query \u0026#39;Table.LatestStreamArn\u0026#39; --output text Kết quả sẽ trông giống như sau:\narn:aws:dynamodb:\u0026lt;REGION\u0026gt;:\u0026lt;ACCOUNTID\u0026gt;:table/logfile/stream/2018-10-27T02:15:46.245 Ghi chú ARN này để sử dụng trong bước tiếp theo.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.8/3.8.4/",
	"title": "Bước 4 - Truy vấn chi tiết Khách hàng và Chi tiết hóa đơn bằng cách sử dụng Index",
	"tags": [],
	"description": "",
	"content": "Truy vấn bằng ID khách hàng và xem lại kết quả hiển thị chi tiết khách hàng và danh sách các hóa đơn liên quan. Lưu ý cách đầu ra hiển thị tất cả các hóa đơn được liên kết với khách hàng.\npython query_index_invoiceandbilling.py InvoiceAndBills \u0026#39;C#1249\u0026#39; Đây là một cái nhìn về đầu ra.\n========================================================= Invoice ID: I#661, Customer ID: C#1249 Invoice ID: I#1249, Customer ID: C#1249 ========================================================= Bây giờ, truy vấn bằng ID hóa đơn và xem lại đầu ra hiển thị chi tiết hóa đơn và chi tiết của các hóa đơn được liên kết. Lưu ý cách đầu ra hiển thị tất cả các hóa đơn được liên kết với một hóa đơn cụ thể.\nChạy tập lệnh Python sau:\npython query_index_invoiceandbilling.py InvoiceAndBills \u0026#39;B#3392\u0026#39; Đây là một cái nhìn về đầu ra.\n========================================================= Invoice ID: I#506, Bill ID: B#3392, BillAmount: $383,572.00 , BillBalance: $5,345,699.00 Invoice ID: I#1721, Bill ID: B#3392, BillAmount: $401,844.00 , BillBalance: $25,408,787.00 Invoice ID: I#390, Bill ID: B#3392, BillAmount: $581,765.00 , BillBalance: $11,588,362.00 ========================================================= "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.2/3.2.4/",
	"title": "Bước 4 - Xem số liệu CloudWatch trên table của bạn",
	"tags": [],
	"description": "",
	"content": "Để xem các số liệu Amazon CloudWatch cho bảng của bạn:\nĐiều hướng đến phần DynamoDB trong bảng điều khiển quản lý AWS.\nNhư hình dưới đây, trong bảng điều hướng, chọn Tables. Chọn bảng logfile, và trong ngăn bên phải, chọn tab Metrics.\nCác số liệu CloudWatch sẽ trông như hình dưới đây.\nBạn có thể không thấy dữ liệu dung lượng được cấp phát trong các biểu đồ dung lượng đọc hoặc ghi, được hiển thị dưới dạng các đường màu đỏ. Việc DynamoDB tạo ra các số liệu CloudWatch về dung lượng được cấp phát mất thời gian, đặc biệt là đối với các bảng mới.\nCác số liệu CloudWatch sẽ trông như hình dưới đây đối với chỉ mục phụ toàn cầu (GSI).\nBạn có thể đang tự hỏi: Tại sao có các sự kiện giới hạn (throttling) trên bảng cơ sở nhưng không có trên chỉ mục phụ toàn cầu? Lý do là bảng cơ sở nhận các ghi chép ngay lập tức và tiêu thụ dung lượng ghi khi thực hiện, trong khi dung lượng của chỉ mục phụ toàn cầu (GSI) được tiêu thụ không đồng bộ sau một thời gian kể từ khi ghi thành công vào bảng cơ sở. Để hệ thống này hoạt động bên trong dịch vụ DynamoDB, có một bộ đệm giữa một bảng DynamoDB cơ sở và một chỉ mục phụ toàn cầu (GSI). Một bảng cơ sở sẽ nhanh chóng gặp phải giới hạn nếu dung lượng bị cạn kiệt, trong khi chỉ một sự mất cân đối trong thời gian dài trên GSI mới làm đầy bộ đệm, dẫn đến việc tạo ra giới hạn. Tóm lại, GSI khoan dung hơn trong trường hợp mô hình truy cập không cân đối.\nTiếp tục bài tập này để xem điều gì xảy ra khi bạn tăng thêm dung lượng ghi cho bảng cơ sở DynamoDB.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.7/3.7.4/",
	"title": "Bước 4- Truy vấn tất cả nhân viên (employees) của một thành phố (city) và một phòng ban (department) cụ thể",
	"tags": [],
	"description": "",
	"content": "Bạn cũng có thể sử dụng global secondary index để truy vấn nhân viên theo tiểu bang. Chạy tập lệnh Python sau để liệt kê tất cả nhân viên trong bộ phận Vận hành ở Dallas, Texas.\npython query_city_dept.py employees TX --citydept \u0026#39;Dallas#Op\u0026#39; Ra:\nList of employees . State: TX Name: Brady Marvel. City: Dallas. Dept: Operation Name: Emmye Fletcher. City: Dallas. Dept: Operation Name: Audra Leahey. City: Dallas. Dept: Operation Name: Waneta Parminter. City: Dallas. Dept: Operation Name: Lizbeth Proudler. City: Dallas. Dept: Operation Name: Arlan Cummings. City: Dallas. Dept: Operation Name: Bone Ruggs. City: Dallas. Dept: Operation Name: Karlis Prisk. City: Dallas. Dept: Operation Name: Marve Bignold. City: Dallas. Dept: Operation Total of employees: 9. Execution time: 0.174154996872 seconds Trong bài tập này, chúng ta đã tạo một chỉ mục phụ toàn cục để truy vấn các thuộc tính bổ sung. Dữ liệu hiện có thể được truy xuất bằng cách sử dụng các trường City và Department.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.3/4.3.4/",
	"title": "Cập nhật IAM Role",
	"tags": [],
	"description": "",
	"content": "Cấu hình hàm Lambda của bạn để sao chép các bản ghi đã thay đổi từ DynamoDB streams của bảng Orders sang bảng OrdersHistory bằng cách thực hiện các bước sau.\nTruy cập bảng điều khiển IAM trên AWS Management Console và kiểm tra chính sách IAM, tức là AWSLambdaMicroserviceExecutionRole\u0026hellip;, được tạo khi bạn tạo hàm Lambda create-order-history-ddbs. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DeleteItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:{aws-region}:{aws-account-id}:table/*\u0026#34; } ] } Cập nhật câu lệnh chính sách bằng cách chỉnh sửa và thay thế chính sách hiện tại bằng câu lệnh chính sách IAM sau. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DescribeStream\u0026#34;, \u0026#34;dynamodb:GetRecords\u0026#34;, \u0026#34;dynamodb:GetShardIterator\u0026#34;, \u0026#34;dynamodb:ListStreams\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:{aws-region}:{aws-account-id}:table/Orders/stream/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:{aws-region}:{aws-account-id}:table/OrdersHistory\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sqs:SendMessage\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sqs:{aws-region}:{aws-account-id}:orders-ddbs-dlq\u0026#34; } ] } Chính sách IAM đã cập nhật cung cấp cho hàm Lambda create-order-history-ddbs quyền cần thiết để đọc các sự kiện từ stream của bảng Orders DynamoDB, ghi các mục mới vào bảng OrdersHistory DynamoDB và gửi tin nhắn đến hàng đợi SQS orders-ddbs-dlq.\nThay thế {aws-region} và {aws-account-id} trong câu lệnh chính sách trên bằng giá trị đúng cho khu vực AWS của bạn và ID tài khoản AWS của bạn.\nĐi đến trình chỉnh sửa bảng điều khiển hàm Lambda. Chọn Layers sau đó chọn Add a Layer. Chọn Specify an ARN, nhập ARN của Lambda Layer dưới đây. arn:aws:lambda:{aws-region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:58 Nhấp vào Verify sau đó chọn Add. Thay thế {aws-region} bằng ID của khu vực AWS mà bạn đang làm việc.\nĐi đến phần cấu hình của trình chỉnh sửa bảng điều khiển Lambda. Chọn Environment variables sau đó chọn Edit. Thêm một biến môi trường mới có tên ORDERS_HISTORY_DB và đặt giá trị của nó là OrdersHistory. Chọn Triggers sau đó chọn Add trigger. Chọn DynamoDB làm nguồn kích hoạt. Chọn bảng DynamoDB Orders. Đặt Batch size thành 10 và giữ nguyên các giá trị khác. Nhấp vào Additional settings để mở rộng phần này. Cung cấp ARN của hàng đợi SQS orders-ddbs-dlq mà bạn đã tạo trước đó. arn:aws:sqs:{aws-region}:{aws-account-id}:orders-ddbs-dlq Đặt số lần thử lại (Retry attempts) thành 3. Chọn Add. "
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.4/4.4.4/",
	"title": "Cấu hình hàm Lambda",
	"tags": [],
	"description": "",
	"content": "Cấu hình hàm Lambda của bạn để sao chép các bản ghi đã thay đổi từ Orders Kinesis Data Stream sang bảng OrdersHistory.\nTruy cập trang tổng quan IAM trên AWS Management Console và kiểm tra chính sách IAM, ví dụ: AWSLambdaMicroserviceExecutionRole\u0026hellip;, được tạo khi bạn tạo hàm Lambda create-order-history-kds. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:DeleteItem\u0026#34;, \u0026#34;dynamodb:GetItem\u0026#34;, \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;dynamodb:Scan\u0026#34;, \u0026#34;dynamodb:UpdateItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:{aws-region}:{aws-account-id}:table/*\u0026#34; } ] } Cập nhật câu lệnh chính sách bằng cách chỉnh sửa và thay thế chính sách hiện có bằng câu lệnh chính sách IAM sau. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kinesis:DescribeStream\u0026#34;, \u0026#34;kinesis:GetRecords\u0026#34;, \u0026#34;kinesis:GetShardIterator\u0026#34;, \u0026#34;kinesis:ListStreams\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:kinesis:{aws-region}:{aws-account-id}:stream/Orders\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:PutItem\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:{aws-region}:{aws-account-id}:table/OrdersHistory\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sqs:SendMessage\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sqs:{aws-region}:{aws-account-id}:orders-kds-dlq\u0026#34; } ] } Thay thế {aws-region} và {aws-account-id} trong câu lệnh chính sách trên bằng AWS region và ID tài khoản AWS của bạn tương ứng.\nChọn Layers, sau đó chọn Add a Layer. Chọn Specify an ARN, nhập ARN của Lambda Layer bên dưới. arn:aws:lambda:{aws-region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:58 Nhấp vào Verify, sau đó chọn Add. Thay thế {aws-region} bằng ID cho AWS region mà bạn đang làm việc.\nĐi đến phần cấu hình của trình soạn thảo console Lambda. Chọn Environment variables rồi chọn Edit. Thêm một biến môi trường mới có tên ORDERS_HISTORY_DB và đặt giá trị của nó là OrdersHistory. Đi đến phần cấu hình của trình soạn thảo console Lambda. Chọn Triggers, sau đó chọn Add trigger. Chọn Kinesis làm nguồn kích hoạt. Chọn bảng DynamoDB Orders. Đặt Batch size là 10 và để tất cả các giá trị khác không thay đổi. Nhấp vào Additional settings để mở rộng phần này. Cung cấp ARN của hàng đợi SQS orders-kds-dlq mà bạn đã tạo trước đó. Đặt Retry attempts thành 3. Chọn Add. "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.3/1.3.4/",
	"title": "Điều chỉnh dữ liệu",
	"tags": [],
	"description": "",
	"content": "Chèn Dữ Liệu DynamoDB cung cấp API PutItem để tạo một mục mới hoặc thay thế hoàn toàn các mục hiện có bằng một mục mới. Nó được gọi bằng lệnh CLI put-item.\nGiả sử chúng ta muốn chèn một mục mới vào bảng Reply từ giao diện điều khiển. Đầu tiên, điều hướng đến bảng Reply và nhấp vào nút Create Item (Tạo Mục).\nNhấp vào JSON view, đảm bảo rằng View DynamoDB JSON chưa được chọn, dán JSON sau và sau đó nhấp vào Create Item để chèn mục mới.\n{ \u0026#34;Id\u0026#34; : \u0026#34;Amazon DynamoDB#DynamoDB Thread 2\u0026#34;, \u0026#34;ReplyDateTime\u0026#34; : \u0026#34;2021-04-27T17:47:30Z\u0026#34;, \u0026#34;Message\u0026#34; : \u0026#34;DynamoDB Thread 2 Reply 3 text\u0026#34;, \u0026#34;PostedBy\u0026#34; : \u0026#34;User C\u0026#34; } Cập Nhật hoặc Xóa Dữ Liệu DynamoDB cung cấp API UpdateItem để tạo một mục mới hoặc thay thế hoàn toàn các mục hiện có bằng một mục mới. Nó được gọi bằng lệnh CLI update-item. API này yêu cầu bạn phải chỉ định đầy đủ Khóa Chính và có thể tùy chọn sửa đổi các thuộc tính cụ thể mà không thay đổi các thuộc tính khác (bạn không cần phải truyền toàn bộ mục).\nDynamoDB cung cấp API DeleteItem để xóa một mục. Nó được gọi bằng lệnh CLI delete-item.\nBạn có thể dễ dàng sửa đổi hoặc xóa một mục bằng cách sử dụng giao diện điều khiển bằng cách chọn hộp kiểm bên cạnh mục bạn quan tâm, nhấp vào menu thả xuống Actions (Hành động) và thực hiện hành động mong muốn.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.4/",
	"title": "Exercise 3: Global Secondary Index Write Sharding",
	"tags": [],
	"description": "",
	"content": "Khóa chính của một bảng DynamoDB hoặc một chỉ mục phụ toàn cầu bao gồm một khóa phân vùng và một khóa sắp xếp tùy chọn. Cách bạn thiết kế nội dung của các khóa này rất quan trọng đối với cấu trúc và hiệu suất của cơ sở dữ liệu. Các giá trị khóa phân vùng xác định các phân vùng logic mà dữ liệu của bạn được lưu trữ. Do đó, việc chọn một giá trị khóa phân vùng phân phối đồng đều khối lượng công việc trên tất cả các phân vùng trong bảng hoặc chỉ mục phụ toàn cầu là rất quan trọng. Để thảo luận về cách chọn khóa phân vùng phù hợp, hãy xem bài viết trên blog của chúng tôi có tiêu đề Choosing the Right DynamoDB Partition Key.\nTrong bài tập này, bạn sẽ tìm hiểu về phương pháp ghi phân mảnh (write sharding) trên chỉ mục phụ toàn cầu, đây là một mẫu thiết kế hiệu quả để truy vấn chọn lọc các mục được phân tán trên các phân vùng logic khác nhau trong một bảng rất lớn. Hãy xem lại ví dụ nhật ký truy cập máy chủ từ [Bài tập 1]{href=\u0026quot;/design-patterns/ex1capacity\u0026quot;}, dựa trên nhật ký truy cập dịch vụ Apache. Lần này, bạn sẽ truy vấn các mục có mã phản hồi 4xx. Lưu ý rằng các mục có mã phản hồi 4xx chiếm một tỷ lệ rất nhỏ trong tổng số dữ liệu và không có sự phân bố đồng đều theo mã phản hồi. Ví dụ, mã phản hồi 200 OK có nhiều bản ghi hơn các mã khác, điều này là mong đợi cho bất kỳ ứng dụng web nào.\nBiểu đồ sau đây cho thấy sự phân bố của các bản ghi nhật ký theo mã phản hồi cho tệp mẫu, logfile_medium1.csv.\nBạn sẽ tạo một chỉ mục phụ toàn cầu ghi phân mảnh trên một bảng để ngẫu nhiên hóa các lượt ghi trên nhiều giá trị khóa phân vùng logic. Việc này sẽ tăng thông lượng ghi và đọc của ứng dụng. Để áp dụng mẫu thiết kế này, bạn có thể tạo một số ngẫu nhiên từ một tập cố định (ví dụ: 1 đến 10) và sử dụng số này làm khóa phân vùng logic cho chỉ mục phụ toàn cầu. Vì bạn đang ngẫu nhiên hóa khóa phân vùng, các lượt ghi vào bảng sẽ được phân phối đồng đều trên tất cả các giá trị khóa phân vùng, không phụ thuộc vào bất kỳ thuộc tính nào. Điều này sẽ mang lại khả năng song song tốt hơn và thông lượng tổng thể cao hơn. Ngoài ra, nếu ứng dụng cần truy vấn các bản ghi nhật ký theo một mã phản hồi cụ thể vào một ngày cụ thể, bạn có thể tạo một khóa sắp xếp tổng hợp bằng cách kết hợp mã phản hồi và ngày.\nTrong bài tập này, bạn sẽ tạo một chỉ mục phụ toàn cầu sử dụng các giá trị ngẫu nhiên cho khóa phân vùng và khóa tổng hợp responsecode#date#hourofday làm khóa sắp xếp. Bảng logfile_scan mà bạn đã tạo và nạp dữ liệu trong giai đoạn chuẩn bị của workshop đã có hai thuộc tính này. Nếu bạn chưa hoàn thành các bước thiết lập, hãy quay lại Thiết lập - Bước 6 và hoàn thành bước này. Các thuộc tính này đã được tạo bằng đoạn mã sau:\nSHARDS = 10 newitem[\u0026#39;GSI_1_PK\u0026#39;] = \u0026#34;shard#{}\u0026#34;.format((newitem[\u0026#39;requestid\u0026#39;] % SHARDS) + 1) newitem[\u0026#39;GSI_1_SK\u0026#39;] = row[7] + \u0026#34;#\u0026#34; + row[2] + \u0026#34;#\u0026#34; + row[3] "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.5/1.5.4/",
	"title": "Explore Source Model",
	"tags": [],
	"description": "",
	"content": "IMDb (Internet Movie Database) là một trong những tên tuổi nổi tiếng nhất với bộ sưu tập cơ sở dữ liệu trực tuyến toàn diện về phim, phim truyền hình, series TV, và nhiều hơn nữa. Bài tập này sẽ sử dụng một phần của bộ dữ liệu IMDb (có sẵn ở định dạng TSV). Workshop này sẽ sử dụng 6 bộ dữ liệu IMDb liên quan đến các bộ phim ở Mỹ kể từ năm 2000. Bộ dữ liệu này có khoảng hơn 106.000 phim, đánh giá, bình chọn và thông tin về dàn diễn viên/đội ngũ sản xuất.\nMẫu CloudFormation đã khởi chạy một phiên bản Amazon Linux 2 EC2 với MySQL đã được cài đặt và chạy. Nó đã tạo cơ sở dữ liệu IMDb, 6 bảng mới (mỗi bảng cho một bộ dữ liệu IMDb), tải các tệp TSV IMDb vào thư mục cục bộ trên máy chủ MySQL và tải các tệp này vào 6 bảng mới. Để khám phá bộ dữ liệu, hãy làm theo các hướng dẫn dưới đây để đăng nhập vào máy chủ EC2. Mẫu này cũng đã cấu hình một người dùng MySQL từ xa dựa trên tham số đầu vào của CloudFormation.\nTruy cập EC2 console\nChọn MySQL-Instance và nhấp vào Connect.\nĐảm bảo ec2-user đã được điền vào trường User name. Nhấp vào Connect.\nTăng quyền hạn của bạn bằng cách sử dụng lệnh sudo:\nsudo su Truy cập vào thư mục tệp:\ncd /var/lib/mysql-files/ ls -lrt Bạn có thể thấy tất cả 6 tệp được sao chép từ bộ dữ liệu IMDB vào thư mục cục bộ của EC2.\nHãy thoải mái khám phá các tệp này.\nTruy cập AWS CloudFormation Stacks và nhấp vào stack bạn đã tạo trước đó. Truy cập tab Parameters và sao chép tên người dùng và mật khẩu được đề cập bên cạnh DbMasterUsername và DbMasterPassword.\nQuay lại bảng điều khiển EC2 Instance và đăng nhập vào MySQL:\nmysql -u DbMasterUsername -pDbMasterPassword Chúc mừng bạn! Bạn đã kết nối thành công với cơ sở dữ liệu MySQL tự quản lý trên EC2. Ở các bước tiếp theo, chúng ta sẽ khám phá cơ sở dữ liệu và các bảng lưu trữ bộ dữ liệu IMDb: use imdb; Hiển thị tất cả các bảng đã được tạo: show tables; Để minh họa, dưới đây là sơ đồ logic thể hiện mối quan hệ giữa các bảng nguồn lưu trữ bộ dữ liệu IMDb:\nBảng title_basics chứa các phim được phát hành ở Mỹ sau năm 2000. tconst là một khóa chữ-số duy nhất được gán cho mỗi bộ phim. Bảng title_akas chứa các vùng phát hành, ngôn ngữ và tiêu đề phim tương ứng. Đây là mối quan hệ 1:n với bảng title_basics. Bảng title_ratings chứa đánh giá phim và số phiếu bầu. Đối với bài tập này, chúng ta có thể giả định thông tin này được cập nhật với tần suất cao sau khi phim được phát hành. Đây là mối quan hệ 1:1 với bảng title_basics. Bảng title_principals chứa thông tin về dàn diễn viên và đội ngũ sản xuất. Đây là mối quan hệ 1:n với bảng title_basics. Bảng title_crew chứa thông tin về biên kịch và đạo diễn. Bảng này có mối quan hệ 1:1 với bảng title_basics. Bảng name_basics chứa chi tiết về dàn diễn viên và đội ngũ sản xuất. Mỗi thành viên có giá trị nconst duy nhất được gán.\nChúng ta sẽ tạo một view đã phi chuẩn hóa với thông tin tĩnh 1:1 và chuẩn bị sẵn sàng để di chuyển sang bảng Amazon DynamoDB. Bây giờ, hãy sao chép và dán đoạn mã dưới đây vào dòng lệnh MySQL. Chi tiết về mô hình dữ liệu mục tiêu sẽ được thảo luận trong chương tiếp theo. CREATE VIEW imdb.movies AS\\ SELECT tp.tconst,\\ tp.ordering,\\ tp.nconst,\\ tp.category,\\ tp.job,\\ tp.characters,\\ tb.titleType,\\ tb.primaryTitle,\\ tb.originalTitle,\\ tb.isAdult,\\ tb.startYear,\\ tb.endYear,\\ tb.runtimeMinutes,\\ tb.genres,\\ nm.primaryName,\\ nm.birthYear,\\ nm.deathYear,\\ nm.primaryProfession,\\ tc.directors,\\ tc.writers\\ FROM imdb.title_principals tp\\ LEFT JOIN imdb.title_basics tb ON tp.tconst = tb.tconst\\ LEFT JOIN imdb.name_basics nm ON tp.nconst = nm.nconst\\ LEFT JOIN imdb.title_crew tc ON tc.tconst = tp.tconst; Sử dụng lệnh dưới đây để xem số lượng bản ghi từ view đã phi chuẩn hóa. Ở thời điểm này, cơ sở dữ liệu nguồn của bạn đã sẵn sàng để di chuyển sang Amazon DynamoDB.\nselect count(*) from imdb.movies; "
},
{
	"uri": "//localhost:1313/vi/6-leda/6.4/",
	"title": "Lab 2: Đảm bảo khả năng chịu lỗi và xử lý chính xác một lần",
	"tags": [],
	"description": "",
	"content": " Điểm và bảng xếp hạng chỉ áp dụng khi phòng lab này được thực hiện trong một sự kiện AWS.\nBạn đã sẵn sàng bắt đầu Lab 2 chưa? Trước khi tiến hành Lab 2, hãy xác minh rằng Lab 1 đã được hoàn thành thành công. Có hai giai đoạn cần hoàn thành trước khi tiếp tục:\nThứ nhất, bạn đã bắt đầu tích lũy điểm trên bảng xếp hạng. Nếu bạn có số điểm khác không, thì giai đoạn này đã hoàn thành. Mở bảng xếp hạng và tìm đội của bạn. Tìm ID tài khoản của bạn trong AWS Management Console ở góc trên bên phải của bảng điều khiển. Thứ hai, bạn cần tích lũy 300 điểm để tiếp tục. Workshop sẽ tự động chuyển sang Lab 2 khi bạn đạt được mốc này, và giai đoạn này hoàn thành. Khi tích lũy đủ 300 điểm, các chế độ lỗi mới sẽ được giới thiệu và cả ba hàm Lambda (StateLambda, MapLambda, và ReduceLambda) sẽ bắt đầu thất bại ngẫu nhiên. Đây là sự phát triển được lập trình sẵn của workshop. Trong Lambda console, nhấp vào bất kỳ hàm Lambda nào trong ba hàm, điều hướng đến tab Monitor và sau đó đến sub-tab Metrics. Bạn nên thấy tỷ lệ lỗi khác không trên một số đồ thị! Nếu bảng điều khiển đã có 300 điểm, thì xin chúc mừng: bạn có thể bắt đầu Lab 2!\nHãy sử dụng các tính năng khác nhau của DynamoDB để đảm bảo tính toàn vẹn dữ liệu và khả năng chịu lỗi Trong Lab 2, chúng ta sẽ đạt được quá trình xử lý thông điệp đúng một lần duy nhất. Để đảm bảo rằng pipeline của chúng ta có thể chịu được các chế độ lỗi khác nhau và đạt được quá trình xử lý thông điệp đúng một lần.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/",
	"title": "LCDC: Change Data Capture for Amazon DynamoDB",
	"tags": [],
	"description": "",
	"content": "Trong hội thảo này, bạn sẽ tìm hiểu cách thực hiện thu thập dữ liệu thay đổi đối với các thay đổi ở cấp độ mục trên bảng DynamoDB bằng cách sử dụng Luồng Amazon DynamoDB và Amazon Kinesis Data Streams . Kỹ thuật này cho phép bạn phát triển các giải pháp theo sự kiện được khởi tạo bằng những thay đổi được thực hiện đối với dữ liệu cấp mục được lưu trữ trong DynamoDB.\nĐây là những gì hội thảo này bao gồm:\nBắt đầu Tổng quan kịch bản Thay đổi Thu thập dữ liệu bằng DynamoDB Streams Thay đổi tính năng Thu thập dữ liệu bằng Kinesis Data Streams Tóm tắt và dọn dẹp Đối tượng mục tiêu Hội thảo này được thiết kế cho các nhà phát triển, kỹ sư và quản trị viên cơ sở dữ liệu tham gia thiết kế và duy trì các ứng dụng DynamoDB.\nYêu cầu Kiến thức cơ bản về dịch vụ AWS Trong số các dịch vụ khác, phòng thí nghiệm này sẽ hướng dẫn bạn sử dụng Đám mây AWS9 và AWS Lambda . Hiểu biết cơ bản về DynamoDB Nếu bạn không quen thuộc với DynamoDB hoặc không tham gia phòng thực hành này như một phần của sự kiện AWS, hãy cân nhắc xem lại tài liệu về \u0026ldquo;Amazon DynamoDB là gì? \u0026quot; Đề xuất nghiên cứu trước khi dùng phòng thí nghiệm Nếu bạn không tham gia sự kiện AWS và gần đây bạn chưa xem xét các khái niệm thiết kế của DynamoDB, chúng tôi khuyên bạn nên xem video này trên Mẫu thiết kế nâng cao cho DynamoDB , thời lượng khoảng một giờ.\n"
},
{
	"uri": "//localhost:1313/vi/5-lmr/5.4/",
	"title": "Module 3: Tương tác với Giao diện Globalflix",
	"tags": [],
	"description": "",
	"content": "Điều hướng đến Ứng dụng Web Globalflix Nhấp vào liên kết dưới đây để mở ứng dụng web Globalflix, hoặc nếu bạn vẫn còn mở ứng dụng từ mô-đun 2, hãy nhấp vào logo Globalflix ở góc trên bên phải. https://amazon-dynamodb-labs.com/static/global-serverless-application/web/globalflix.html\nNếu bạn đã tải thành công các URL API trong mô-đun trước, bạn sẽ thấy một lưới gồm 12 hình thu nhỏ của video. Đây là kết quả của một truy vấn chống lại DynamoDB cho dữ liệu mẫu mà bạn đã tải trong mô-đun 1.\nKhu vực API mà bạn đã thiết lập trong mô-đun trước sẽ được hiển thị ở góc trên bên phải, với khu vực \u0026ldquo;đang hoạt động\u0026rdquo; hiện tại được đánh dấu màu cam đậm.\nChọn khu vực được viền để thực hiện \u0026ldquo;chuyển đổi\u0026rdquo; cục bộ sang khu vực thứ hai Để tiết kiệm thời gian trong mô-đun này, chúng ta sẽ thực hiện chuyển đổi khu vực trong ứng dụng web, nhưng trong sản xuất, một mô hình phổ biến hơn là sử dụng Amazon Route 53 Application Recovery Controller để quản lý các kiểm tra sức khỏe, chuyển đổi và khôi phục các dịch vụ khu vực của bạn.\nXem một video để bắt đầu tải các điểm đánh dấu vào cơ sở dữ liệu Nhấp vào bất kỳ video nào để tải trang trình phát video. Trên trang này, video đã chọn sẽ bắt đầu phát ở giữa với các chỉ số sau được hiển thị xung quanh (từ trái sang phải):\nTiến trình Video: Dấu thời gian hiện tại của tiến trình qua video như được thấy bởi trình duyệt web của bạn Độ trễ ghi: Thời gian tính bằng mili giây để ghi điểm đánh dấu cuối cùng vào cơ sở dữ liệu Tiến trình Khu vực 1 và 2: Dấu thời gian hiện tại của tiến trình qua video khi đọc mục điểm đánh dấu từ mỗi khu vực Bên dưới trình phát, bạn có thể thấy nhật ký của mỗi thao tác ghi được thực hiện, lưu ý đến khu vực đang được sử dụng.\nMô phỏng sự cố Khu vực Quay lại bảng điều khiển AWS và tìm kiếm \u0026ldquo;Lambda\u0026rdquo; bằng thanh tìm kiếm ở trên cùng Một hàm có tên \u0026ldquo;global-serverless-dev\u0026rdquo; sẽ được liệt kê trên trang các hàm, nhấp vào tên hàm đó. Nếu bạn không thấy nó được liệt kê, hãy kiểm tra để đảm bảo bạn đang ở một trong hai khu vực mà bạn đã triển khai với Chalice ở góc trên bên phải của trang Sử dụng nút Throttle ở góc trên bên phải của trang để đặt mức độ đồng thời tối đa của hàm Lambda thành 0, dừng bất kỳ lời gọi nào trong tương lai của hàm trong khu vực này. Quay lại trình phát video Globalflix và quan sát rằng một lỗi API trong khu vực đó đã được phát hiện Chờ ứng dụng chờ đợi để chuyển đổi khu vực Mặc dù ngăn xếp ứng dụng trong khu vực đó hiện không phản hồi, vì chúng ta đang sử dụng Bảng Toàn cầu DynamoDB, các cập nhật dữ liệu vẫn được sao chép vào khu vực đó. Khi dịch vụ khôi phục, chúng ta không cần lo lắng về việc mất dữ liệu trong thời gian ngừng hoạt động.\nBạn có thể xác minh điều này nếu muốn bằng cách chạy truy vấn chống lại Bảng DynamoDB \u0026ldquo;global-serverless\u0026rdquo; ở mỗi khu vực của bạn\naws dynamodb query \\ --table-name global-serverless \\ --region us-west-2 \\ --key-condition-expression \u0026#34;PK = :PK\u0026#34; \\ --expression-attribute-values \u0026#39;{\u0026#34;:PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;user10\u0026#34;}}\u0026#39; \\ --query \u0026#39;Items[*].bookmark.S\u0026#39; \\ --output text | awk \u0026#39;{print $1\u0026#34;: us-west-2\u0026#34;}\u0026#39; aws dynamodb query \\ --table-name global-serverless \\ --region eu-west-1 \\ --key-condition-expression \u0026#34;PK = :PK\u0026#34; \\ --expression-attribute-values \u0026#39;{\u0026#34;:PK\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;user10\u0026#34;}}\u0026#39; \\ --query \u0026#39;Items[*].bookmark.S\u0026#39; \\ --output text | awk \u0026#39;{print $1\u0026#34;: eu-west-1\u0026#34;}\u0026#39; Quay lại bảng điều khiển Lambda và nhấp vào \u0026ldquo;Edit concurrency\u0026rdquo; ở góc trên bên phải Chọn nút \u0026ldquo;Use unreserved account concurrency\u0026rdquo; và sau đó nhấp vào Save Ứng dụng linh hoạt của bạn đã thành công xử lý sự cố ngăn xếp khu vực, chuyển đổi sang khu vực thay thế, và chuyển đổi trở lại, tất cả mà không mất dữ liệu hoặc ảnh hưởng đến trải nghiệm người dùng.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.4/7.4.4/",
	"title": "Quét sparse GSI",
	"tags": [],
	"description": "",
	"content": "Trong bước trước, bạn đã thấy cách tìm game cho một bản đồ cụ thể. Một số người chơi có thể thích chơi trên một bản đồ cụ thể, vì vậy điều này rất hữu ích. Những người chơi khác có thể sẵn sàng tham gia bất kỳ game nào trên bất kỳ bản đồ nào. Trong phần này, bạn sẽ học cách tìm bất kỳ game mở nào trong ứng dụng, bất kể loại bản đồ. Để làm điều này, bạn sử dụng API Scan.\nThông thường, bạn không nên thiết kế bảng của mình để sử dụng thao tác Scan của DynamoDB vì DynamoDB được xây dựng cho các truy vấn chính xác để lấy những thực thể cần thiết. Thao tác Scan lấy ngẫu nhiên một tập hợp các thực thể trong bảng của bạn, vì vậy việc tìm kiếm các thực thể cần thiết có thể yêu cầu nhiều lần truy xuất đến cơ sở dữ liệu.\nTuy nhiên, đôi khi Scan có thể hữu ích. Ví dụ, khi bạn có một chỉ mục thứ cấp thưa (sparse secondary index), nghĩa là chỉ mục đó không có quá nhiều thực thể. Ngoài ra, chỉ mục chỉ bao gồm các game vẫn đang mở, và đó chính là những gì bạn cần.\nĐối với trường hợp sử dụng này, Scan hoạt động rất tốt. Hãy xem cách nó hoạt động. Trong mã mà bạn đã tải xuống, tệp find_open_games.py nằm trong thư mục scripts/.\nimport boto3 from entities import Game dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) def find_open_games(): resp = dynamodb.scan( TableName=\u0026#39;battle-royale\u0026#39;, IndexName=\u0026#34;OpenGamesIndex\u0026#34;, ) games = [Game(item) for item in resp[\u0026#39;Items\u0026#39;]] return games games = find_open_games() print(\u0026#34;Open games:\u0026#34;) for game in games: print(game) Mã này tương tự như mã trong bước trước. Tuy nhiên, thay vì sử dụng phương thức query() trên client DynamoDB, bạn sử dụng phương thức scan(). Vì bạn đang sử dụng scan(), bạn không cần phải chỉ định bất kỳ điều gì về điều kiện khóa như đã làm với query(). DynamoDB sẽ trả về một nhóm các mục mà không có thứ tự cụ thể nào.\nChạy script với lệnh sau trong terminal:\npython scripts/find_open_games.py Terminal của bạn sẽ hiển thị danh sách chín game đang mở trên nhiều bản đồ khác nhau.\nOpen games: Game: c6f38a6a-d1c5-4bdf-8468-24692ccc4646 Map: Urban Underground Game: d06af94a-2363-441d-a69b-49e3f85e748a Map: Dirty Desert Game: 873aaf13-0847-4661-ba26-21e0c66ebe64 Map: Dirty Desert Game: fe89e561-8a93-4e08-84d8-efa88bef383d Map: Dirty Desert Game: 248dd9ef-6b17-42f0-9567-2cbd3dd63174 Map: Juicy Jungle Game: 14c7f97e-8354-4ddf-985f-074970818215 Map: Green Grasslands Game: 3d4285f0-e52b-401a-a59b-112b38c4a26b Map: Green Grasslands Game: 683680f0-02b0-4e5e-a36a-be4e00fc93f3 Map: Green Grasslands Game: 0ab37cf1-fc60-4d93-b72b-89335f759581 Map: Green Grasslands Ngoài ra, bằng cách sử dụng PartiQL, bạn có thể chạy một truy vấn Scan index để nhận được kết quả tương tự.\nNhấp vào dấu ba chấm (\u0026hellip;) bên cạnh OpenGamesIndex và chọn Scan index.\nTrong bước này, bạn đã thấy rằng việc sử dụng thao tác Scan có thể là lựa chọn đúng đắn trong những tình huống cụ thể. Bạn đã sử dụng Scan để lấy một tập hợp các thực thể từ chỉ mục thứ cấp thưa (sparse global secondary index - GSI) để hiển thị các game mở cho người chơi.\nTóm tắt Trong module này, bạn đã thêm một chỉ mục thứ cấp toàn cục (GSI) vào bảng. Điều này đáp ứng hai mẫu truy cập bổ sung:\nTìm game mở theo bản đồ (Đọc) Tìm game mở (Đọc) Để thực hiện điều này, bạn đã sử dụng một chỉ mục thưa chỉ bao gồm các game vẫn đang mở cho người chơi bổ sung. Sau đó, bạn đã sử dụng cả hai API Query và Scan trên chỉ mục để tìm các game mở.\nTrong module tiếp theo, bạn sẽ sử dụng các giao dịch DynamoDB khi thêm người chơi mới vào một game và đóng game khi đã đủ người chơi.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.4/",
	"title": "Sao lưu",
	"tags": [],
	"description": "",
	"content": "Amazon DynamoDB cung cấp hai loại sao lưu: sao lưu theo yêu cầu (on-demand) và khôi phục theo thời gian (point-in-time recovery - PITR). PITR hoạt động theo cửa sổ thời gian cuốn chiếu, còn sao lưu theo yêu cầu sẽ tồn tại mãi mãi (ngay cả khi bảng bị xóa) cho đến khi có người yêu cầu DynamoDB xóa các bản sao lưu. Khi bạn bật PITR, DynamoDB tự động sao lưu dữ liệu bảng của bạn với độ chính xác đến từng giây. Thời gian lưu trữ là cố định trong 35 ngày (5 tuần lịch) và không thể thay đổi. Tuy nhiên, các khách hàng doanh nghiệp lớn, những người đã quen với việc triển khai các giải pháp sao lưu truyền thống trong các trung tâm dữ liệu của họ, thường muốn một giải pháp sao lưu tập trung có thể lên lịch sao lưu thông qua các “công việc” và xử lý các tác vụ như hết hạn/xóa các bản sao lưu cũ theo thời gian, giám sát trạng thái của các bản sao lưu đang diễn ra, xác minh tuân thủ, và tìm kiếm/khôi phục các bản sao lưu, tất cả đều sử dụng một giao diện điều khiển trung tâm. Đồng thời, họ không muốn quản lý các bản sao lưu của mình thủ công, tạo công cụ riêng thông qua các script hoặc chức năng AWS Lambda, hoặc sử dụng một giải pháp khác cho mỗi ứng dụng mà họ phải bảo vệ. Họ muốn có khả năng quản lý sao lưu của mình một cách tiêu chuẩn hóa ở quy mô lớn cho các tài nguyên trong tài khoản AWS của họ.\nAWS Backup nhằm mục đích trở thành điểm quản lý sao lưu tập trung duy nhất và là nguồn thông tin đáng tin cậy mà khách hàng có thể tin cậy. Bạn có thể lên lịch sao lưu định kỳ hoặc sao lưu trong tương lai bằng cách sử dụng AWS Backup. Các kế hoạch sao lưu bao gồm lịch trình và chính sách lưu giữ cho các tài nguyên của bạn. AWS Backup tạo các bản sao lưu và xóa các bản sao lưu trước đó dựa trên lịch lưu giữ của bạn. Các bản sao lưu của tài nguyên luôn cần thiết trong trường hợp khôi phục sau thảm họa.\nAWS Backup loại bỏ công việc thủ công nặng nề của việc tạo và xóa các bản sao lưu theo yêu cầu bằng cách tự động hóa lịch trình và xóa cho bạn. Trong bài thực hành này, chúng ta sẽ khám phá cách lên lịch sao lưu định kỳ cho một bảng DynamoDB bằng cách sử dụng AWS Backup. Tôi sẽ tạo một kế hoạch sao lưu mà trong đó tôi thực hiện sao lưu hàng ngày và giữ nó trong một tháng. Tiếp theo, tôi thiết lập một quy tắc sao lưu để chuyển bản sao lưu sang lưu trữ lạnh sau 31 ngày và tự động xóa bản sao lưu sau 366 ngày kể từ ngày tạo bản sao lưu.\nNgoài ra, tôi sẽ chỉ cho bạn cách bạn có thể hạn chế người trong tổ chức của mình xóa các bản sao lưu từ AWS Backup và DynamoDB console trong khi vẫn có thể thực hiện các thao tác khác như tạo bản sao lưu, tạo bảng, v.v.\nBây giờ hãy cùng đi sâu vào các tùy chọn sao lưu DynamoDB khác nhau.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.4/1.4.4/",
	"title": "Sao lưu theo lịch",
	"tags": [],
	"description": "",
	"content": "Sao lưu theo yêu cầu\nBạn phải tạo ít nhất một vault (kho lưu trữ) trước khi tạo một kế hoạch sao lưu hoặc bắt đầu một công việc sao lưu.\nTrong AWS Management Console, điều hướng đến Services -\u0026gt; AWS Backup. Nhấp vào Create Backup vault dưới Backup vaults. Cung cấp tên Backup vault theo ý muốn của bạn. AWS KMS encryption master key (khóa chính mã hóa AWS KMS). Mặc định, AWS Backup sẽ tạo một khóa chính với bí danh aws/backup cho bạn. Bạn có thể chọn khóa đó hoặc chọn bất kỳ khóa nào khác trong tài khoản của bạn. Nhấp vào Create Backup vault. Bạn có thể thấy Backup vault đã được tạo thành công.\nBây giờ, chúng ta cần tạo một kế hoạch sao lưu.\nNhấp vào Create Backup plan dưới Backup plans. Chọn Build a new plan. Cung cấp backup plan name và rule name. Chọn backup frequency (tần suất sao lưu). Tần suất sao lưu xác định mức độ thường xuyên tạo một bản sao lưu. Sử dụng giao diện điều khiển, bạn có thể chọn frequency là mỗi 12 giờ, hàng ngày, hàng tuần, hoặc hàng tháng. Chọn backup window (cửa sổ sao lưu). Cửa sổ sao lưu bao gồm thời gian bắt đầu sao lưu và thời gian của cửa sổ tính bằng giờ. Công việc sao lưu sẽ bắt đầu trong cửa sổ này. Tôi đang cấu hình sao lưu bắt đầu vào lúc 6 giờ chiều UTC trong vòng 1 giờ và hoàn thành trong vòng 4 giờ.\nTiếp theo, chọn lifecycle (vòng đời). Vòng đời xác định khi nào một bản sao lưu được chuyển sang lưu trữ lạnh và khi nào nó hết hạn. Tôi đang cấu hình sao lưu để chuyển sang lưu trữ lạnh sau 31 ngày và hết hạn sau 366 ngày.\nChọn backup vault mà chúng ta đã tạo trước đó. Nhấp vào Create plan. Lưu ý: Các bản sao lưu được chuyển sang lưu trữ lạnh phải được lưu trữ trong lưu trữ lạnh ít nhất 90 ngày.\nBây giờ, hãy gán tài nguyên cho kế hoạch sao lưu. Khi bạn gán một tài nguyên cho một kế hoạch sao lưu, tài nguyên đó sẽ được sao lưu tự động theo kế hoạch sao lưu.\nĐặt tên cho Resource assignment (gán tài nguyên). Chọn vai trò mặc định. Chọn Include specific resource types dưới mục \u0026ldquo;1. Define resource selection\u0026rdquo;. Dưới \u0026ldquo;2. Select specific resource types\u0026rdquo; (Chọn loại tài nguyên cụ thể), chọn loại tài nguyên DynamoDB từ menu thả xuống. Nhấp vào \u0026ldquo;Choose resources\u0026rdquo;, bỏ chọn \u0026ldquo;All\u0026rdquo;, và chọn bảng ProductCatalog. Nhấp vào Assign resources. Bạn có thể thấy trạng thái của công việc sao lưu trong phần \u0026ldquo;jobs\u0026rdquo; sau khoảng thời gian của cửa sổ sao lưu đã lên lịch. Bạn sẽ thấy sao lưu DynamoDB của mình đã hoàn thành. Khôi phục một bản sao lưu: Sau khi một tài nguyên đã được sao lưu ít nhất một lần, nó được coi là đã được bảo vệ và có thể được khôi phục bằng AWS Backup. Trong tài khoản của bạn, có thể một bản sao lưu chưa có sẵn. Nếu vậy, hãy xem qua các ảnh chụp màn hình thay vì thực hiện điều này trong tài khoản của riêng bạn.\nTrên trang Protected resources (Tài nguyên được bảo vệ), bạn có thể xem chi tiết về các tài nguyên được sao lưu trong AWS Backup. Chọn tài nguyên bảng DynamoDB của chúng ta. Chọn ID điểm khôi phục của tài nguyên. Nhấp vào Restore. Lưu ý: Nếu bạn không thấy điểm khôi phục, bạn có thể nhấp vào \u0026ldquo;Create an on-demand backup\u0026rdquo; và hoàn tất sao lưu. Đối với mục đích của bài thực hành này, bạn cần một bản sao lưu đã hoàn thành để tiếp tục và bạn có thể không muốn chờ đợi bản sao lưu đã lên lịch trong kế hoạch sao lưu của mình. Cung cấp tên bảng DynamoDB mới. Giữ tất cả các cài đặt mặc định và nhấp vào Restore backup. Bảng Restore jobs (Công việc khôi phục) xuất hiện. Một thông báo ở đầu trang cung cấp thông tin về công việc khôi phục. Bạn sẽ thấy trạng thái công việc đang chạy. Sau một thời gian, bạn sẽ thấy trạng thái thay đổi thành hoàn tất.\nBạn cũng có thể giám sát tất cả các công việc sao lưu và khôi phục trong bảng điều khiển trung tâm.\nĐể xem bảng đã khôi phục, truy cập DynamoDB Console và nhấp vào Tables từ menu bên. Chọn bảng ProductCatalogRestored. Bạn sẽ thấy bảng đã được khôi phục cùng với dữ liệu.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.4/",
	"title": "Thay đổi tính năng Thu thập dữ liệu bằng Kinesis Data Streams",
	"tags": [],
	"description": "",
	"content": "Amazon Kinesis Data Streams có thể được sử dụng để thu thập và xử lý các luồng dữ liệu lớn từ các ứng dụng tạo dữ liệu streaming theo thời gian thực. Ở mức cao, các nhà sản xuất dữ liệu (data producers) đẩy các bản ghi dữ liệu (data records) đến Amazon Kinesis Data Streams và người tiêu dùng (consumers) có thể đọc và xử lý dữ liệu trong thời gian thực.\nDữ liệu trên Amazon Kinesis Data Streams theo mặc định sẽ có sẵn trong 24 giờ sau khi dữ liệu được ghi vào luồng và thời gian lưu giữ (retention period) có thể được tăng lên tối đa 365 ngày.\nAmazon DynamoDB có tích hợp tự nhiên với Kinesis streams, do đó Kinesis Data Streams cũng có thể được sử dụng để ghi lại các thay đổi ở cấp độ mục (item level changes) cho các bảng DynamoDB.\nTrong chương này, bạn sẽ lặp lại quá trình thu thập các thay đổi ở cấp độ mục trên một bảng DynamoDB và ghi những thay đổi đó vào một bảng DynamoDB khác. Tuy nhiên, trong phần này, việc thu thập dữ liệu thay đổi (change data capture) sẽ được thực hiện bằng cách sử dụng Amazon Kinesis Data Streams.\nKiến trúc của giải pháp kết quả được hiển thị trong hình dưới đây.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.2/1.2.4/",
	"title": "Thêm/Sửa dữ liệu",
	"tags": [],
	"description": "",
	"content": "Chèn Dữ Liệu DynamoDB cung cấp API PutItem để tạo một mục mới hoặc thay thế hoàn toàn các mục hiện có bằng một mục mới. Nó được gọi bằng lệnh CLI put-item.\nGiả sử chúng ta muốn chèn một mục mới vào bảng Reply:\naws dynamodb put-item \\ --table-name Reply \\ --item \u0026#39;{ \u0026#34;Id\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB#DynamoDB Thread 2\u0026#34;}, \u0026#34;ReplyDateTime\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;2021-04-27T17:47:30Z\u0026#34;}, \u0026#34;Message\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;DynamoDB Thread 2 Reply 3 text\u0026#34;}, \u0026#34;PostedBy\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;User C\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL Chúng ta có thể thấy trong phản hồi rằng yêu cầu này tiêu thụ 1 WCU:\n{ \u0026#34;ConsumedCapacity\u0026#34;: { \u0026#34;TableName\u0026#34;: \u0026#34;Reply\u0026#34;, \u0026#34;CapacityUnits\u0026#34;: 1.0 } } Cập Nhật Dữ Liệu DynamoDB cung cấp API UpdateItem để tạo một mục mới hoặc thay thế hoàn toàn các mục hiện có bằng một mục mới. Nó được gọi bằng lệnh CLI update-item. API này yêu cầu bạn phải chỉ định đầy đủ Khóa Chính và có thể tùy chọn sửa đổi các thuộc tính cụ thể mà không thay đổi các thuộc tính khác (bạn không cần phải truyền toàn bộ mục).\nLệnh gọi API update-item cũng cho phép bạn chỉ định một ConditionExpression, nghĩa là yêu cầu Cập nhật sẽ chỉ được thực thi nếu ConditionExpression được thỏa mãn. Để biết thêm thông tin, vui lòng xem Condition Expressions trong Hướng dẫn Dành cho Nhà Phát triển.\nGiả sử chúng ta muốn cập nhật mục Forum cho DynamoDB để ghi nhận rằng hiện có 5 tin nhắn thay vì 4, và chúng ta chỉ muốn thay đổi đó được thực thi nếu không có luồng xử lý nào khác đã cập nhật mục đó trước. Điều này cho phép chúng ta tạo ra các sửa đổi idempotent (không bị lặp lại). Để biết thêm thông tin về các thay đổi idempotent, vui lòng xem Làm Việc Với Các Mục trong Hướng dẫn Dành cho Nhà Phát triển.\nĐể thực hiện điều này từ CLI, chúng ta sẽ chạy:\naws dynamodb update-item \\ --table-name Forum \\ --key \u0026#39;{ \u0026#34;Name\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB\u0026#34;} }\u0026#39; \\ --update-expression \u0026#34;SET Messages = :newMessages\u0026#34; \\ --condition-expression \u0026#34;Messages = :oldMessages\u0026#34; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:oldMessages\u0026#34; : {\u0026#34;N\u0026#34;: \u0026#34;4\u0026#34;}, \u0026#34;:newMessages\u0026#34; : {\u0026#34;N\u0026#34;: \u0026#34;5\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL Lưu ý rằng nếu bạn chạy lại lệnh chính xác này, bạn sẽ thấy lỗi sau:\nAn error occurred (ConditionalCheckFailedException) when calling the UpdateItem operation: The conditional request failed Bởi vì thuộc tính Messages đã được tăng lên 5 trong lệnh update-item trước đó, yêu cầu thứ hai sẽ thất bại với lỗi ConditionalCheckFailedException.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.4/",
	"title": "Tìm trò chơi đang mở",
	"tags": [],
	"description": "",
	"content": "Một trong những điều chỉnh lớn nhất cho người dùng mới với DynamoDB và NoSQL là cách mô hình hóa dữ liệu để lọc trên toàn bộ bộ dữ liệu. Ví dụ, trong ứng dụng trò chơi, bạn cần tìm các trò chơi còn chỗ trống để có thể hiển thị cho người dùng các trò chơi mà họ có thể tham gia.\nTrong cơ sở dữ liệu quan hệ, bạn có thể viết một số câu lệnh SQL để truy vấn dữ liệu.\nSELECT * FROM games WHERE status = \u0026#34;OPEN\u0026#34; DynamoDB có thể lọc kết quả trên một thao tác Query hoặc Scan, nhưng DynamoDB không hoạt động như một cơ sở dữ liệu quan hệ. Bộ lọc DynamoDB áp dụng sau khi các mục ban đầu khớp với thao tác Query hoặc Scan đã được truy xuất. Bộ lọc giảm kích thước của payload được gửi từ dịch vụ DynamoDB, nhưng số lượng mục được truy xuất ban đầu phụ thuộc vào giới hạn kích thước của DynamoDB.\nMay mắn thay, có một số cách bạn có thể cho phép truy vấn có lọc trên bộ dữ liệu của bạn trong DynamoDB. Để cung cấp các bộ lọc hiệu quả trên bảng DynamoDB của bạn, bạn cần lập kế hoạch cho các bộ lọc này vào mô hình dữ liệu của bảng từ đầu. Hãy nhớ bài học bạn đã học ở các mô-đun trước của lab này: Xem xét các mẫu truy cập của bạn, sau đó thiết kế bảng của bạn.\nTrong các bước tiếp theo, bạn sẽ sử dụng global secondary index (chỉ mục phụ toàn cầu) để tìm các trò chơi còn chỗ trống. Cụ thể, bạn sẽ sử dụng kỹ thuật sparse index (chỉ mục thưa) để xử lý mẫu truy cập này.\n"
},
{
	"uri": "//localhost:1313/vi/2-lbed/2.4/",
	"title": "Truy vấn và kết luận",
	"tags": [],
	"description": "",
	"content": "Giờ đây, bạn đã tạo tất cả các kết nối và pipeline cần thiết, và dữ liệu đã được sao chép từ DynamoDB vào OpenSearch Service, bạn có nhiều lựa chọn để truy vấn dữ liệu của mình. Bạn có thể thực hiện tra cứu key/value trực tiếp với DynamoDB, thực hiện các truy vấn tìm kiếm trên OpenSearch và sử dụng Bedrock cùng với OpenSearch để đề xuất sản phẩm bằng ngôn ngữ tự nhiên.\nTruy vấn này sẽ sử dụng OpenSearch như một cơ sở dữ liệu vector để tìm sản phẩm phù hợp nhất với ý định của bạn. Nội dung của chỉ mục OpenSearch được tạo thông qua kết nối DynamoDB Zero ETL. Khi các bản ghi được thêm vào DynamoDB, kết nối này tự động chuyển chúng vào OpenSearch. OpenSearch sau đó sử dụng mô hình Titan Embeddings để bổ sung dữ liệu đó.\nScript này xây dựng một truy vấn tìm kiếm chỉ mục OpenSearch để tìm các sản phẩm phù hợp nhất với văn bản đầu vào của bạn. Điều này được thực hiện bằng truy vấn \u0026ldquo;neural\u0026rdquo;, sử dụng các embeddings được lưu trữ trong OpenSearch để tìm các sản phẩm có nội dung văn bản tương tự. Sau khi truy xuất các sản phẩm liên quan, script sử dụng Bedrock để tạo ra một phản hồi tinh vi hơn thông qua mô hình Claude. Điều này bao gồm việc tạo ra một prompt kết hợp truy vấn ban đầu của bạn với dữ liệu đã truy xuất và gửi prompt này đến Bedrock để xử lý.\nQuay lại Cloud9 IDE Console.\nĐầu tiên, chúng ta sẽ thực hiện một yêu cầu trực tiếp đến DynamoDB\naws dynamodb get-item \\ --table-name ProductDetails \\ --key \u0026#39;{\u0026#34;ProductID\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;S020\u0026#34;}}\u0026#39; Đây là ví dụ về tra cứu key/value mà DynamoDB rất xuất sắc. Nó trả về chi tiết sản phẩm cho một sản phẩm cụ thể, được xác định bằng ProductID của nó.\nTiếp theo, chúng ta sẽ thực hiện một truy vấn tìm kiếm đến OpenSearch. Chúng ta sẽ tìm những chiếc váy có chứa \u0026ldquo;Spandex\u0026rdquo; trong mô tả.\ncurl --request POST \\ ${OPENSEARCH_ENDPOINT}/product-details-index-en/_search \\ --header \u0026#39;Content-Type: application/json\u0026#39; \\ --header \u0026#39;Accept: application/json\u0026#39; \\ --header \u0026#34;x-amz-security-token: ${METADATA_AWS_SESSION_TOKEN}\u0026#34; \\ --aws-sigv4 aws:amz:${METADATA_AWS_REGION}:es \\ --user \u0026#34;${METADATA_AWS_ACCESS_KEY_ID}:${METADATA_AWS_SECRET_ACCESS_KEY}\u0026#34; \\ --data-raw \u0026#39;{ \u0026#34;_source\u0026#34;: { \u0026#34;excludes\u0026#34;: [\u0026#34;product_embedding\u0026#34;] }, \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [ { \u0026#34;match\u0026#34;: { \u0026#34;Category\u0026#34;: \u0026#34;Skirt\u0026#34; } }, { \u0026#34;match_phrase\u0026#34;: { \u0026#34;Description\u0026#34;: \u0026#34;Spandex\u0026#34; } } ] } } }\u0026#39; | jq . Hãy thử thay đổi Spandex thành Polyester và xem kết quả thay đổi như thế nào.\nCuối cùng, chúng ta sẽ yêu cầu Bedrock cung cấp một số đề xuất sản phẩm bằng cách sử dụng một trong các script đã cung cấp trong lab.\nTruy vấn này sẽ sử dụng OpenSearch như một cơ sở dữ liệu vector để tìm sản phẩm phù hợp nhất với ý định của bạn. Nội dung của chỉ mục OpenSearch được tạo thông qua kết nối DynamoDB Zero ETL. Khi các bản ghi được thêm vào DynamoDB, kết nối này tự động chuyển chúng vào OpenSearch. OpenSearch sau đó sử dụng mô hình Titan Embeddings để bổ sung dữ liệu đó.\nScript này xây dựng một truy vấn tìm kiếm chỉ mục OpenSearch để tìm các sản phẩm phù hợp nhất với văn bản đầu vào của bạn. Điều này được thực hiện bằng truy vấn \u0026ldquo;neural\u0026rdquo;, sử dụng các embeddings được lưu trữ trong OpenSearch để tìm các sản phẩm có nội dung văn bản tương tự. Sau khi truy xuất các sản phẩm liên quan, script sử dụng Bedrock để tạo ra một phản hồi tinh vi hơn thông qua mô hình Claude. Điều này bao gồm việc tạo ra một prompt kết hợp truy vấn ban đầu của bạn với dữ liệu đã truy xuất và gửi prompt này đến Bedrock để xử lý.\nTrong console, thực hiện script Python được cung cấp để thực hiện truy vấn đến Bedrock và trả về kết quả sản phẩm.\npython bedrock_query.py product_recommend en \u0026#34;I need a warm winter coat\u0026#34; $METADATA_AWS_REGION $OPENSEARCH_ENDPOINT $MODEL_ID | jq . Thử thêm một mục mới vào bảng DynamoDB của bạn.\naws dynamodb put-item \\ --table-name ProductDetails \\ --item \u0026#39;{ \u0026#34;ProductID\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;S021\u0026#34;}, \u0026#34;Category\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Socks\u0026#34;}, \u0026#34;Description\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;{\\\u0026#34;Style\\\u0026#34;: \\\u0026#34;Outdoor\\\u0026#34;, \\\u0026#34;Pattern\\\u0026#34;: \\\u0026#34;Striped\\\u0026#34;, \\\u0026#34;Length\\\u0026#34;: \\\u0026#34;Knee-High\\\u0026#34;, \\\u0026#34;Type\\\u0026#34;: \\\u0026#34;Thick\\\u0026#34;, \\\u0026#34;Fabric\\\u0026#34;: \\\u0026#34;Wool\\\u0026#34;, \\\u0026#34;Composition\\\u0026#34;: \\\u0026#34;80% Wool, 20% Nylon\\\u0026#34;, \\\u0026#34;Care Instructions\\\u0026#34;: \\\u0026#34;Hand wash cold, lay flat to dry\\\u0026#34;, \\\u0026#34;Ideal For\\\u0026#34;: \\\u0026#34;Outdoor Activities\\\u0026#34;, \\\u0026#34;Stretch\\\u0026#34;: \\\u0026#34;Moderate\\\u0026#34;, \\\u0026#34;Opacity\\\u0026#34;: \\\u0026#34;Opaque\\\u0026#34;, \\\u0026#34;Lining\\\u0026#34;: \\\u0026#34;No\\\u0026#34;, \\\u0026#34;Pockets\\\u0026#34;: \\\u0026#34;No Pockets\\\u0026#34;, \\\u0026#34;Closure\\\u0026#34;: \\\u0026#34;Pull Up\\\u0026#34;, \\\u0026#34;Shoe Height\\\u0026#34;: \\\u0026#34;Knee-High\\\u0026#34;, \\\u0026#34;Occasion\\\u0026#34;: \\\u0026#34;Outdoor\\\u0026#34;, \\\u0026#34;Season\\\u0026#34;: \\\u0026#34;Fall, Winter\\\u0026#34;}\u0026#34;}, \u0026#34;Image\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;https://example.com/S021.jpg\u0026#34;}, \u0026#34;ProductName\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Striped Wool Knee-High Socks\u0026#34;} }\u0026#39; Thử sửa đổi lệnh DynamoDB get-item ở trên để truy xuất mục mới của bạn. Tiếp theo, thử sửa đổi truy vấn OpenSearch để tìm kiếm \u0026ldquo;Socks\u0026rdquo; có chứa \u0026ldquo;Wool\u0026rdquo;. Cuối cùng, yêu cầu Bedrock \u0026ldquo;I need warm socks for hiking in winter\u0026rdquo;. Liệu nó có đề xuất mục mới của bạn không?\nTiếp tục truy vấn! Đừng dừng lại ở đây với các truy vấn của bạn. Hãy thử yêu cầu quần áo cho mùa đông (liệu nó có đề xuất các sản phẩm có len không?) hoặc cho giờ đi ngủ. Lưu ý rằng có một danh mục sản phẩm rất nhỏ để nhúng, vì vậy thuật ngữ tìm kiếm của bạn nên giới hạn dựa trên những gì bạn đã thấy khi xem bảng DynamoDB.\nChúc mừng! Bạn đã hoàn thành bài lab. Nếu bạn đang chạy trên tài khoản của riêng mình, hãy nhớ xóa CloudFormation Stack sau khi hoàn thành bài lab để tránh các chi phí không mong muốn.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.3/7.3.4/",
	"title": "Truy xuất Item collentions",
	"tags": [],
	"description": "",
	"content": "Một Item collection (Bộ sưu tập mục) là một tập hợp các mục có cùng giá trị partition key (khóa phân vùng) nhưng có các giá trị sort key (khóa sắp xếp) khác nhau, nơi mà các mục của các loại thực thể khác nhau có mối quan hệ với khóa phân vùng.\nNhư bạn đã đọc trong mô-đun trước, bạn nên tối ưu hóa bảng DynamoDB để giảm số lượng yêu cầu mà nó nhận được. Cũng đã đề cập rằng DynamoDB không có phép nối (joins) như cơ sở dữ liệu quan hệ. Thay vào đó, bạn thiết kế bảng của mình để cho phép hành vi tương tự như phép nối trong các yêu cầu của bạn.\nTrong bước này, bạn sẽ truy xuất nhiều loại thực thể trong một yêu cầu duy nhất. Trong ứng dụng trò chơi, bạn có thể muốn lấy chi tiết về một trò chơi. Các chi tiết này bao gồm thông tin về trò chơi như thời gian bắt đầu, thời gian kết thúc, và chi tiết về người dùng đã tham gia trò chơi.\nYêu cầu này bao gồm hai loại thực thể: thực thể Game và thực thể UserGameMapping. Tuy nhiên, điều này không có nghĩa là bạn cần thực hiện nhiều yêu cầu.\nTrong mã mà bạn đã tải xuống, có một script fetch_game_and_players.py trong thư mục scripts/. Script này cho thấy cách bạn có thể cấu trúc mã của mình để truy xuất cả thực thể Game và thực thể UserGameMapping cho trò chơi trong một yêu cầu duy nhất.\nDưới đây là mã tạo thành script fetch_game_and_players.py:\nimport boto3 from entities import Game, UserGameMapping dynamodb = boto3.client(\u0026#39;dynamodb\u0026#39;) GAME_ID = \u0026#34;3d4285f0-e52b-401a-a59b-112b38c4a26b\u0026#34; def fetch_game_and_users(game_id): resp = dynamodb.query( TableName=\u0026#39;battle-royale\u0026#39;, KeyConditionExpression=\u0026#34;PK = :pk AND SK BETWEEN :metadata AND :users\u0026#34;, ExpressionAttributeValues={ \u0026#34;:pk\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;GAME#{}\u0026#34;.format(game_id) }, \u0026#34;:metadata\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;#METADATA#{}\u0026#34;.format(game_id) }, \u0026#34;:users\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;USER$\u0026#34; }, }, ScanIndexForward=True ) game = Game(resp[\u0026#39;Items\u0026#39;][0]) game.users = [UserGameMapping(item) for item in resp[\u0026#39;Items\u0026#39;][1:]] return game game = fetch_game_and_users(GAME_ID) print(game) for user in game.users: print(user) Ở phần đầu của script này, bạn import thư viện Boto 3 và một số lớp đơn giản để đại diện cho các đối tượng trong mã ứng dụng. Bạn có thể xem định nghĩa cho các thực thể đó trong tệp scripts/entities.py.\nPhần quan trọng của script diễn ra trong hàm fetch_game_and_users được định nghĩa trong mô-đun. Đây tương tự như một hàm mà bạn sẽ định nghĩa trong ứng dụng của mình để được sử dụng bởi bất kỳ endpoint nào cần dữ liệu này.\nHàm fetch_game_and_users thực hiện một số việc. Đầu tiên, nó thực hiện một yêu cầu Query tới DynamoDB. Yêu cầu Query này sử dụng PK của GAME#\u0026lt;GameId\u0026gt;. Sau đó, nó yêu cầu bất kỳ thực thể nào mà sort key nằm giữa #METADATA#\u0026lt;GameId\u0026gt; và USER$. Điều này lấy thực thể Game, với sort key là #METADATA#\u0026lt;GameId\u0026gt;, và tất cả các thực thể UserGameMapping, với các khóa bắt đầu bằng USER#. Các sort key của loại chuỗi được sắp xếp theo mã ký tự ASCII. Dấu đô la ($) đến ngay sau dấu thăng (#) trong ASCII, vì vậy điều này đảm bảo rằng bạn sẽ lấy tất cả các bản đồ trong thực thể UserGameMapping.\nKhi bạn nhận được phản hồi, bạn lắp ráp các thực thể dữ liệu thành các đối tượng được biết đến bởi ứng dụng. Bạn biết rằng thực thể đầu tiên được trả về là thực thể Game, vì vậy bạn tạo một đối tượng Game từ thực thể này. Đối với các thực thể còn lại, bạn tạo một đối tượng UserGameMapping cho mỗi thực thể và sau đó đính kèm mảng người dùng vào đối tượng Game.\nPhần cuối của script cho thấy cách sử dụng hàm và in ra các đối tượng kết quả.\nBạn có thể chạy script trong Terminal của Cloud9 với lệnh sau:\npython scripts/fetch_game_and_players.py Script sẽ in đối tượng Game và tất cả các đối tượng UserGameMapping ra console.\nGame: 3d4285f0-e52b-401a-a59b-112b38c4a26b Map: Green Grasslands UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: branchmichael UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: deanmcclure UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: emccoy UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: emma83 UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: iherrera UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: jeremyjohnson UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: lisabaker UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: maryharris UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: mayrebecca UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: meghanhernandez UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: nruiz UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: pboyd UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: richardbowman UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: roberthill UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: robertwood UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: victoriapatrick UserGameMapping: 3d4285f0-e52b-401a-a59b-112b38c4a26b Username: waltervargas Script này cho thấy cách bạn có thể mô hình hóa bảng của mình và viết các truy vấn để truy xuất nhiều loại thực thể trong một yêu cầu DynamoDB duy nhất. Trong một cơ sở dữ liệu quan hệ, bạn sử dụng các phép nối để truy xuất nhiều loại thực thể từ các bảng khác nhau trong một yêu cầu. Với DynamoDB, bạn mô hình hóa dữ liệu của mình một cách cụ thể, sao cho các thực thể mà bạn nên truy cập cùng nhau được đặt cạnh nhau trong một bảng duy nhất. Cách tiếp cận này thay thế nhu cầu sử dụng phép nối trong cơ sở dữ liệu quan hệ điển hình và giữ cho ứng dụng của bạn có hiệu suất cao khi mở rộng.\nĐánh giá Trong mô-đun này, bạn đã thiết kế một khóa chính và tạo một bảng. Sau đó, bạn đã tải dữ liệu vào bảng và thấy cách truy vấn cho nhiều loại thực thể trong một yêu cầu duy nhất.\nVới thiết kế khóa chính hiện tại, bạn có thể đáp ứng các mẫu truy cập sau:\nTạo hồ sơ người dùng (Ghi)\nCập nhật hồ sơ người dùng (Ghi)\nLấy hồ sơ người dùng (Đọc)\nTạo trò chơi (Ghi)\nXem trò chơi (Đọc)\nTham gia trò chơi cho một người dùng (Ghi)\nBắt đầu trò chơi (Ghi)\nCập nhật trò chơi cho một người dùng (Ghi)\nCập nhật trò chơi (Ghi)\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.1/1.1.4/",
	"title": "Xóa tài nguyên",
	"tags": [],
	"description": "",
	"content": "Nếu bạn đã sử dụng tài khoản của riêng mình, vui lòng xóa các tài nguyên sau:\nBốn bảng DynamoDB đã được tạo trong phần Bắt đầu của lab: aws dynamodb delete-table \\ --table-name ProductCatalog aws dynamodb delete-table \\ --table-name Forum aws dynamodb delete-table \\ --table-name Thread aws dynamodb delete-table \\ --table-name Reply Mẫu CloudFormation đã được khởi động trong phần bắt đầu. Điều hướng đến bảng điều khiển CloudFormation, chọn stack amazon-dynamodb-labs và nhấp vào Delete. Điều này sẽ hoàn tất quá trình dọn dẹp.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.5/",
	"title": "Bài tập 4: Global Secondary Index Quá tải",
	"tags": [],
	"description": "",
	"content": "Tại thời điểm trang này được viết, bạn có thể tạo tối đa 20 chỉ mục phụ toàn cầu (global secondary indexes) cho một bảng DynamoDB. Tuy nhiên, đôi khi ứng dụng của bạn có thể cần hỗ trợ nhiều mẫu truy cập và vượt quá giới hạn hiện tại về số lượng chỉ mục phụ toàn cầu trên mỗi bảng. Mẫu thiết kế \u0026ldquo;nạp chồng khóa chỉ mục phụ toàn cầu\u0026rdquo; được kích hoạt bằng cách chỉ định và tái sử dụng tên thuộc tính (tiêu đề cột) trên các loại mục khác nhau và lưu trữ giá trị trong thuộc tính đó tùy thuộc vào ngữ cảnh của loại mục. Khi bạn tạo một chỉ mục phụ toàn cầu trên thuộc tính đó, bạn đang lập chỉ mục cho nhiều mẫu truy cập, mỗi mẫu cho một loại mục khác nhau—và chỉ sử dụng một chỉ mục phụ toàn cầu duy nhất. Ví dụ, một bảng employees. Một nhân viên có thể chứa các mục kiểu metadata (cho chi tiết nhân viên), employee-title (tất cả các chức danh công việc mà nhân viên đã giữ), hoặc employee-location (tất cả các tòa nhà văn phòng và vị trí mà nhân viên đã làm việc).\nCác mẫu truy cập cần thiết cho kịch bản này bao gồm:\nTruy vấn tất cả nhân viên của một tiểu bang Truy vấn tất cả nhân viên với một chức danh hiện tại cụ thể Truy vấn tất cả nhân viên từng có một chức danh cụ thể Truy vấn nhân viên theo tên Ảnh chụp màn hình sau đây hiển thị thiết kế của bảng employees. Thuộc tính có tên PK chứa ID của nhân viên, được thêm vào phía trước bởi chữ cái e. Dấu thăng (#) được sử dụng làm ký tự phân tách giữa định danh loại thực thể (e) và ID nhân viên thực tế. Thuộc tính SK là một thuộc tính được nạp chồng và có thể là chức danh hiện tại, chức danh trước đây, hoặc từ khóa root, biểu thị mục chính cho nhân viên chứa hầu hết các thuộc tính quan trọng của họ. Thuộc tính GSI_1_PK bao gồm chức danh hoặc tên của nhân viên. Việc tái sử dụng một chỉ mục phụ toàn cầu nhất định cho nhiều loại thực thể như nhân viên, vị trí làm việc của nhân viên, và chức danh nhân viên giúp chúng ta đơn giản hóa việc quản lý bảng DynamoDB vì chúng ta chỉ cần giám sát và trả tiền cho một chỉ mục phụ toàn cầu thay vì ba chỉ mục riêng biệt.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.1/3.1.5/",
	"title": "Bước 4 - Kiểm tra nội dung thư mục workshop",
	"tags": [],
	"description": "",
	"content": "Trên phiên bản EC2, vào thư mục workshop và chạy lệnh ls:\ncd /home/ubuntu/workshop ls -l . Danh sách sau đây cho biết cấu trúc thư mục và các tệp sẽ được sử dụng trong hội thảo:\n. ├── data │ ├── employees.csv │ ├── invoice-data2.csv │ ├── invoice-data.csv │ ├── logfile_medium1.csv │ ├── logfile_medium2.csv │ ├── logfile_small1.csv │ └── logfile_stream.csv ├── ddbreplica_lambda.py ├── ddb-replication-role-arn.txt ├── gsi_city_dept.json ├── gsi_manager.json ├── iam-role-policy.json ├── iam-trust-relationship.json ├── lab_config.py ├── load_employees.py ├── load_invoice.py ├── load_logfile_parallel.py ├── load_logfile.py ├── query_city_dept.py ├── query_employees.py ├── query_index_invoiceandbilling.py ├── query_invoiceandbilling.py ├── query_responsecode.py ├── requirements.txt ├── scan_for_managers_gsi.py ├── scan_for_managers.py ├── scan_logfile_parallel.py └── scan_logfile_simple.py Mã Python:\nddbreplica_lambda.py load_employees.py load_invoice.py load_logfile_parallel.py load_logfile.py lab_config.py query_city_dept.py query_employees.py query_index_invoiceandbilling.py query_invoiceandbilling.py query_responsecode.py scan_for_managers_gsi.py scan_for_managers.py scan_logfile_parallel.py scan_logfile_simple.py JSON:\ngsi_city_dept.json gsi_manager.json iam-role-policy.json iam-trust-relationship.json Văn bản (được sử dụng sau này trong phòng thí nghiệm):\nddb-replication-role-arn.txt Chạy lệnh ls để hiển thị các tệp dữ liệu mẫu:\nls -l ./data ./Nội dung dữ liệu:\nemployees.csv invoice-data2.csv invoice-data.csv logfile_medium1.csv logfile_medium2.csv logfile_small1.csv logfile_stream.csv _Lưu ý: Mã được cung cấp chỉ dành cho mục đích sử dụng theo hướng dẫn. Nó không nên được sử dụng bên ngoài phòng thí nghiệm này, và nó không phù hợp để sử dụng sản xuất.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.9/3.9.5/",
	"title": "Bước 5 - Ánh xạ luồng nguồn tới hàm Lambda",
	"tags": [],
	"description": "",
	"content": "Đến nay, bạn đã có bảng nguồn với DynamoDB Streams được kích hoạt và hàm Lambda. Bây giờ bạn cần ánh xạ stream nguồn đến hàm Lambda. Bạn cần sao chép ARN từ bước trước và dán nó vào lệnh sau trước khi chạy lệnh.\naws lambda create-event-source-mapping \\ --function-name ddbreplica_lambda --enabled --batch-size 100 --starting-position TRIM_HORIZON \\ --event-source-arn YOUR_STREAM_ARN_HERE Bạn phải sao chép đầy đủ ARN của stream, bao gồm cả dấu thời gian ở cuối\nVí dụ:\naws lambda create-event-source-mapping \\ --function-name ddbreplica_lambda --enabled --batch-size 100 --starting-position TRIM_HORIZON \\ --event-source-arn arn:aws:dynamodb:\u0026lt;REGION\u0026gt;:\u0026lt;ACCOUNTID\u0026gt;:table/logfile/stream/2021-12-31T00:00:00.000 Kết quả dự kiến sẽ trông như sau:\n{ \u0026#34;UUID\u0026#34;: \u0026#34;0dcede66-709c-4073-a628-724d01b92095\u0026#34;, \u0026#34;BatchSize\u0026#34;: 100, \u0026#34;MaximumBatchingWindowInSeconds\u0026#34;: 0, \u0026#34;ParallelizationFactor\u0026#34;: 1, \u0026#34;EventSourceArn\u0026#34;: \u0026#34;arn:aws:dynamodb:\u0026lt;REGION\u0026gt;:\u0026lt;ACCOUNTID\u0026gt;:table/logfile/stream/2021-12-31T00:00:00.000\u0026#34;, \u0026#34;FunctionArn\u0026#34;: \u0026#34;arn:aws:lambda:\u0026lt;REGION\u0026gt;:\u0026lt;ACCOUNTID\u0026gt;:function:ddbreplica_lambda\u0026#34;, \u0026#34;LastModified\u0026#34;: 1663286115.972, \u0026#34;LastProcessingResult\u0026#34;: \u0026#34;No records processed\u0026#34;, \u0026#34;State\u0026#34;: \u0026#34;Creating\u0026#34;, \u0026#34;StateTransitionReason\u0026#34;: \u0026#34;User action\u0026#34;, \u0026#34;DestinationConfig\u0026#34;: { \u0026#34;OnFailure\u0026#34;: {} }, \u0026#34;MaximumRecordAgeInSeconds\u0026#34;: -1, \u0026#34;BisectBatchOnFunctionError\u0026#34;: false, \u0026#34;MaximumRetryAttempts\u0026#34;: -1 } "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.2/3.2.5/",
	"title": "Bước 5 - Tăng dung lượng của bảng",
	"tags": [],
	"description": "",
	"content": "Chạy lệnh AWS CLI sau để tăng đơn vị dung lượng ghi và đơn vị dung lượng đọc từ 5 lên 100.\naws dynamodb update-table --table-name logfile \\ --provisioned-throughput ReadCapacityUnits=100,WriteCapacityUnits=100 Chạy lệnh để đợi cho đến khi bảng trở thành Hoạt động.\ntime aws dynamodb wait table-exists --table-name logfile Chủ đề thảo luận: Mất bao lâu để tăng công suất? Nó nhanh hơn, hay lâu hơn bạn mong đợi? Thông thường, khi bạn cần thêm dung lượng từ bảng thông lượng được cung cấp, bảng thông lượng này sẽ sẵn dùng chỉ trong vài chục giây.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.5/1.5.5/",
	"title": "Explore Target Model",
	"tags": [],
	"description": "",
	"content": "Hệ thống quản lý cơ sở dữ liệu quan hệ (Relational Database Management System - RDBMS) lưu trữ dữ liệu trong một cấu trúc quan hệ đã chuẩn hóa. Cấu trúc này giúp giảm bớt các cấu trúc dữ liệu dạng phân cấp và lưu trữ dữ liệu trên nhiều bảng. Bạn thường có thể truy vấn dữ liệu từ nhiều bảng và tập hợp chúng tại lớp trình bày. Tuy nhiên, điều này không phải lúc nào cũng phù hợp và sẽ không hiệu quả cho các khối lượng công việc yêu cầu độ trễ đọc cực thấp (ultra-low read latency workloads). Để hỗ trợ các truy vấn có lưu lượng cao với độ trễ cực thấp, việc thiết kế một schema để tận dụng hệ thống NoSQL thường có ý nghĩa cả về mặt kỹ thuật lẫn kinh tế.\nĐể bắt đầu thiết kế mô hình dữ liệu mục tiêu trong Amazon DynamoDB sao cho mở rộng hiệu quả, bạn cần xác định các mẫu truy cập phổ biến (common access patterns). Đối với trường hợp sử dụng IMDb, chúng tôi đã xác định một tập hợp các mẫu truy cập như mô tả dưới đây: Một cách tiếp cận phổ biến để thiết kế schema cho DynamoDB là xác định các thực thể ở tầng ứng dụng và sử dụng việc không chuẩn hóa (denormalization) và tổng hợp khóa tổng hợp (composite key aggregation) để giảm độ phức tạp của truy vấn. Trong DynamoDB, điều này có nghĩa là sử dụng composite sort keys (khóa sắp xếp tổng hợp), overloaded global secondary indexes (chỉ mục thứ cấp toàn cầu quá tải), và các mẫu thiết kế khác.\nTrong kịch bản này, chúng ta sẽ áp dụng Adjacency List Design Pattern (mẫu thiết kế danh sách kề) với việc sử dụng khóa chính quá tải (primary key overloading) để lưu trữ dữ liệu quan hệ trong bảng DynamoDB. Lợi thế của mẫu thiết kế này bao gồm việc tối ưu hóa sự sao chép dữ liệu và đơn giản hóa các mẫu truy vấn để tìm tất cả metadata liên quan đến mỗi bộ phim. Thông thường, mẫu thiết kế danh sách kề lưu trữ dữ liệu trùng lặp dưới hai mục, mỗi mục đại diện cho một nửa của mối quan hệ. Để liên kết một tiêu đề với một vùng (region), ví dụ, bạn sẽ ghi một mục cho vùng dưới tiêu đề và một mục cho tiêu đề dưới vùng, như sau:\nPartition Key Sort Key Attribute List tt0309377 REGN|NZ ordering, language, region, title, types REGN|NZ tt0309377 language, region, title Tuy nhiên, trong bài tập này, chúng ta chỉ làm việc với một bên của mối quan hệ: dữ liệu nằm dưới tiêu đề. Khóa phân vùng (partition key) của chúng ta sẽ là mpkey và khóa sắp xếp (sort key) sẽ là mskey cho bảng phim. Mỗi khóa phân vùng và khóa sắp xếp được tiền tố bằng các chữ cái để xác định loại thực thể, và khóa sắp xếp sử dụng | như một dấu phân cách giữa loại thực thể và giá trị. Khóa phân vùng được tiền tố bằng tt (mã phim duy nhất) và khóa sắp xếp được quá tải để xác định loại thực thể.\nCác loại thực thể sau được tìm thấy trong bảng:\ntt: Mã phim duy nhất. Đây là loại thực thể của khóa phân vùng trong bảng cơ sở. nm: Một mục duy nhất cho mỗi thành viên đoàn làm phim. Đây là loại thực thể của khóa phân vùng GSI. DETL: Chứa thông tin diễn viên/đoàn làm phim cho mỗi bộ phim. Có mối quan hệ 1: nhiều giữa title_basics và title_principals. title_principals chứa tất cả thông tin diễn viên và đoàn làm phim được lưu trữ dưới dạng các dòng riêng biệt cho mỗi bộ phim, trong khi title_basics chứa metadata về bộ phim. Thông tin trong cả hai bảng này được coi là tĩnh sau khi một bộ phim được công bố. Các mẫu truy cập yêu cầu thông tin phim và diễn viên/đoàn làm phim phải được truy xuất cùng nhau. Trong quá trình mô hình hóa mục tiêu, mỗi metadata của thành viên diễn viên/đoàn làm phim (diễn viên, đạo diễn, nhà sản xuất, v.v.) được không chuẩn hóa với thông tin phim và lưu trữ với loại thực thể DETL. REGN: Chứa tất cả các vùng, ngôn ngữ và tiêu đề mà một bộ phim được công bố. Trong quá trình mô hình hóa mục tiêu, dữ liệu được chuyển đổi nguyên bản vào bảng DynamoDB. RTNG: Chứa xếp hạng IMDb và số phiếu bầu. Đây được coi là các bản ghi động và thường xuyên thay đổi cho một bộ phim. Để giảm I/O trong kịch bản cập nhật, bản ghi này không được không chuẩn hóa với các thông tin khác trong bảng DynamoDB. Một chỉ mục GSI mới được tạo trên bảng phim với khóa phân vùng mới là nconst (duy nhất cho mỗi thành viên đoàn làm phim với loại thực thể nm) và khóa sắp xếp là startYear. Điều này sẽ giúp truy vấn mẫu truy cập theo thành viên đoàn làm phim (số 6 trong bảng mẫu truy cập chung).\nNhấp vào đây để xem video minh họa cách tất cả các mẫu truy cập này được đánh giá đối với mô hình DynamoDB mục tiêu.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.3/1.3.5/",
	"title": "Global Secondary Indexes",
	"tags": [],
	"description": "",
	"content": "Chúng ta đã quan tâm đến việc truy cập dữ liệu dựa trên các thuộc tính khóa. Nếu muốn tìm các mục dựa trên các thuộc tính không phải khóa, chúng ta phải quét toàn bộ bảng và sử dụng điều kiện lọc để tìm những gì chúng ta muốn, điều này sẽ rất chậm và tốn kém đối với các hệ thống hoạt động ở quy mô lớn.\nDynamoDB cung cấp một tính năng gọi là Global Secondary Indexes (GSIs) giúp tự động xoay chuyển dữ liệu của bạn xung quanh các Khóa Phân Vùng và Khóa Sắp Xếp khác nhau. Dữ liệu có thể được tái nhóm và tái sắp xếp để cho phép nhiều mẫu truy cập hơn được phục vụ nhanh chóng với các API Query và Scan.\nHãy nhớ ví dụ trước đó khi chúng ta muốn tìm tất cả các phản hồi trong bảng Reply được đăng bởi User A và cần sử dụng thao tác Scan? Nếu có một tỷ mục Reply nhưng chỉ có ba mục được đăng bởi User A, chúng ta sẽ phải trả giá (cả về thời gian và chi phí) để quét qua một tỷ mục chỉ để tìm ba mục mà chúng ta cần.\nVới kiến thức về GSIs, chúng ta có thể tạo một GSI trên bảng Reply để phục vụ mẫu truy cập mới này. GSIs có thể được tạo và xóa bất kỳ lúc nào, ngay cả khi bảng đã có dữ liệu! GSI mới này sẽ sử dụng thuộc tính PostedBy làm khóa Phân Vùng (HASH) và chúng ta sẽ giữ các tin nhắn được sắp xếp theo ReplyDateTime làm khóa Sắp Xếp (RANGE). Chúng ta muốn tất cả các thuộc tính từ bảng được sao chép (projected) vào GSI nên chúng ta sẽ sử dụng ALL ProjectionType. Lưu ý rằng tên của chỉ mục chúng ta tạo là PostedBy-ReplyDateTime-gsi.\nĐiều hướng đến bảng Reply, chuyển sang tab Indexes và nhấp vào Create Index.\nNhập PostedBy làm khóa Phân Vùng, ReplyDateTime làm khóa Sắp Xếp, và PostedBy-ReplyDateTime-gsi làm tên Chỉ mục. Giữ nguyên các thiết lập khác và nhấp vào Create Index. Khi chỉ mục thoát khỏi trạng thái Creating, bạn có thể tiếp tục với bài tập bên dưới.\nDọn Dẹp Khi bạn hoàn thành, hãy chắc chắn xóa GSI. Quay lại tab Indexes, chọn chỉ mục PostedBy-ReplyDateTime-gsi và nhấp vào Delete.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.4/1.4.5/",
	"title": "Hạn chế xóa sao lưu",
	"tags": [],
	"description": "",
	"content": "Khách hàng thường yêu cầu cho phép nhà phát triển/quản trị viên của họ tạo và xóa bảng DynamoDB, nhưng không được phép xóa các bản sao lưu.\nBạn có thể đạt được điều này bằng cách tạo chính sách IAM. Dưới đây là ví dụ về chính sách AWS IAM cho phép “Tạo Bảng” (Create Table), “Liệt kê Bảng” (List Table), “Tạo Sao lưu” (Create Backup) và “Xóa Bảng” (Delete Table), nhưng từ chối quyền “Xóa Sao lưu” (Delete Backup) của bảng DynamoDB.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:CreateTable\u0026#34;, \u0026#34;dynamodb:CreateBackup\u0026#34;, \u0026#34;dynamodb:DeleteTable\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-east-1:123456789:table/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor1\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:ListTables\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor2\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;dynamodb:DeleteBackup\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-east-1:123456789:table/*/backup/*\u0026#34; } ] } Tại trang tài liệu này, bạn sẽ tìm thấy thêm thông tin về việc sử dụng IAM với sao lưu DynamoDB.\nBạn cũng có thể giới hạn quyền trong AWS Backup bằng cách từ chối quyền “DeleteBackupSelection” trong chính sách IAM.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;backup:DeleteBackupSelection\u0026#34;, \u0026#34;backup:CreateBackupSelection\u0026#34;, \u0026#34;backup:StartBackupJob\u0026#34;, \u0026#34;backup:CreateBackupPlan\u0026#34;, \u0026#34;backup:ListBackupSelections\u0026#34;, \u0026#34;backup:ListRecoveryPointsByBackupVault\u0026#34;, \u0026#34;backup:GetBackupVaultAccessPolicy\u0026#34;, \u0026#34;backup:GetBackupSelection\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:backup:us-east-1:123456789:backup-plan:*\u0026#34;, \u0026#34;arn:aws:backup:us-east-1:123456789:backup-vault:*\u0026#34; ] }, { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor1\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;backup:DeleteBackupSelection\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:backup:us-east-1:123456789:backup-plan:*\u0026#34; } ] } Bạn có thể áp dụng chính sách này cho một vai trò (role) và gán vai trò đó cho một nhóm IAM. Bây giờ, người dùng thuộc nhóm IAM này sẽ thừa hưởng các quyền hạn này.\nGiả sử người dùng cố gắng xóa bản sao lưu trong AWS Backup.\nNgười dùng sẽ gặp lỗi \u0026ldquo;Access Denied\u0026rdquo; do không có đủ quyền để xóa bản sao lưu.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.5/",
	"title": "LMIG: Relational Modeling &amp; Migration",
	"tags": [],
	"description": "",
	"content": "Trong module này, còn được phân loại là LMIG, bạn sẽ học cách thiết kế một mô hình dữ liệu mục tiêu trong DynamoDB cho dữ liệu quan hệ được chuẩn hóa cao trong cơ sở dữ liệu quan hệ. Bài tập này cũng hướng dẫn từng bước quá trình di chuyển một bộ dữ liệu IMDb từ một phiên bản cơ sở dữ liệu MySQL tự quản lý trên EC2 sang cơ sở dữ liệu cặp khóa-giá trị được quản lý hoàn toàn, Amazon DynamoDB. Khi kết thúc bài học này, bạn sẽ tự tin vào khả năng thiết kế và di chuyển một cơ sở dữ liệu quan hệ hiện có sang Amazon DynamoDB.\nĐôi khi, dữ liệu xuất hiện dưới dạng định dạng quan hệ tại một thời điểm nhất định, nhưng yêu cầu kinh doanh thay đổi có thể gây ra các thay đổi trong schema trong suốt vòng đời dự án. Mỗi thay đổi schema đều tốn công sức, chi phí và đôi khi khiến doanh nghiệp phải ưu tiên lại nhu cầu của họ do các tác động phức tạp của việc thay đổi này. Amazon DynamoDB giúp bộ phận CNTT suy nghĩ lại về mô hình dữ liệu trong định dạng cặp khóa-giá trị. Định dạng này có tiềm năng hấp thụ những gián đoạn do schema thay đổi. Amazon DynamoDB cung cấp một kho dữ liệu không cần quản lý, không máy chủ cho thông tin được lưu trữ dưới dạng cặp khóa-giá trị. Sự linh hoạt về schema cho phép DynamoDB lưu trữ dữ liệu phân cấp phức tạp trong một mục và cung cấp độ trễ chỉ vài mili giây ngay cả khi mở rộng quy mô.\nModule này sẽ thảo luận ngắn gọn về các kỹ thuật để thiết kế mô hình dữ liệu mục tiêu và di chuyển các bộ dữ liệu quan hệ từ MySQL sang Amazon DynamoDB. Dữ liệu IMDb trong cơ sở dữ liệu MySQL bắt đầu dưới dạng chuẩn hóa trên nhiều bảng. Chúng ta sẽ sử dụng các kỹ thuật mô hình hóa dữ liệu phi chuẩn hóa hoặc mô hình hóa bộ sưu tập mục để tạo ra một mô hình dữ liệu toàn diện cho các mẫu truy cập đã xác định. Có nhiều yếu tố sẽ ảnh hưởng đến quyết định của chúng ta trong việc xây dựng mô hình dữ liệu mục tiêu:\nMẫu truy cập (Access patterns) Độ đông đúc (Cardinality) Tổng thể I/O Chúng ta sẽ thảo luận ngắn gọn về các khía cạnh chính của việc tạo ra một mô hình có thể phục vụ nhiều mẫu truy cập với độ trễ cực thấp, I/O thấp và chi phí thấp.\n"
},
{
	"uri": "//localhost:1313/vi/5-lmr/",
	"title": "LMR: Xây dựng và triển khai ứng dụng serverless toàn cầu với Amazon DynamoDB",
	"tags": [],
	"description": "",
	"content": "Trong buổi workshop này, bạn sẽ học cách xây dựng và triển khai một ứng dụng serverless phân phối toàn cầu và có kinh nghiệm sử dụng Amazon DynamoDB Global Tables để sao chép dữ liệu trên các vùng (AWS Regions).\nBạn sẽ sử dụng các thành phần serverless để xây dựng một API hỗ trợ cho ứng dụng web trình phát video. Dịch vụ API này được thiết kế để lưu trữ các bản ghi bookmark cho bất kỳ chương trình video nào mà khách hàng xem, để ứng dụng có thể nhớ nơi người dùng đã dừng lại trong một phiên xem.\nĐối tượng mục tiêu cho buổi workshop này là bất kỳ nhà phát triển hoặc kiến trúc sư ứng dụng nào cần hiểu về kiến trúc khả dụng dữ liệu đa vùng (multi-region data availability architectures) cho ứng dụng của họ. Kết thúc buổi workshop này, bạn sẽ:\nCảm thấy thoải mái khi tạo một DynamoDB Global Table trong nhiều vùng Hiểu cách DynamoDB Global Tables Replication hoạt động Có thể giải thích ý nghĩa của \u0026ldquo;eventual consistency\u0026rdquo; trong ngữ cảnh sao chép của DynamoDB Global Tables Bạn phải mang theo laptop của mình để tham gia và thời lượng dự kiến của buổi workshop là 50 phút.\nBuổi workshop bao gồm các chương sau:\nBắt đầu Module 1: Khởi chạy ứng dụng Module 2: Khám phá Global Tables Module 3: Tương tác với Giao diện Globalflix Các chủ đề thảo luận về Global Tables "
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.3/4.3.5/",
	"title": "Mô phỏng cập nhật đơn hàng",
	"tags": [],
	"description": "",
	"content": "Sau khi tạo bảng Orders, bạn đã tải lên một số đơn hàng mẫu vào bảng. Hãy khám phá các mặt hàng trên bảng Orders trước khi mô phỏng bất kỳ cập nhật nào đối với các đơn hàng trên bảng.\nĐiều hướng đến trang Dịch vụ DynamoDB bằng cách sử dụng AWS Management Console.\nChọn bảng Orders, sau đó chọn nút Explore table items để xem các đơn hàng trên bảng.\nSẽ có 4 đơn hàng trên bảng, tất cả đều có trạng thái là PLACED như hình dưới đây.\nBạn có thể khám phá nội dung của từng đơn hàng bằng cách chọn id của mục bằng Console DynamoDB.\nSẽ không có dữ liệu nào trên bảng OrdersHistory tại thời điểm này vì chưa có dữ liệu nào được ghi vào đó.\nBạn có thể mô phỏng cập nhật các mục trên bảng Orders bằng cách sử dụng AWS Management Console hoặc AWS CLI. Mở rộng phần thích hợp dưới đây để có hướng dẫn về cách tiến hành với phương pháp ưa thích của bạn.\nMô phỏng cập nhật sử dụng AWS Management Console\nChọn bảng Orders. Chọn nút Explore table items. Nhấp vào ID đơn hàng 6421680 trên bảng. Thay đổi trạng thái của đơn hàng từ PLACED sang COMPLETE. Chọn nút Save and close. Mô phỏng cập nhật sử dụng AWS CLI\nÁp dụng cập nhật cho ID đơn hàng 642168\naws dynamodb update-item \\ --table-name Orders \\ --key \u0026#39;{ \u0026#34;id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;6421680\u0026#34;} }\u0026#39; \\ --update-expression \u0026#34;SET #items = :val1, #status = :val2\u0026#34; \\ --expression-attribute-names \u0026#39;{ \u0026#34;#items\u0026#34;: \u0026#34;items\u0026#34;, \u0026#34;#status\u0026#34;: \u0026#34;status\u0026#34; }\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:val2\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; }, \u0026#34;:val1\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23769901\u0026#34;}, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Hydrating Face Cream\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£12.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;8\u0026#34;}, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34; COMPLETE\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23673445\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;EXTRA Repair Serum\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£10.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;5\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34; COMPLETE\u0026#34; } } } ] } }\u0026#39; \\ --return-values ALL_NEW \\ --return-item-collection-metrics SIZE \\ --return-consumed-capacity TOTAL Kết quả sẽ tương tự như sau.\n{ \u0026#34;Attributes\u0026#34;: { \u0026#34;orderDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-01 20:39:08\u0026#34; }, \u0026#34;shipDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-04 16:29:36\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; }, \u0026#34;customer\u0026#34;: { \u0026#34;M\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Brody Dent\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;558490551\u0026#34; }, \u0026#34;address\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;3 Bailey Lane, Clenchwarton,PE34 4AY\u0026#34; }, \u0026#34;phone\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;+441268381612\u0026#34; } } }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;6421680\u0026#34; }, \u0026#34;items\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Hydrating Face Cream\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23769901\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;8\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£12.00\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34; COMPLETE\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;EXTRA Repair Serum\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23673445\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;5\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£10.00\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34; COMPLETE\u0026#34; } } } ] } }, \u0026#34;ConsumedCapacity\u0026#34;: { \u0026#34;TableName\u0026#34;: \u0026#34;Orders\u0026#34;, \u0026#34;CapacityUnits\u0026#34;: 1.0 } } Bây giờ hãy khám phá các bảng Orders và OrdersHistory để xem các kết quả cập nhật mục mà bạn đã thực hiện.\nTrạng thái của đơn hàng ID 6421680 trên bảng Orders sẽ là COMPLETE như hình dưới đây.\n\u0026hellip; và sẽ có một bản ghi trên OrdersHistory hiển thị trạng thái trước đó của đơn hàng ID 6421680.\nThực hiện các cập nhật bổ sung cho đơn hàng ID 4514280 trên bảng Orders. Lần này, đầu tiên thay đổi trạng thái của đơn hàng thành COMPLETE, sau đó thay đổi trạng thái của một số mặt hàng trên cùng đơn hàng thành RETURNED bằng cách sử dụng các lệnh dưới đây.\naws dynamodb update-item \\ --table-name Orders \\ --key \u0026#39;{ \u0026#34;id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;4514280\u0026#34;} }\u0026#39; \\ --update-expression \u0026#34;SET #items = :val1, #status = :val2\u0026#34; \\ --expression-attribute-names \u0026#39;{ \u0026#34;#items\u0026#34;: \u0026#34;items\u0026#34;, \u0026#34;#status\u0026#34;: \u0026#34;status\u0026#34; }\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:val1\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23884750\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Metallic Long-Wear Cream Shadow\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£15.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;13\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23699354\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Eye Liner\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£9.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;8\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23599030\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Bronzing Powder\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£12.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } } } ] }, \u0026#34;:val2\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } }\u0026#39; \\ --return-values ALL_NEW \\ --return-item-collection-metrics SIZE \\ --return-consumed-capacity TOTAL Sau đó tiếp tục\naws dynamodb update-item \\ --table-name Orders \\ --key \u0026#39;{ \u0026#34;id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;4514280\u0026#34;} }\u0026#39; \\ --update-expression \u0026#34;SET #items = :val1, #status = :val2\u0026#34; \\ --expression-attribute-names \u0026#39;{ \u0026#34;#items\u0026#34;: \u0026#34;items\u0026#34;, \u0026#34;#status\u0026#34;: \u0026#34;status\u0026#34; }\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:val1\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23884750\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Metallic Long-Wear Cream Shadow\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£15.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;13\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S \u0026#34;: \u0026#34;23699354\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Eye Liner\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£9.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;8\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;RETURNED\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23599030\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Bronzing Powder\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£12.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;RETURNED\u0026#34; } } } ] }, \u0026#34;:val2\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } }\u0026#39; \\ --return-values ALL_NEW \\ --return-item-collection-metrics SIZE \\ --return-consumed-capacity TOTAL Khám phá các mặt hàng trên các bảng Orders và OrdersHistory để xem kết quả của các cập nhật của bạn.\nTrạng thái của đơn hàng ID 4514280 trên bảng Orders sẽ là COMPLETE như hình dưới đây.\n\u0026hellip; và sẽ có hai mục nhập cho đơn hàng ID 4514280 trên bảng OrdersHistory hiển thị các trạng thái trước đó của đơn hàng.\nLưu ý: Thứ tự cập nhật trên bảng Orders được duy trì bởi các luồng DynamoDB khi các thay đổi được gửi đến hàm lambda tạo lịch sử đơn hàng. Vì các mục trên bảng OrdersHistory có khóa sắp xếp - sk, là một dấu thời gian, các mục trên bảng OrderHistory có thể được sắp xếp theo thứ tự chúng được tạo ra.\n"
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.4/4.4.5/",
	"title": "Mô phỏng cập nhật đơn hàng",
	"tags": [],
	"description": "",
	"content": "Tương tự như trong phòng thí nghiệm trước, hãy thực hiện các cập nhật cấp mục cho bảng Orders và quan sát các bản sao cũ của các mục được cập nhật được ghi vào OrdersHistory.\nĐiều hướng đến trang Dịch vụ DynamoDB bằng cách sử dụng AWS Management Console.\nChọn bảng Orders sau đó chọn nút Explore table items để xem các đơn hàng trên bảng.\nVui lòng tham khảo phần Simulate Order Updates từ phòng thí nghiệm trước nếu bạn cần làm mới cách khám phá các mục bảng bằng AWS Management Console.\nCác mục trên bảng sẽ trông quen thuộc từ phòng thí nghiệm trước. Trạng thái của các mục trên bảng Orders có thể thay đổi nếu bạn đã thực hiện các mô phỏng bổ sung trong phòng thí nghiệm trước về thu thập dữ liệu thay đổi bằng DynamoDB streams.\nCũng khám phá các đơn hàng trên bảng OrdersHistory. Số lượng các mục trên bảng sẽ phụ thuộc vào số lượng cập nhật bạn đã thực hiện đối với bảng Orders trong phòng thí nghiệm trước.\nCập nhật trạng thái của đơn hàng ID 9844720 từ PLACED sang COMPLETE bằng lệnh dưới đây.\naws dynamodb update-item \\ --table-name Orders \\ --key \u0026#39;{ \u0026#34;id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;9844720\u0026#34;} }\u0026#39; \\ --update-expression \u0026#34;SET #items = :val1, #status = :val2\u0026#34; \\ --expression-attribute-names \u0026#39;{ \u0026#34;#items\u0026#34;: \u0026#34;items\u0026#34;, \u0026#34;#status\u0026#34;: \u0026#34;status\u0026#34; }\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:val2\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; }, \u0026#34;:val1\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;24002126\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Shimmer Wash Eye Shadow\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£13.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23607685\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Buffing Grains for Face\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£8.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;11\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } } } ] } }\u0026#39; \\ --return-values ALL_NEW \\ --return-item-collection-metrics SIZE \\ --return-consumed-capacity TOTAL Kết quả đầu ra sẽ tương tự như dưới đây.\n{ \u0026#34;Attributes\u0026#34;: { \u0026#34;orderDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-01 01:49:13\u0026#34; }, \u0026#34;shipDate\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;2023-10-06 13:05:33\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; }, \u0026#34;customer\u0026#34;: { \u0026#34;M\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Taylor Burnette\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;941852721\u0026#34; }, \u0026#34;address\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;31 Walkhampton Avenue, Bradwell Common,MK13 8ND\u0026#34; }, \u0026#34;phone\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;+441663724681\u0026#34; } } }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;9844720\u0026#34; }, \u0026#34;items\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Shimmer Wash Eye Shadow\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;24002126\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£13.00\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Buffing Grains for Face\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23607685\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;11\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£8.00\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;COMPLETE\u0026#34; } } } ] } }, \u0026#34;ConsumedCapacity\u0026#34;: { \u0026#34;TableName\u0026#34;: \u0026#34;Orders\u0026#34;, \u0026#34;CapacityUnits\u0026#34;: 1.0 } } Xem các mục trên bảng Orders và OrdersHistory để xem hiệu ứng của việc cập nhật mục mà bạn đã thực hiện.\nTrạng thái của đơn hàng ID 9844720 trên bảng Orders sẽ là COMPLETE như hình dưới đây.\n\u0026hellip; và sẽ có một bản ghi trên OrdersHistory hiển thị trạng thái trước đó của đơn hàng ID 9844720.\nThực hiện các cập nhật bổ sung cho đơn hàng ID 9953371 trên bảng Orders. Bắt đầu bằng cách thay đổi trạng thái của đơn hàng thành ACTIVE sau đó thực hiện một cập nhật khác bằng cách đặt trạng thái của cùng đơn hàng thành CANCELLED bằng các lệnh dưới đây.\naws dynamodb update-item \\ --table-name Orders \\ --key \u0026#39;{ \u0026#34;id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;9953371\u0026#34;} }\u0026#39; \\ --update-expression \u0026#34;SET #items = :val1, #status = :val2\u0026#34; \\ --expression-attribute-names \u0026#39;{ \u0026#34;#items\u0026#34;: \u0026#34;items\u0026#34;, \u0026#34;#status\u0026#34;: \u0026#34;status\u0026#34; }\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:val1\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23924636\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Protective Face Lotion\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£3.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;9\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;CANCELLED\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23514506\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Nail File\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£11.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;13\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PLACED\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23508704\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Kitten Heels Powder Finish Foot Creme\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£11.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;PLACED\u0026#34; } } } ] }, \u0026#34;:val2\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;ACTIVE\u0026#34; } }\u0026#39; \\ --return-values ALL_NEW \\ --return-item-collection-metrics SIZE \\ --return-consumed-capacity TOTAL Sau đó tiếp tục\naws dynamodb update-item \\ --table-name Orders \\ --key \u0026#39;{ \u0026#34;id\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;9953371\u0026#34;} }\u0026#39; \\ --update-expression \u0026#34;SET #items = :val1, #status = :val2\u0026#34; \\ --expression-attribute-names \u0026#39;{ \u0026#34;#items\u0026#34;: \u0026#34;items\u0026#34;, \u0026#34;#status\u0026#34;: \u0026#34;status\u0026#34; }\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:val1\u0026#34;: { \u0026#34;L\u0026#34;: [ { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23924636\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Protective Face Lotion\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£3.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;9\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;CANCELLED\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23514506\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Nail File\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£11.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;13\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;CANCELLED\u0026#34; } } }, { \u0026#34;M\u0026#34;: { \u0026#34;id\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;23508704\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;Kitten Heels Powder Finish Foot Creme\u0026#34; }, \u0026#34;price\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;£11.00\u0026#34; }, \u0026#34;quantity\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;10\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;CANCELLED\u0026#34; } } } ] }, \u0026#34;:val2\u0026#34;: { \u0026#34;S\u0026#34;: \u0026#34;CANCELLED\u0026#34; } }\u0026#39; \\ --return-values ALL_NEW \\ --return-item-collection-metrics SIZE \\ --return-consumed-capacity TOTAL Khám phá các mục trên các bảng Orders và OrdersHistory để xem kết quả của các cập nhật của bạn. Trạng thái cho đơn hàng ID 9953371 nên được cập nhật trên bảng Orders và nên có hai mục trên bảng OrdersHistory cho đơn hàng ID 9953371.\n\u0026hellip; và sẽ có hai mục nhập cho đơn hàng ID 9953371 trên bảng **OrdersHistory\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.5/",
	"title": "Tham gia và đóng trò chơi",
	"tags": [],
	"description": "",
	"content": "Qua các module trước trong bài lab này, bạn đã thỏa mãn các mẫu truy cập cho việc tạo và truy xuất các thực thể cốt lõi trong ứng dụng game, chẳng hạn như Users và Games. Bạn cũng đã sử dụng một GSI thưa (sparse GSI) để tìm các game mở mà người dùng có thể tham gia.\nTrong module này, bạn sẽ thỏa mãn hai mẫu truy cập:\nTham gia game cho một người dùng (Write) Bắt đầu game (Write) Lưu ý rằng cả hai mẫu truy cập này đều ghi dữ liệu vào DynamoDB, trái ngược với các mẫu đọc nhiều mà bạn đã thực hiện từ trước trong bài lab này.\nGiao dịch DynamoDB Để thỏa mãn mẫu truy cập \u0026ldquo;Tham gia game cho một người dùng\u0026rdquo; trong các bước của module này, bạn sẽ sử dụng giao dịch DynamoDB. Giao dịch rất phổ biến trong các hệ thống quan hệ cho các thao tác ảnh hưởng đến nhiều phần tử dữ liệu cùng một lúc. Ví dụ, hãy tưởng tượng bạn đang điều hành một ngân hàng. Một khách hàng chuyển $100 cho một khách hàng khác. Khi ghi lại giao dịch này, bạn sẽ sử dụng giao dịch để đảm bảo các thay đổi được áp dụng cho cả hai tài khoản của khách hàng, thay vì chỉ một người.\nGiao dịch DynamoDB giúp dễ dàng hơn trong việc xây dựng các ứng dụng thay đổi nhiều mục (items) trong một thao tác duy nhất. Với giao dịch, bạn có thể thao tác lên đến 100 mục như một phần của yêu cầu giao dịch duy nhất. Trong một cuộc gọi API TransactWriteItems, bạn có thể sử dụng các thao tác sau:\nPut: Để chèn hoặc ghi đè một mục. Update: Để cập nhật một mục hiện có. Delete: Để xóa một mục. ConditionCheck: Để khẳng định một điều kiện trên một mục hiện có mà không thay đổi mục đó. Trong các bước tiếp theo, bạn sẽ sử dụng giao dịch DynamoDB khi thêm người dùng mới vào game và ngăn không cho game bị đầy quá mức.\n"
},
{
	"uri": "//localhost:1313/vi/5-lmr/5.5/",
	"title": "Thảo luận chủ đề Global Tables ",
	"tags": [],
	"description": "",
	"content": "Dưới đây là một số chủ đề thảo luận dành cho những người đã hoàn thành công việc phát triển hoặc muốn thảo luận về các khía cạnh thú vị của Global Tables với chuyên gia DynamoDB.\nGlobal Tables là gì? Global Tables (Bảng toàn cầu) xây dựng trên cơ sở hạ tầng toàn cầu của Amazon DynamoDB để cung cấp cho bạn một cơ sở dữ liệu đa vùng (multi-Region) và đa hoạt động (multi-active) được quản lý hoàn toàn, mang lại hiệu suất đọc và ghi nhanh chóng, cục bộ cho các ứng dụng quy mô lớn toàn cầu. Global Tables tự động sao chép các bảng DynamoDB của bạn trên các Vùng AWS mà bạn chọn. Global Tables loại bỏ công việc phức tạp của việc sao chép dữ liệu giữa các vùng và giải quyết các xung đột cập nhật, cho phép bạn tập trung vào logic kinh doanh của ứng dụng. Ngoài ra, Global Tables còn giúp ứng dụng của bạn luôn khả dụng cao ngay cả trong trường hợp hiếm có khi toàn bộ một vùng bị cô lập hoặc suy giảm. Bạn có thể thiết lập Global Tables trong Bảng điều khiển quản lý AWS hoặc AWS CLI. Không cần thay đổi ứng dụng vì Global Tables sử dụng các API DynamoDB hiện có. Không có chi phí ban đầu hay cam kết sử dụng Global Tables, và bạn chỉ trả tiền cho các tài nguyên đã cấp phát. Chi phí sử dụng Global Tables như thế nào? Một lần ghi vào bảng DynamoDB truyền thống được tính bằng Write Units (Đơn vị ghi), trong đó nếu bạn ghi một mục 5 KB, nó sẽ phải chịu phí 5 Write Units. Ghi vào Global Table được tính bằng Replicated Write Capacity Units (rWCUs, đối với bảng cấp phát sẵn) hoặc Replicated Write Request Units (rWRUs, đối với bảng theo yêu cầu). Các đơn vị ghi sao chép bao gồm chi phí của cơ sở hạ tầng truyền phát cần thiết để quản lý sao chép. Đối với bảng theo yêu cầu ở us-east-1, giá là $1.875 cho mỗi triệu đơn vị ghi sao chép thay vì $1.25 mỗi triệu. Đối với bảng cấp phát sẵn, giá là $0.000975 mỗi giờ rWCU thay vì $0.00065 mỗi giờ WCU. Các phí chuyển dữ liệu giữa các vùng cũng áp dụng. Phí đơn vị ghi sao chép được tính ở mỗi vùng mà mục được ghi trực tiếp hoặc ghi sao chép. Ghi vào Global Secondary Index (GSI) được coi là ghi cục bộ và sử dụng Write Units thông thường. Hiện tại không có dung lượng dự trữ cho rWCUs. Mua Dung lượng Dự trữ có thể vẫn có lợi cho các bảng với GSIs tiêu thụ đơn vị ghi. Sự khác biệt chính giữa GTv1 (2017) và GTv2 (2019) là gì? DynamoDB có hai phiên bản Global Tables. Cả hai đều vẫn được hỗ trợ, nhưng chúng tôi khuyên bạn sử dụng GTv2 (2019) hoặc nâng cấp khi có thể. Mọi thảo luận ngoài câu hỏi này đều đề cập đến các hành vi của GTv2. Với GTv2, bảng nguồn và đích được duy trì cùng nhau và tự động được căn chỉnh (đối với thông lượng, cài đặt TTL, cài đặt tự động mở rộng, v.v.). Với GTv2, các thuộc tính siêu dữ liệu cần thiết để kiểm soát sao chép giờ đây được ẩn, ngăn chặn việc ghi nhầm (hoặc cố ý) vào chúng gây ra vấn đề với việc sao chép. Mã hóa Customer Managed Key (CMK) chỉ có sẵn trên GTv2. Nhiều vùng được hỗ trợ với GTv2 hơn. GTv2 cho phép bạn thêm/xóa vùng vào một bảng hiện có. GTv2 thường có chi phí hiệu quả hơn. Làm thế nào để nâng cấp từ Global Tables v1 lên v2? Việc nâng cấp là một nút nhấn trong Console. Đây là một nâng cấp trực tiếp sẽ hoàn tất trong vòng chưa đầy một giờ. Cách quản lý thông lượng đọc và ghi cho Global Tables như thế nào? Công suất ghi phải giống nhau trên tất cả các bảng trong các vùng. Với GTv2, công suất ghi tự động được đồng bộ hóa bởi cơ sở hạ tầng GT, vì vậy thay đổi công suất ghi trên một bảng sẽ được sao chép sang các bảng khác. Bảng phải hỗ trợ tự động mở rộng hoặc ở chế độ theo yêu cầu. Công suất đọc được phép khác nhau vì số lượng đọc có thể không đồng đều giữa các vùng. Khi thêm một bản sao toàn cầu vào bảng, công suất của vùng nguồn sẽ được truyền đi. Sau khi tạo, bạn có thể điều chỉnh công suất đọc, điều này không được chuyển đến phía bên kia. Công suất đọc cũng có thể được điều chỉnh cho từng chỉ số thứ cấp toàn cầu của từng vùng thông qua điều chỉnh thông lượng cung cấp. Global Tables hỗ trợ những vùng nào? Tính đến hôm nay, GTv2 hỗ trợ hơn 32 vùng. Danh sách mới nhất có thể được xem trong menu thả xuống trên Console khi chọn một vùng để thêm bản sao. GSIs được xử lý như thế nào với Global Tables? Với GTv2, bạn tạo một GSI trong một vùng, và nó sẽ tự động được sao chép sang vùng khác cũng như được tự động điền lại. Công suất ghi phải giống nhau trên mỗi bản sao chỉ số, nhưng bạn có thể ghi đè công suất đọc cho từng vùng. Làm thế nào để xóa một bảng toàn cầu? Bạn có thể xóa một bảng bản sao giống như bất kỳ bảng nào khác, điều này sẽ dừng việc sao chép đến vùng đó và xóa bản sao bảng được giữ trong vùng đó. Tuy nhiên, bạn không thể yêu cầu ngắt kết nối việc sao chép và giữ bản sao bảng như các thực thể độc lập. Cũng có một quy tắc bạn không thể xóa bảng nguồn nhanh chóng sau khi nó được sử dụng để khởi tạo một vùng mới. Nếu bạn thử, bạn sẽ nhận được lỗi: \u0026ldquo;Bản sao không thể bị xóa vì nó đã hoạt động như một vùng nguồn cho các bản sao mới được thêm vào bảng trong 24 giờ qua..\u0026rdquo; Xử lý xung đột ghi như thế nào với Global Tables? Xung đột có thể xảy ra nếu các ứng dụng cập nhật cùng một mục trong các vùng khác nhau gần như cùng lúc. Để đảm bảo tính nhất quán cuối cùng, bảng toàn cầu DynamoDB sử dụng cơ chế hòa giải \u0026ldquo;last writer wins\u0026rdquo; giữa các cập nhật đồng thời, trong đó DynamoDB sẽ cố gắng hết sức để xác định người ghi cuối cùng. Với cơ chế giải quyết xung đột này, tất cả các bản sao sẽ đồng ý về bản cập nhật mới nhất và hướng tới trạng thái trong đó tất cả đều có dữ liệu giống hệt nhau. Có một số cách để tránh xung đột, chẳng hạn như sử dụng chính sách IAM để chỉ cho phép ghi vào bảng ở một vùng, định tuyến người dùng đến một vùng duy nhất và giữ vùng khác ở chế độ chờ không hoạt động, định tuyến người dùng lẻ đến một vùng và người dùng chẵn đến vùng khác, tránh sử dụng các cập nhật không xác định như Bookmark = Bookmark + 1 thay vì các cập nhật tĩnh như Bookmark = 25. Để biết thêm thông tin, hãy xem hướng dẫn thực hành tốt nhất của chúng tôi về định tuyến yêu cầu với bảng toàn cầu. Những thực hành tốt nhất khi triển khai Global Tables là gì? Làm thế nào để tự động hóa việc triển khai? Trong AWS CloudFormation, mỗi bảng toàn cầu được kiểm soát bởi một ngăn xếp duy nhất, trong một vùng duy nhất, bất kể số lượng bản sao. Khi bạn triển khai mẫu của mình, CloudFormation sẽ tạo/cập nhật tất cả các bản sao như một phần của một hoạt động ngăn xếp duy nhất. Bạn không nên triển khai tài nguyên AWS::DynamoDB::GlobalTable cùng một lúc trong nhiều vùng. Làm như vậy sẽ dẫn đến lỗi và không được hỗ trợ. Nếu bạn triển khai mẫu ứng dụng của mình trong nhiều vùng, bạn có thể sử dụng điều kiện để chỉ tạo tài nguyên trong một vùng duy nhất. Ngoài ra, bạn có thể chọn định nghĩa các tài nguyên AWS::DynamoDB::GlobalTable trong một ngăn xếp tách biệt với ngăn xếp ứng dụng của bạn, và đảm bảo rằng nó chỉ được triển khai vào một vùng duy nhất. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-dynamodb-globaltable.html Một bảng DynamoDB là AWS::DynamoDB::Table và một bảng toàn cầu là AWS::DynamoDB::GlobalTable, điều này khiến chúng về cơ bản trở thành hai tài nguyên khác nhau liên quan đến CFN. Một cách tiếp cận là tạo tất cả các bảng có thể từng là bảng toàn cầu bằng cách sử dụng cấu trúc Global "
},
{
	"uri": "//localhost:1313/vi/4-lcdc/4.5/",
	"title": "Tóm tắt và dọn dẹp",
	"tags": [],
	"description": "",
	"content": "Chúc mừng! Bạn đã hoàn thành xong buổi workshop.\nTrong buổi workshop này, bạn đã khám phá cách thu thập các thay đổi cấp mục trên bảng DynamoDB bằng cách sử dụng DynamoDB Streams và Kinesis Data Streams. Trong trường hợp này, bạn đã ghi phiên bản trước của các mục đã cập nhật vào một bảng DynamoDB khác. Bằng cách áp dụng các kỹ thuật tương tự, bạn có thể xây dựng các giải pháp phức tạp dựa trên sự kiện được kích hoạt bởi các thay đổi đối với các mục mà bạn đã lưu trữ trên DynamoDB.\nNếu bạn đã sử dụng tài khoản do Workshop Studio cung cấp, bạn không cần phải thực hiện bất kỳ việc dọn dẹp nào. Tài khoản sẽ bị hủy khi sự kiện kết thúc.\nNếu bạn đã sử dụng tài khoản của riêng mình, vui lòng loại bỏ các tài nguyên sau:\nCác Mapping Nguồn Sự kiện cho Hàm Lambda: UUID_1=`aws lambda list-event-source-mappings --function-name create-order-history-kds --query \u0026#39;EventSourceMappings[].UUID\u0026#39; --output text` UUID_2=`aws lambda list-event-source-mappings --function-name create-order-history-ddbs --query \u0026#39;EventSourceMappings[].UUID\u0026#39; --output text` aws lambda delete-event-source-mapping --uuid ${UUID_1} aws lambda delete-event-source-mapping --uuid ${UUID_2} Các hàm AWS Lambda được tạo trong phòng thí nghiệm: aws lambda delete-function --function-name create-order-history-ddbs aws lambda delete-function --function-name create-order-history-kds Dữ liệu Kinesis stream được tạo trong phòng thí nghiệm: aws kinesis delete-stream --stream-name Orders Các bảng Amazon DynamoDB được tạo trong phần Bắt đầu của phòng thí nghiệm: aws dynamodb delete-table --table-name Orders aws dynamodb delete-table --table-name OrdersHistory Các hàng đợi Amazon SQS được tạo trong phòng thí nghiệm: aws sqs delete-queue --queue-url https://sqs.${REGION}.amazonaws.com/${ACCOUNT_ID}/orders-ddbs-dlq aws sqs delete-queue --queue-url https://sqs.${REGION}.amazonaws.com/${ACCOUNT_ID}/orders-kds-dlq Các chính sách IAM gắn vào vai trò thực thi IAM mà bạn đã tạo: Các vai trò thực thi AWS IAM được tạo cho các hàm lambda: Đây là các bước để hoàn tất quá trình dọn dẹp.\n"
},
{
	"uri": "//localhost:1313/vi/6-leda/6.5/",
	"title": "Tóm tắt: Kết luận",
	"tags": [],
	"description": "",
	"content": "Chúc mừng bạn Bạn đã hoàn thành cả hai labs!\nDọn dẹp tất cả các tài nguyên Nếu bạn đang chạy lab này như một phần của sự kiện AWS trên tài khoản mà chúng tôi cung cấp, bạn không cần phải làm gì thêm. Nếu bạn đang tự chạy lab này, hãy đảm bảo dọn dẹp mọi tài nguyên đã được tạo bằng cách xóa stack CloudFormation.\nBlogs Workshop này dựa trên một loạt bài viết 2 phần trên blog AWS Database được công bố lần đầu vào tháng 11 năm 2021.\nPhần 1: Xây dựng một pipeline tổng hợp dữ liệu gần như thời gian thực bằng kiến trúc không máy chủ, dựa trên sự kiện Phần 2: Xây dựng một pipeline tổng hợp dữ liệu không máy chủ, chịu lỗi với xử lý chỉ một lần Nguồn blog Trong khi workshop này được mở mã nguồn, các bài blog đã được phát hành kèm với một kho GitHub chứa nhiều mã giống như bạn đã sử dụng trong workshop này. Kho aws-serverless-realtime-aggregation có trên GitHub.\nGiải pháp Xem Giải pháp\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.2/1.2.5/",
	"title": "Xóa Data",
	"tags": [],
	"description": "",
	"content": "DynamoDB cung cấp API DeleteItem để xóa một mục. Nó được gọi bằng lệnh CLI delete-item.\nViệc xóa trong DynamoDB luôn là các thao tác đơn lẻ. Không có lệnh nào mà bạn có thể chạy để xóa tất cả các hàng trong bảng, chẳng hạn.\nHãy nhớ mục mà chúng ta đã thêm vào bảng Reply trong phần trước:\naws dynamodb get-item \\ --table-name Reply \\ --key \u0026#39;{ \u0026#34;Id\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB#DynamoDB Thread 2\u0026#34;}, \u0026#34;ReplyDateTime\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;2021-04-27T17:47:30Z\u0026#34;} }\u0026#39; Hãy xóa mục này. Khi sử dụng lệnh delete-item, chúng ta cần tham chiếu đến đầy đủ Khóa Chính giống như khi dùng get-item:\naws dynamodb delete-item \\ --table-name Reply \\ --key \u0026#39;{ \u0026#34;Id\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB#DynamoDB Thread 2\u0026#34;}, \u0026#34;ReplyDateTime\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;2021-04-27T17:47:30Z\u0026#34;} }\u0026#39; Bạn có thể an toàn xóa cùng một mục nhiều lần. Bạn có thể chạy cùng một lệnh trên nhiều lần tùy ý mà không gặp lỗi; nếu khóa không tồn tại thì API DeleteItem vẫn trả về thành công.\nSau khi chúng ta đã xóa mục đó khỏi bảng Reply, chúng ta cũng cần giảm số đếm Messages liên quan trong bảng Forum.\naws dynamodb update-item \\ --table-name Forum \\ --key \u0026#39;{ \u0026#34;Name\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB\u0026#34;} }\u0026#39; \\ --update-expression \u0026#34;SET Messages = :newMessages\u0026#34; \\ --condition-expression \u0026#34;Messages = :oldMessages\u0026#34; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:oldMessages\u0026#34; : {\u0026#34;N\u0026#34;: \u0026#34;5\u0026#34;}, \u0026#34;:newMessages\u0026#34; : {\u0026#34;N\u0026#34;: \u0026#34;4\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.6/",
	"title": "Bài tập 5: Sparse Global Secondary Indexes",
	"tags": [],
	"description": "",
	"content": "Bạn có thể sử dụng một sparse global secondary index (chỉ mục phụ toàn cầu thưa) để xác định các mục bảng có một thuộc tính không phổ biến. Để làm điều này, bạn tận dụng thực tế rằng các mục bảng không chứa thuộc tính của chỉ mục phụ toàn cầu sẽ không được lập chỉ mục.\nTruy vấn như vậy cho các mục bảng có một thuộc tính không phổ biến có thể rất hiệu quả vì số lượng mục trong chỉ mục nhỏ hơn đáng kể so với số lượng mục trong bảng. Ngoài ra, càng ít thuộc tính bảng bạn chiếu vào chỉ mục, thì càng ít đơn vị dung lượng ghi và đọc bạn tiêu thụ từ chỉ mục đó.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.1/3.1.6/",
	"title": "Bước 5 - Kiểm tra định dạng và nội dung tệp",
	"tags": [],
	"description": "",
	"content": "Trong quá trình thực hiện lab này, bạn sẽ làm việc với các loại dữ liệu khác nhau:\nDữ liệu nhật ký máy chủ (Server Logs) Dữ liệu nhân viên (Employees data) Dữ liệu hóa đơn và biên lai (Invoices and Bills data) Tệp nhật ký máy chủ (Server Logs) có cấu trúc như sau:\nrequestid (số) host (chuỗi) date (chuỗi) hourofday (số) timezone (chuỗi) method (chuỗi) url (chuỗi) responsecode (số) bytessent (số) useragent (chuỗi) Để xem một bản ghi mẫu trong tệp, thực hiện lệnh:\nhead -n1 ./data/logfile_small1.csv Bản ghi nhật ký mẫu:\n1,66.249.67.3,2017-07-20,20,GMT-0700,GET,\u0026#34;/gallery/main.php?g2_controller=exif.SwitchDetailMode\u0026amp;g2_mode=detailed\u0026amp;g2_return=%2Fgallery%2Fmain.php%3Fg2_itemId%3D15741\u0026amp;g2_returnName=photo\u0026#34;,302,5,\u0026#34;Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\u0026#34; Tệp dữ liệu nhân viên (Employees data) có cấu trúc như sau:\nemployeeid (số) name (chuỗi) title (chuỗi) dept (chuỗi) city (chuỗi) state (chuỗi) dob (chuỗi) hire-date (chuỗi) previous title (chuỗi) previous title end date (chuỗi) is a manager (chuỗi), 1 nếu là quản lý, không có giá trị nếu không phải là quản lý Để xem một bản ghi mẫu trong tệp, thực hiện lệnh:\nhead -n1 ./data/employees.csv Bản ghi nhân viên mẫu:\n1,Onfroi Greeno,Systems Administrator,Operation,Portland,OR,1992-03-31,2014-10-24,Application Support Analyst,2014-04-12 "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.9/3.9.6/",
	"title": "Bước 6 - Điền vào bảng logfile và xác minh sao chép để logfile_replica",
	"tags": [],
	"description": "",
	"content": "Chạy đoạn mã Python sau để tải thêm các mục vào bảng logfile. Các hàng sẽ được sao chép vào DynamoDB stream, được xử lý bởi hàm AWS Lambda, và sau đó được ghi vào bảng logfile_replica cuối cùng.\npython load_logfile.py logfile ./data/logfile_stream.csv Kết quả đầu ra sẽ trông như sau:\nRowCount: 2000, Total seconds: 15.808809518814087 Xác minh việc sao chép Bạn có thể quét bảng logfile_replica để xác minh rằng các bản ghi đã được sao chép. Quá trình này mất vài giây, vì vậy bạn có thể cần phải lặp lại lệnh AWS CLI sau đây cho đến khi bạn nhận được các bản ghi. Một lần nữa, sử dụng phím mũi tên lên để lặp lại lệnh trước đó.\naws dynamodb scan --table-name \u0026#39;logfile_replica\u0026#39; --max-items 2 --output text Bạn sẽ thấy hai mục đầu tiên của bảng sao chép như sau:\nNone 723 723 BYTESSENT 2969 DATE 2009-07-21 HOST 64.233.172.17 HOUROFDAY 8 METHOD GET REQUESTID 4666 RESPONSECODE 200 TIMEZONE GMT-0700 URL /gwidgets/alexa.xml USERAGENT Mozilla/5.0 (compatible) Feedfetcher-Google; (+http://www.google.com/feedfetcher.html) BYTESSENT 1160 DATE 2009-07-21 HOST 64.233.172.17 HOUROFDAY 6 METHOD GET REQUESTID 4119 RESPONSECODE 200 TIMEZONE GMT-0700 URL /gadgets/adpowers/AlexaRank/ALL_ALL.xml USERAGENT Mozilla/5.0 (compatible) Feedfetcher-Google; (+http://www.google.com/feedfetcher.html) NEXTTOKEN eyJFeGNsdXNpdmVTdGFydEtleSI6IG51bGwsICJib3RvX3RydW5jYXRlX2Ftb3VudCI6IDJ9 Lưu ý: Nhật ký của bạn có thể khác nhau. Miễn là bạn có hai mục nhật ký, bạn đã xác minh việc sao chép thành công. Nếu bạn không thấy bất kỳ mục nào, hãy chạy lại lệnh load_logfile.py vì bạn có thể đã thực hiện các lệnh chèn quá sớm sau khi tạo hàm Lambda.\nChúc mừng, bạn đã hoàn thành thành công tất cả các bài tập trong buổi workshop! Nếu bạn tự thực hiện lab trên tài khoản AWS của mình, bạn nên xóa tất cả các bảng được tạo trong quá trình này. Nếu bạn đang ở một sự kiện AWS sử dụng nền tảng AWS Workshop (Workshop Studio), bạn không cần xóa bảng của mình.\nTrong quá trình thực hiện lab, bạn đã tạo các bảng DynamoDB có thể phát sinh chi phí lên tới hàng chục hoặc hàng trăm đô la mỗi ngày. Bạn phải xóa các bảng DynamoDB bằng cách sử dụng bảng điều khiển DynamoDB để dọn dẹp lab. Ngoài ra, nếu bạn không thuộc một sự kiện AWS hoặc bạn đang chạy lab này trong tài khoản của riêng mình, hãy đảm bảo xóa stack CloudFormation ngay khi hoàn thành lab. Nếu bạn đang sử dụng Workshop Studio Event Delivery, bạn không cần phải xóa stack CloudFormation.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.2/3.2.6/",
	"title": "Bước 6 - Sau khi tăng dung lượng của bảng, tải thêm dữ liệu",
	"tags": [],
	"description": "",
	"content": "Sau khi bạn tăng dung lượng của bảng, hãy chạy lại tập lệnh Python sau để điền bảng bằng cách sử dụng logfile_medium2.csv Nhập tệp dữ liệu có cùng số hàng như khi bạn chạy lệnh này trước đó. Lưu ý rằng việc thực hiện lệnh xảy ra nhanh hơn lần này.\npython load_logfile.py logfile ./data/logfile_medium2.csv Đầu ra sẽ như thế này:\nrow: 100 in 0.9451174736022949 row: 200 in 0.8512668609619141 ... row: 1900 in 0.8499886989593506 row: 2000 in 0.8817043304443359 RowCount: 2000, Total seconds: 17.13607406616211 Với công suất mới, tổng thời gian tải thấp hơn.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.4/1.4.6/",
	"title": "Dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dọn dẹp tài nguyên Bước 1: Xóa các tài nguyên AWS đã khôi phục Xóa ba bảng DynamoDB đã khôi phục bằng lệnh sau.\naws dynamodb delete-table \\ --table-name ProductCatalogODRestore aws dynamodb delete-table \\ --table-name ProductCatalogRestored aws dynamodb delete-table \\ --table-name ProductCatalogPITR Bước 2: Xóa kế hoạch sao lưu Thực hiện các bước sau để xóa một kế hoạch sao lưu:\nTrong AWS Management Console, điều hướng đến Services -\u0026gt; AWS Backup. Trong bảng điều hướng, chọn Backup plans. Trên trang Backup plans, chọn dbBackupPlan. Thao tác này sẽ đưa bạn đến trang chi tiết. Để xóa việc gán tài nguyên cho kế hoạch của bạn, chọn nút radio bên cạnh dynamodbTable trong phần Resource assignments, sau đó chọn Delete. Để xóa kế hoạch sao lưu, chọn Delete ở góc trên bên phải của trang. Trên trang xác nhận, nhập dbBackupPlan, và chọn Delete plan. Bước 3: Xóa các điểm khôi phục Trên AWS Backup console, trong bảng điều hướng, chọn Backup vaults.\nTrên trang Backup vaults, chọn dynamodb-backup-vault. Kiểm tra điểm khôi phục và chọn Delete.\nNếu bạn đang xóa nhiều hơn một điểm khôi phục, hãy làm theo các bước sau:\na. Xem lại danh sách các điểm khôi phục mà bạn đang xóa.\nb. Nếu bạn muốn chỉnh sửa danh sách, chọn Modify selection.\nc. Nếu danh sách của bạn chứa một bản sao lưu liên tục, chọn xem bạn muốn giữ lại hay xóa dữ liệu sao lưu liên tục của mình.\nd. Để xóa tất cả các điểm khôi phục được liệt kê, nhập delete, và sau đó chọn Delete recovery points.\nGiữ tab trình duyệt của bạn mở cho đến khi bạn thấy biểu ngữ màu xanh lá cây thành công ở đầu trang.\nĐóng tab này quá sớm sẽ kết thúc quá trình xóa và có thể để lại một số điểm khôi phục mà bạn muốn xóa.\nBước 4: Xóa backup vault Chọn backup vault dynamodb-backup-vault và chọn Delete. Trên trang xác nhận, nhập dynamodb-backup-vault, và chọn Delete Backup vault. "
},
{
	"uri": "//localhost:1313/vi/6-leda/",
	"title": "LEDA: Xây dựng Kiến trúc Serverless Event Driven với DynamoDB",
	"tags": [],
	"description": "",
	"content": "Trong workshop này, bạn sẽ được giới thiệu với một pipeline tổng hợp dữ liệu dựa trên sự kiện không máy chủ. Pipeline này được xây dựng với AWS Lambda, Amazon DynamoDB, và Amazon Kinesis Data Streams.\nMặc dù bạn có thể vui lòng tham gia workshop này, hãy lưu ý rằng pipeline hiện đang bị lỗi và cần sự chú ý của bạn để hoạt động trở lại! Như bạn sẽ sớm phát hiện, workshop được thiết kế với một luồng đầu vào chứa các bản sao trùng lặp và các hàm Lambda ngẫu nhiên bị lỗi.\nTrong suốt hai bài thực hành, bạn sẽ phải kết nối tất cả các thành phần của pipeline và sau đó cập nhật các hàm Lambda để tránh mất hoặc trùng lặp tin nhắn dưới các trường hợp lỗi ngẫu nhiên (được tạo ra).\nDưới đây là nội dung của workshop này:\nBắt đầu từ đây: Khởi động Tổng quan Bài thực hành 1: Kết nối pipeline Bài thực hành 2: Đảm bảo khả năng chịu lỗi và xử lý chính xác từng lần Tóm tắt: Kết luận Đối tượng mục tiêu Workshop này dành cho bất kỳ ai quan tâm đến việc hiểu cách xây dựng các pipeline xử lý dữ liệu không máy chủ. Kiến thức cơ bản về các dịch vụ AWS và kinh nghiệm lập trình Python là điều mong muốn nhưng không bắt buộc. Chúng tôi xếp loại workshop này ở mức độ 300, có nghĩa là bạn không cần phải là chuyên gia về bất kỳ dịch vụ nào trong ba dịch vụ được tập trung vào.\nYêu cầu Kiến thức cơ bản về các dịch vụ AWS Trong các dịch vụ khác, bài thực hành này sẽ hướng dẫn bạn cách sử dụng Amazon Kinesis Data Streams và AWS Lambda. Hiểu biết cơ bản về DynamoDB Nếu bạn chưa quen với DynamoDB hoặc không tham gia vào bài thực hành này như một phần của sự kiện AWS, hãy xem lại tài liệu về \u0026ldquo;Amazon DynamoDB là gì? \u0026quot; Quen thuộc với Python/Boto3 Bạn sẽ sao chép và dán mã để tập trung vào việc học về DynamoDB. Bạn sẽ có thể xem lại tất cả mã đã chạy trong các bài tập. Thời lượng Workshop yêu cầu khoảng 2 giờ để hoàn thành.\nKết quả đạt được Sử dụng các ví dụ thực tế, hiểu cách kết nối các thành phần AWS không máy chủ vào một pipeline dựa trên sự kiện. Hiểu cách tận dụng các tính năng đặc biệt của DynamoDB và Lambda để xây dựng một pipeline xử lý dữ liệu đáng tin cậy với tính chính xác từng lần xử lý. Hiểu các chế độ lỗi khác nhau và cơ chế thử lại. "
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.5/1.5.6/",
	"title": "Load DynamoDB Table",
	"tags": [],
	"description": "",
	"content": "Trong bài tập này, chúng ta sẽ thiết lập các công việc của Dịch vụ Di chuyển Cơ sở dữ liệu (Database Migration Service - DMS) để di chuyển dữ liệu từ cơ sở dữ liệu MySQL nguồn (dạng xem quan hệ, bảng) sang Amazon DynamoDB.\nXác minh việc tạo DMS Truy cập DMS Console và nhấp vào \u0026ldquo;Replication Instances\u0026rdquo;. Bạn sẽ thấy một bản sao nhân bản với Class dms.c5.2xlarge ở trạng thái \u0026ldquo;Available\u0026rdquo;.\nHãy đảm bảo rằng DMS instance ở trạng thái \u0026ldquo;Available\u0026rdquo; trước khi bạn tiếp tục. Nếu không phải là \u0026ldquo;Available\u0026rdquo;, quay lại bảng điều khiển CloudFormation để xem xét và khắc phục sự cố với CloudFormation stack.\nTạo endpoints nguồn và đích Nhấp vào \u0026ldquo;Endpoints\u0026rdquo; và nút \u0026ldquo;Create endpoint\u0026rdquo;.\nTạo endpoint nguồn. Sử dụng các tham số sau để cấu hình endpoint:\nTham số Giá trị Endpoint type Source endpoint Endpoint identifier mysql-endpoint Source engine MySQL Access to endpoint database Chọn radio button \u0026ldquo;Provide access information manually\u0026rdquo; Server name Từ EC2 dashboard, chọn MySQL-Instance và sao chép Public IPv4 DNS Port 3306 SSL mode none User name Giá trị của DbMasterUsername đã thêm làm tham số khi cấu hình môi trường MySQL Password Giá trị của DbMasterPassword đã thêm làm tham số khi cấu hình môi trường MySQL Mở phần \u0026ldquo;Test endpoint connection (optional)\u0026rdquo;, sau đó trong danh sách thả xuống VPC chọn DMS-VPC và nhấp vào nút \u0026ldquo;Run test\u0026rdquo; để xác minh cấu hình endpoint của bạn là hợp lệ. Bài kiểm tra sẽ chạy trong một phút và bạn sẽ thấy một thông báo thành công trong cột Status. Nhấp vào nút \u0026ldquo;Create endpoint\u0026rdquo; để tạo endpoint. Nếu bạn thấy lỗi kết nối, hãy nhập lại tên người dùng và mật khẩu để đảm bảo không có sai sót. Ngoài ra, hãy đảm bảo bạn đã cung cấp tên DNS IPv4 kết thúc bằng amazonaws.com trong trường Server name.\nTạo endpoint đích. Lặp lại tất cả các bước để tạo endpoint đích với các giá trị tham số sau:\nTham số Giá trị Endpoint type Target endpoint Endpoint identifier dynamodb-endpoint Target engine Amazon DynamoDB Service access role ARN CloudFormation template đã tạo vai trò mới với toàn quyền truy cập Amazon DynamoDB. Sao chép Role ARN từ vai trò dynamodb-access Mở phần \u0026ldquo;Test endpoint connection (optional)\u0026rdquo;, sau đó trong danh sách thả xuống VPC chọn DMS-VPC và nhấp vào nút \u0026ldquo;Run test\u0026rdquo; để xác minh cấu hình endpoint của bạn là hợp lệ. Bài kiểm tra sẽ chạy trong một phút và bạn sẽ thấy một thông báo thành công trong cột Status. Nhấp vào nút \u0026ldquo;Create endpoint\u0026rdquo; để tạo endpoint.\nCấu hình và chạy tác vụ sao chép Vẫn ở trong AWS DMS console, vào \u0026ldquo;Database migration tasks\u0026rdquo; và nhấp vào nút \u0026ldquo;Create Task\u0026rdquo;. Chúng ta sẽ tạo 3 công việc sao chép để di chuyển dữ liệu đã được không chuẩn hóa, xếp hạng (title_ratings), và thông tin vùng/ngôn ngữ (title_akas).\nTác vụ 1: Nhập các giá trị tham số sau trong màn hình \u0026ldquo;Create database migration task\u0026rdquo;:\nTham số Giá trị Task identified historical-migration01 Replication instance mysqltodynamodb-instance-* Source database endpoint mysql-endpoint Target database endpoint dynamodb-endpoint Migration type Migrate existing data Task settings: Editing mode Wizard Task settings: Target table preparation mode Do nothing Task settings: Turn on CloudWatch logs Checked Table mappings: Editing mode Chọn tùy chọn \u0026ldquo;JSON editor\u0026rdquo; và làm theo hướng dẫn sau các ảnh chụp màn hình bên dưới Mở phần \u0026ldquo;JSON editor\u0026rdquo; trong trình duyệt của bạn. Trong phần này, chúng ta sẽ tạo tài liệu JSON cho \u0026ldquo;Table mappings\u0026rdquo; để thay thế những gì bạn thấy trong \u0026ldquo;JSON editor\u0026rdquo;. Tài liệu này bao gồm việc ánh xạ từ nguồn sang đích bao gồm bất kỳ chuyển đổi nào trên các bản ghi sẽ được thực hiện trong quá trình di chuyển. Để giảm thời gian tải trong Immersion Day, chúng tôi đã giới hạn danh sách di chuyển đến các bộ phim đã chọn lọc. Dưới đây là tài liệu JSON với danh sách 28 bộ phim do Clint Eastwood tham gia. Các bài tập còn lại sẽ chỉ tập trung vào những bộ phim này. Tuy nhiên, bạn có thể tải dữ liệu còn lại nếu muốn khám phá thêm. Một số thống kê xung quanh bộ dữ liệu đầy đủ được đưa ra ở cuối chương này.\nSao chép danh sách các bộ phim đã chọn lọc của Clint Eastwood.\n{ \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt0309377\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt12260846\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt1212419\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt1205489\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt1057500\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt0949815\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt0824747\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt0772168\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt0498380\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt0418689\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt0405159\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt0327056\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt2310814\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt2179136\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt2083383\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt1924245\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt1912421\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt1742044\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt1616195\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt6997426\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt6802308\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt3513548\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt3263904\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt3031654\u0026#34; }, { \u0026#34;filter-operator\u0026#34;: \u0026#34;eq\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;tt8884452\u0026#34; } Tài liệu JSON dưới đây sẽ di chuyển dữ liệu đã được không chuẩn hóa từ cơ sở dữ liệu MySQL imdb (Task identified: historical-migration01). Thay thế chuỗi “REPLACE THIS STRING BY MOVIES LIST” bằng danh sách phim đã sao chép trước đó (Xem ảnh chụp màn hình dưới đây nếu có bất kỳ nhầm lẫn nào). Sau đó dán mã JSON kết quả vào \u0026ldquo;JSON editor\u0026rdquo;, thay thế mã hiện có.\n{ \u0026#34;rules\u0026#34;: [ { \u0026#34;rule-type\u0026#34;: \u0026#34;selection\u0026#34;, ```json { \u0026#34;rule-id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;rule-name\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;object-locator\u0026#34;: { \u0026#34;schema-name\u0026#34;: \u0026#34;imdb\u0026#34;, \u0026#34;table-name\u0026#34;: \u0026#34;movies\u0026#34;, \u0026#34;table-type\u0026#34;: \u0026#34;view\u0026#34; }, \u0026#34;rule-action\u0026#34;: \u0026#34;include\u0026#34;, \u0026#34;filters\u0026#34;: [ { \u0026#34;filter-type\u0026#34;: \u0026#34;source\u0026#34;, \u0026#34;column-name\u0026#34;: \u0026#34;tconst\u0026#34;, \u0026#34;filter-conditions\u0026#34;: [\u0026#34;REPLACE THIS STRING BY MOVIES LIST\u0026#34;] } ] }, { \u0026#34;rule-type\u0026#34;: \u0026#34;object-mapping\u0026#34;, \u0026#34;rule-id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;rule-name\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;rule-action\u0026#34;: \u0026#34;map-record-to-record\u0026#34;, \u0026#34;object-locator\u0026#34;: { \u0026#34;schema-name\u0026#34;: \u0026#34;imdb\u0026#34;, \u0026#34;table-name\u0026#34;: \u0026#34;movies\u0026#34;, \u0026#34;table-type\u0026#34;: \u0026#34;view\u0026#34; }, \u0026#34;target-table-name\u0026#34;: \u0026#34;movies\u0026#34;, \u0026#34;mapping-parameters\u0026#34;: { \u0026#34;partition-key-name\u0026#34;: \u0026#34;mpkey\u0026#34;, \u0026#34;sort-key-name\u0026#34;: \u0026#34;mskey\u0026#34;, \u0026#34;exclude-columns\u0026#34;: [], \u0026#34;attribute-mappings\u0026#34;: [ { \u0026#34;target-attribute-name\u0026#34;: \u0026#34;mpkey\u0026#34;, \u0026#34;attribute-type\u0026#34;: \u0026#34;scalar\u0026#34;, \u0026#34;attribute-sub-type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;${tconst}\u0026#34; }, { \u0026#34;target-attribute-name\u0026#34;: \u0026#34;mskey\u0026#34;, \u0026#34;attribute-type\u0026#34;: \u0026#34;scalar\u0026#34;, \u0026#34;attribute-sub-type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;DETL|${category}|${ordering}\u0026#34; } ] } } ] } Đi tới cuối trang và nhấp vào \u0026ldquo;Create task\u0026rdquo;. Lúc này, tác vụ sẽ được tạo và tự động bắt đầu tải các bộ phim đã chọn từ nguồn sang bảng DynamoDB đích. Bạn có thể tiến hành và tạo thêm hai tác vụ với các bước tương tự (historical-migration02 và historical-migration03). Sử dụng cùng cài đặt như trên ngoại trừ tài liệu JSON \u0026ldquo;Table Mappings\u0026rdquo;. Đối với các tác vụ historical-migration02 và historical-migration03, hãy sử dụng tài liệu JSON được đề cập bên dưới.\nDưới đây là tài liệu JSON sẽ di chuyển bảng title_akas từ cơ sở dữ liệu MySQL IMDb (Task identified: historical-migration02). Thay thế chuỗi \u0026ldquo;REPLACE THIS STRING BY MOVIES LIST\u0026rdquo; bằng danh sách các bộ phim đã sao chép trước đó.\n{ \u0026#34;rules\u0026#34;: [ { \u0026#34;rule-type\u0026#34;: \u0026#34;selection\u0026#34;, \u0026#34;rule-id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;rule-name\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;object-locator\u0026#34;: { \u0026#34;schema-name\u0026#34;: \u0026#34;imdb\u0026#34;, \u0026#34;table-name\u0026#34;: \u0026#34;title_akas\u0026#34;, \u0026#34;table-type\u0026#34;: \u0026#34;table\u0026#34; }, \u0026#34;rule-action\u0026#34;: \u0026#34;include\u0026#34;, \u0026#34;filters\u0026#34;: [ { \u0026#34;filter-type\u0026#34;: \u0026#34;source\u0026#34;, \u0026#34;column-name\u0026#34;: \u0026#34;titleId\u0026#34;, \u0026#34;filter-conditions\u0026#34;: [\u0026#34;REPLACE THIS STRING BY MOVIES LIST\u0026#34;] } ] }, { \u0026#34;rule-type\u0026#34;: \u0026#34;object-mapping\u0026#34;, \u0026#34;rule-id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;rule-name\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;rule-action\u0026#34;: \u0026#34;map-record-to-record\u0026#34;, \u0026#34;object-locator\u0026#34;: { \u0026#34;schema-name\u0026#34;: \u0026#34;imdb\u0026#34;, \u0026#34;table-name\u0026#34;: \u0026#34;title_akas\u0026#34;, \u0026#34;table-type\u0026#34;: \u0026#34;table\u0026#34; }, \u0026#34;target-table-name\u0026#34;: \u0026#34;movies\u0026#34;, \u0026#34;mapping-parameters\u0026#34;: { \u0026#34;partition-key-name\u0026#34;: \u0026#34;mpkey\u0026#34;, \u0026#34;sort-key-name\u0026#34;: \u0026#34;mskey\u0026#34;, \u0026#34;exclude-columns\u0026#34;: [], \u0026#34;attribute-mappings\u0026#34;: [ { \u0026#34;target-attribute-name\u0026#34;: \u0026#34;mpkey\u0026#34;, \u0026#34;attribute-type\u0026#34;: \u0026#34;scalar\u0026#34;, \u0026#34;attribute-sub-type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;${titleId}\u0026#34; }, { \u0026#34;target-attribute-name\u0026#34;: \u0026#34;mskey\u0026#34;, \u0026#34;attribute-type\u0026#34;: \u0026#34;scalar\u0026#34;, \u0026#34;attribute-sub-type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;REGN|${region}\u0026#34; } ] } } ] } Dưới đây là tài liệu JSON sẽ di chuyển bảng title_ratings từ cơ sở dữ liệu MySQL IMDb (Task identified: historical-migration03). Thay thế chuỗi \u0026ldquo;REPLACE THIS STRING BY MOVIES LIST\u0026rdquo; bằng danh sách các bộ phim đã sao chép trước đó.\n{ \u0026#34;rules\u0026#34;: [ { \u0026#34;rule-type\u0026#34;: \u0026#34;selection\u0026#34;, \u0026#34;rule-id\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;rule-name\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;object-locator\u0026#34;: { \u0026#34;schema-name\u0026#34;: \u0026#34;imdb\u0026#34;, \u0026#34;table-name\u0026#34;: \u0026#34;title_ratings\u0026#34;, \u0026#34;table-type\u0026#34;: \u0026#34;table\u0026#34; }, \u0026#34;rule-action\u0026#34;: \u0026#34;include\u0026#34;, \u0026#34;filters\u0026#34;: [ { \u0026#34;filter-type\u0026#34;: \u0026#34;source\u0026#34;, \u0026#34;column-name\u0026#34;: \u0026#34;tconst\u0026#34;, \u0026#34;filter-conditions\u0026#34;: [\u0026#34;REPLACE THIS STRING BY MOVIES LIST\u0026#34;] } ] }, { \u0026#34;rule-type\u0026#34;: \u0026#34;object-mapping\u0026#34;, \u0026#34;rule-id\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;rule-name\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;rule-action\u0026#34;: \u0026#34;map-record-to-record\u0026#34;, \u0026#34;object-locator\u0026#34;: { \u0026#34;schema-name\u0026#34;: \u0026#34;imdb\u0026#34;, \u0026#34;table-name\u0026#34;: \u0026#34;title_ratings\u0026#34;, \u0026#34;table-type\u0026#34;: \u0026#34;table\u0026#34; }, \u0026#34;target-table-name\u0026#34;: \u0026#34;movies\u0026#34;, \u0026#34;mapping-parameters\u0026#34;: { \u0026#34;partition-key-name\u0026#34;: \u0026#34;mpkey\u0026#34;, \u0026#34;sort-key-name\u0026#34;: \u0026#34;mskey\u0026#34;, \u0026#34;exclude-columns\u0026#34;: [], \u0026#34;attribute-mappings\u0026#34;: [ { \u0026#34;target-attribute-name\u0026#34;: \u0026#34;mpkey\u0026#34;, \u0026#34;attribute-type\u0026#34;: \u0026#34;scalar\u0026#34;, \u0026#34;attribute-sub-type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;${tconst}\u0026#34; }, { \u0026#34;target-attribute-name\u0026#34;: \u0026#34;mskey\u0026#34;, \u0026#34;attribute-type\u0026#34;: \u0026#34;scalar\u0026#34;, \u0026#34;attribute-sub-type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;RTNG\u0026#34; } ] } } ] } Giải pháp Nếu bạn gặp khó khăn khi tạo tài liệu JSON cho các tác vụ, mở rộng phần này để xem giải pháp!\nTask đầu tiên - historical-migration01 Task thứ hai - historical-migration02 Task thứ ba - historical-migration03 Giám sát và khởi động lại/tái khởi động các tác vụ Các tác vụ sao chép để di chuyển dữ liệu lịch sử từ MySQL imdb.movies view, title_akas, và title_ratings sang bảng DynamoDB sẽ bắt đầu trong vài phút. Nếu bạn đang tải các bản ghi đã chọn dựa trên danh sách trên, có thể mất 5-10 phút để hoàn tất cả ba tác vụ.\nNếu bạn chạy bài tập này lần nữa và thực hiện tải đầy đủ, thời gian tải sẽ như sau:\nTác vụ historical-migration01 sẽ di chuyển hơn 800K bản ghi và thường mất 2-3 giờ. Tác vụ historical-migration02 sẽ di chuyển hơn 747K bản ghi và thường mất 2-3 giờ. Tác vụ historical-migration03 sẽ di chuyển hơn 79K bản ghi và thường mất 10-15 phút. Bạn có thể theo dõi trạng thái tải dữ liệu dưới phần \u0026ldquo;Table statistics\u0026rdquo; của tác vụ di chuyển. Khi quá trình tải đang tiến hành, hãy thoải mái chuyển sang phần tiếp theo của bài tập.\nHãy đảm bảo tất cả các tác vụ đang chạy hoặc đã hoàn tất trước khi bạn tiếp tục. Nếu một tác vụ ở trạng thái \u0026ldquo;Ready\u0026rdquo;, hãy chọn hộp kiểm của nó và chọn \u0026ldquo;Restart/Resume\u0026rdquo; dưới nút \u0026ldquo;Actions\u0026rdquo; để bắt đầu tác vụ.\n"
},
{
	"uri": "//localhost:1313/vi/5-lmr/5.6/",
	"title": "Tóm tắt",
	"tags": [],
	"description": "",
	"content": "Chúng tôi hy vọng bạn đã thích workshop này và học được cách xây dựng và triển khai các ứng dụng toàn cầu! Hãy thoải mái gửi yêu cầu thay đổi đến GitHub issues của chúng tôi.\nNếu bạn đang tham gia workshop này như một phần của sự kiện do AWS tài trợ, tài khoản tạm thời của bạn sẽ bị hủy vào cuối sự kiện và tất cả các tài nguyên sẽ được xóa, do đó bạn không cần phải làm gì thêm.\nNếu bạn đang thực hiện workshop này trên tài khoản AWS của riêng bạn, bạn có thể xóa CloudFormation Stack DynamoDBID và các thành phần do Chalice tạo ra để tránh phát sinh bất kỳ chi phí nào sau đó. Bảng DynamoDB được tạo ở chế độ On Demand, vì vậy không có chi phí cho mức công suất cấp phát, chỉ có chi phí cho sử dụng thực tế. Tuy nhiên, sẽ có một số chi phí nhỏ cho lưu trữ nếu bảng không được dọn sạch.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.2/1.2.6/",
	"title": "Transactions",
	"tags": [],
	"description": "",
	"content": "DynamoDB cung cấp API TransactWriteItems, một thao tác ghi đồng bộ nhóm lên đến 100 yêu cầu hành động (tổng cộng không vượt quá giới hạn kích thước 4MB cho giao dịch). Nó được gọi bằng lệnh CLI transact-write-items.\nCác hành động này có thể nhắm đến các mục trong các bảng khác nhau, nhưng không thể nhắm đến các tài khoản hoặc Vùng AWS khác nhau, và không có hai hành động nào có thể nhắm đến cùng một mục. Các hành động được hoàn thành một cách nguyên tử sao cho tất cả đều thành công, hoặc tất cả đều thất bại. Để thảo luận sâu hơn về Cấp độ Cô lập cho Giao dịch, hãy xem Hướng dẫn Dành cho Nhà Phát triển.\nBạn sẽ nhớ từ các mô-đun trước rằng dữ liệu mẫu chứa nhiều bảng liên quan: Forum, Thread, và Reply. Khi một mục Reply mới được thêm vào, chúng ta cũng cần tăng số lượng Messages trong mục Forum liên quan. Điều này nên được thực hiện trong một giao dịch để cả hai thay đổi đều thành công hoặc cả hai thay đổi đều thất bại cùng một lúc, và ai đó đọc dữ liệu này sẽ thấy cả hai thay đổi hoặc không thấy thay đổi nào cùng một lúc.\nGiao dịch trong DynamoDB tôn trọng khái niệm idempotency. Idempotency cho phép bạn gửi cùng một giao dịch nhiều lần, nhưng DynamoDB sẽ chỉ thực thi giao dịch đó một lần. Điều này đặc biệt hữu ích khi sử dụng các API không tự chúng là idempotent, như sử dụng UpdateItem để tăng hoặc giảm một trường số. Khi thực thi một giao dịch, bạn sẽ chỉ định một chuỗi để đại diện cho ClientRequestToken (còn gọi là Idempotency Token). Để thảo luận thêm về idempotency, vui lòng xem Hướng dẫn Dành cho Nhà Phát triển.\nLệnh này trong CLI sẽ là:\naws dynamodb transact-write-items --client-request-token TRANSACTION1 --transact-items \u0026#39;[ { \u0026#34;Put\u0026#34;: { \u0026#34;TableName\u0026#34; : \u0026#34;Reply\u0026#34;, \u0026#34;Item\u0026#34; : { \u0026#34;Id\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB#DynamoDB Thread 2\u0026#34;}, \u0026#34;ReplyDateTime\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;2021-04-27T17:47:30Z\u0026#34;}, \u0026#34;Message\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;DynamoDB Thread 2 Reply 3 text\u0026#34;}, \u0026#34;PostedBy\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;User C\u0026#34;} } } }, { \u0026#34;Update\u0026#34;: { \u0026#34;TableName\u0026#34; : \u0026#34;Forum\u0026#34;, \u0026#34;Key\u0026#34; : {\u0026#34;Name\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB\u0026#34;}}, \u0026#34;UpdateExpression\u0026#34;: \u0026#34;ADD Messages :inc\u0026#34;, \u0026#34;ExpressionAttributeValues\u0026#34; : { \u0026#34;:inc\u0026#34;: {\u0026#34;N\u0026#34; : \u0026#34;1\u0026#34;} } } } ]\u0026#39; Hãy xem mục Forum và bạn sẽ thấy rằng số đếm Messages đã được tăng lên 1, từ 4 lên 5.\naws dynamodb get-item \\ --table-name Forum \\ --key \u0026#39;{\u0026#34;Name\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB\u0026#34;}}\u0026#39; ... \u0026#34;Messages\u0026#34;: { \u0026#34;N\u0026#34;: \u0026#34;5\u0026#34; } ... Nếu bạn chạy cùng lệnh giao dịch này một lần nữa với cùng giá trị client-request-token, bạn có thể xác minh rằng các lần thực thi khác của giao dịch về cơ bản bị bỏ qua và thuộc tính Messages vẫn giữ nguyên ở 5.\nBây giờ chúng ta cần thực hiện một giao dịch khác để đảo ngược thao tác trên và dọn dẹp bảng:\naws dynamodb transact-write-items --client-request-token TRANSACTION2 --transact-items \u0026#39;[ { \u0026#34;Delete\u0026#34;: { \u0026#34;TableName\u0026#34; : \u0026#34;Reply\u0026#34;, \u0026#34;Key\u0026#34; : { \u0026#34;Id\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB#DynamoDB Thread 2\u0026#34;}, \u0026#34;ReplyDateTime\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;2021-04-27T17:47:30Z\u0026#34;} } } }, { \u0026#34;Update\u0026#34;: { \u0026#34;TableName\u0026#34; : \u0026#34;Forum\u0026#34;, \u0026#34;Key\u0026#34; : {\u0026#34;Name\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;Amazon DynamoDB\u0026#34;}}, \u0026#34;UpdateExpression\u0026#34;: \u0026#34;ADD Messages :inc\u0026#34;, \u0026#34;ExpressionAttributeValues\u0026#34; : { \u0026#34;:inc\u0026#34;: {\u0026#34;N\u0026#34; : \u0026#34;-1\u0026#34;} } } } ]\u0026#39; "
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.6/",
	"title": "Xem các game trước",
	"tags": [],
	"description": "",
	"content": "Trong module này, bạn sẽ xử lý mẫu truy cập cuối cùng — tìm tất cả các game đã chơi cho một người dùng. Người dùng trong ứng dụng có thể muốn xem lại các game mà họ đã chơi để xem lại trận đấu, hoặc họ có thể muốn xem các game của bạn bè.\nMẫu chỉ mục đảo ngược (Inverted index pattern) Bạn có thể nhớ rằng có một mối quan hệ nhiều-nhiều giữa thực thể Game và các thực thể User liên quan, và mối quan hệ này được biểu diễn bằng thực thể UserGameMapping.\nThường thì bạn muốn truy vấn cả hai phía của một mối quan hệ. Với cấu hình khóa chính hiện tại, bạn có thể tìm tất cả các thực thể User trong một Game. Bạn có thể cho phép truy vấn tất cả các thực thể Game cho một User bằng cách sử dụng một chỉ mục đảo ngược (inverted index).\nTrong DynamoDB, một chỉ mục đảo ngược là một chỉ mục thứ cấp toàn cục (GSI) mà trong đó khóa phân vùng và khóa sắp xếp của bạn được hoán đổi vị trí. Khóa sắp xếp trở thành khóa phân vùng và ngược lại. Mẫu này lật ngược bảng của bạn và cho phép bạn truy vấn phía bên kia của các mối quan hệ nhiều-nhiều.\nTrong các bước tiếp theo, bạn sẽ thêm một chỉ mục đảo ngược vào bảng và xem cách sử dụng nó để truy xuất tất cả các thực thể Game cho một User cụ thể.\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.5/1.5.7/",
	"title": "Access DynamoDB Table",
	"tags": [],
	"description": "",
	"content": "Amazon DynamoDB hỗ trợ PartiQL, một ngôn ngữ truy vấn tương thích với SQL, để chọn, chèn, cập nhật và xóa dữ liệu trong Amazon DynamoDB. Sử dụng PartiQL, bạn có thể dễ dàng tương tác với các bảng DynamoDB và chạy các truy vấn ad hoc bằng AWS Management Console. Trong bài tập này, chúng ta sẽ thực hành một số mẫu truy cập sử dụng các câu lệnh PartiQL.\nĐăng nhập vào DynamoDB console và chọn PartiQL editor từ thanh điều hướng bên trái. Chọn bảng movies đã được tạo và tải bằng công việc của Database Migration Service. Chọn dấu ba chấm bên cạnh tên bảng và nhấp vào \u0026ldquo;scan table\u0026rdquo;.\nChúng ta sẽ sử dụng các tập lệnh PartiQL để minh họa tất cả 6 mẫu truy cập đã được thảo luận ở chương trước. Trong ví dụ của chúng ta, chúng tôi sẽ cung cấp cho bạn các giá trị khóa phân vùng, nhưng trong thực tế bạn sẽ cần tạo một chỉ mục của các khóa có thể bằng cách sử dụng GSI. Lấy thông tin chi tiết của bộ phim: Mỗi bộ phim IMDB có một tconst duy nhất. Bảng đã không chuẩn hóa được tạo ra với mỗi hàng đại diện cho một sự kết hợp duy nhất của bộ phim và đoàn làm phim, tức là tconst và nconst. Vì tconst là một phần của khóa phân vùng cho bảng cơ sở, nó có thể được sử dụng trong điều kiện WHERE để chọn chi tiết. Sao chép lệnh dưới đây để chạy bên trong PartiQL query editor.\nTìm tất cả các diễn viên và đoàn làm phim đã làm việc trong một bộ phim. Truy vấn dưới đây sẽ bao gồm diễn viên, diễn viên nữ, nhà sản xuất, nhà quay phim, v.v. đã làm việc trong một bộ phim cho trước. SELECT * FROM \u0026#34;movies\u0026#34; WHERE \u0026#34;mpkey\u0026#34; = \u0026#39;tt0309377\u0026#39; and begins_with(\u0026#34;mskey\u0026#34;,\u0026#39;DETL|\u0026#39;) Tìm chỉ các diễn viên đã làm việc trong một bộ phim. SELECT * FROM \u0026#34;movies\u0026#34; WHERE \u0026#34;mpkey\u0026#34; = \u0026#39;tt0309377\u0026#39; and begins_with(\u0026#34;mskey\u0026#34;,\u0026#39;DETL|actor\u0026#39;) Tìm chỉ thông tin chi tiết của một bộ phim. SELECT * FROM \u0026#34;movies\u0026#34; WHERE \u0026#34;mpkey\u0026#34; = \u0026#39;tt0309377\u0026#39; and begins_with(\u0026#34;mskey\u0026#34;,\u0026#39;DETL|\u0026#39;) and \u0026#34;ordering\u0026#34; = \u0026#39;1\u0026#39; Tìm tất cả các vùng, ngôn ngữ và tiêu đề của một bộ phim. SELECT * FROM \u0026#34;movies\u0026#34; WHERE \u0026#34;mpkey\u0026#34; = \u0026#39;tt0309377\u0026#39; and begins_with(\u0026#34;mskey\u0026#34;,\u0026#39;REGN|\u0026#39;) Tìm tiêu đề phim cho một vùng cụ thể của một bộ phim. SELECT * FROM \u0026#34;movies\u0026#34; WHERE \u0026#34;mpkey\u0026#34; = \u0026#39;tt0309377\u0026#39; and begins_with(\u0026#34;mskey\u0026#34;,\u0026#39;REGN|NZ\u0026#39;) Tìm tiêu đề gốc của một bộ phim. SELECT * FROM \u0026#34;movies\u0026#34; WHERE \u0026#34;mpkey\u0026#34; = \u0026#39;tt0309377\u0026#39; and begins_with(\u0026#34;mskey\u0026#34;,\u0026#39;REGN|\u0026#39;) and \u0026#34;types\u0026#34; = \u0026#39;original\u0026#39; Để truy cập thông tin ở cấp độ thành viên đoàn làm phim (#6 trong mẫu truy cập), chúng ta cần tạo một Chỉ mục Thứ cấp Toàn cầu bổ sung (GSI) với khóa phân vùng mới nconst (duy nhất cho thành viên đoàn làm phim). Điều này sẽ cho phép truy vấn trên khóa phân vùng mới cho GSI thay vì quét trên bảng cơ sở.\nChọn \u0026ldquo;Tables\u0026rdquo; từ thanh điều hướng bên trái, chọn bảng movies và nhấp vào tab \u0026ldquo;Index\u0026rdquo;. Nhấp vào \u0026ldquo;Create Index\u0026rdquo; và thêm các chi tiết sau. Tham số Giá trị Partition key nconst Data type String Sort key - optional startYear Data type String Attribute projections All Cuối cùng, nhấp vào \u0026ldquo;Create Index\u0026rdquo;. Quá trình này có thể mất một giờ tùy thuộc vào số lượng bản ghi trong bảng cơ sở. Khi cột trạng thái GSI chuyển từ \u0026ldquo;Pending\u0026rdquo; sang \u0026ldquo;Available\u0026rdquo;, quay lại PartiQL editor để thực thi truy vấn trên GSI. Tìm tất cả các bộ phim của một đoàn làm phim (như diễn viên, đạo diễn, v.v.) SELECT * FROM \u0026#34;movies\u0026#34;.\u0026#34;nconst-startYear-index\u0026#34; WHERE \u0026#34;nconst\u0026#34; = \u0026#39;nm0000142\u0026#39; Tìm tất cả các bộ phim của một đoàn làm phim với vai trò diễn viên từ năm 2002 và sắp xếp theo năm tăng dần. SELECT * FROM \u0026#34;movies\u0026#34;.\u0026#34;nconst-startYear-index\u0026#34; WHERE \u0026#34;nconst\u0026#34; = \u0026#39;nm0000142\u0026#39; and \u0026#34;startYear\u0026#34; \u0026gt;= \u0026#39;2002\u0026#39; ORDER BY \u0026#34;startYear\u0026#34; Chúc mừng! Bạn đã hoàn thành bài tập di chuyển RDBMS.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.7/",
	"title": "Bài tập 6: Composite Keys",
	"tags": [],
	"description": "",
	"content": "Việc lựa chọn cẩn thận thuộc tính khóa sắp xếp rất quan trọng vì nó có thể cải thiện đáng kể khả năng lựa chọn các mục được truy xuất bằng truy vấn. Giả sử bạn cần tạo một ứng dụng để truy vấn nhân viên theo vị trí địa lý (tiểu bang và thành phố) và theo phòng ban. Bạn có các thuộc tính: state, city, và dept. Bạn có thể tạo một global secondary index kết hợp các thuộc tính này để cho phép truy vấn theo vị trí/phòng ban. Trong DynamoDB, bạn có thể truy vấn các mục bằng cách sử dụng sự kết hợp của khóa phân vùng và khóa sắp xếp. Trong trường hợp này, tiêu chí truy vấn của bạn cần sử dụng nhiều hơn hai thuộc tính, vì vậy bạn sẽ tạo một cấu trúc khóa tổng hợp (composite-key) cho phép bạn truy vấn với nhiều hơn hai thuộc tính.\nTrước đó (Bài tập 4, Bước 1) bạn đã chạy các lệnh để tạo bảng employees và nạp dữ liệu mẫu vào. Một trong những thuộc tính trong dữ liệu này được gọi là state, lưu trữ các chữ viết tắt hai chữ cái của các bang Hoa Kỳ. Ngoài ra, giá trị thuộc tính của state được thêm tiền tố state# và được lưu trữ dưới tên thuộc tính GSI_3_PK. Script cũng đã tạo thuộc tính city_dept đại diện cho một thuộc tính tổng hợp sử dụng các thuộc tính city và dept, được phân cách bằng ký tự # giữa các giá trị. Giá trị thuộc tính này sử dụng định dạng city#dept (ví dụ: Seattle#Development). Giá trị thuộc tính này được sao chép và lưu trữ dưới khóa GSI_3_SK.\nGSI_3 Tên Thuộc Tính (Loại) Thuộc Tính Đặc Biệt? Trường Hợp Sử Dụng Thuộc Tính Giá Trị Mẫu của Thuộc Tính GSI_3_PK (STRING) Khóa phân vùng của GSI_3 Tiểu bang của nhân viên state#WA GSI_3_SK (STRING) Khóa sắp xếp của GSI_3 Thành phố và phòng ban của nhân viên, được nối lại Seattle#Development Lưu ý: Mặc dù bạn đang tạo một global secondary index mới cho truy vấn này, bạn vẫn có thể nạp chồng chỉ mục phụ toàn cầu này trong tương lai. Việc nạp chồng chỉ mục phụ toàn cầu mang lại cho bạn sự linh hoạt để đặt các loại thực thể khác nhau vào cùng một chỉ mục (ví dụ: nhân viên và tòa nhà). Để hỗ trợ sự phát triển trong tương lai, khóa phân vùng GSI_3 được thêm hậu tố với loại thực thể, cho phép bạn chèn các hàng vào cùng một chỉ mục phụ toàn cầu sau này mà không cần kết hợp dữ liệu.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.8/",
	"title": "Bài tập 7: Adjacency Lists",
	"tags": [],
	"description": "",
	"content": "Khi các thực thể khác nhau của một ứng dụng có mối quan hệ nhiều-nhiều (many-to-many), việc mô hình hóa mối quan hệ này dưới dạng một danh sách liền kề (adjacency list) sẽ dễ dàng hơn. Trong mô hình này, tất cả các thực thể cấp cao nhất (đồng nghĩa với các nút trong mô hình đồ thị) được biểu diễn như là khóa phân vùng (partition key). Mọi mối quan hệ với các thực thể khác (các cạnh trong đồ thị) được biểu diễn như một mục trong phân vùng bằng cách đặt giá trị của khóa sắp xếp (sort key) thành ID của thực thể mục tiêu (nút mục tiêu).\nVí dụ này sử dụng bảng InvoiceAndBills để minh họa mẫu thiết kế này. Trong kịch bản này, một khách hàng có thể có nhiều hóa đơn, do đó có mối quan hệ 1-nhiều giữa ID khách hàng và ID hóa đơn. Một hóa đơn chứa nhiều hóa đơn chi tiết, và một hóa đơn chi tiết có thể được chia nhỏ và liên kết với nhiều hóa đơn. Vì vậy, có mối quan hệ nhiều-nhiều giữa ID hóa đơn và ID hóa đơn chi tiết. Thuộc tính khóa phân vùng là ID hóa đơn, ID hóa đơn chi tiết, hoặc ID khách hàng.\nBạn sẽ mô hình hóa bảng để thực hiện các truy vấn sau:\nSử dụng ID hóa đơn, truy xuất chi tiết hóa đơn cấp cao nhất, khách hàng và chi tiết hóa đơn liên quan. Truy xuất tất cả ID hóa đơn cho một khách hàng. Sử dụng ID hóa đơn chi tiết, truy xuất chi tiết hóa đơn chi tiết cấp cao nhất và chi tiết hóa đơn liên quan. Bảng: InvoiceAndBills Lược đồ khóa: HASH, RANGE (khóa phân vùng và khóa sắp xếp) Đơn vị dung lượng đọc bảng (RCUs) = 100 Đơn vị dung lượng ghi bảng (WCUs) = 100 Chỉ số phụ toàn cục (GSI): GSI_1 (100 RCUs, 100 WCUs) - Cho phép tra cứu ngược tới thực thể liên quan. Tên Thuộc Tính (Loại) Thuộc Tính Đặc Biệt? Trường Hợp Sử Dụng Thuộc Tính Giá Trị Mẫu Của Thuộc Tính PK (STRING) Khóa phân vùng Chứa ID của thực thể, có thể là hóa đơn chi tiết, hóa đơn, hoặc khách hàng B#3392 hoặc I#506 hoặc C#1317 SK (STRING) Khóa sắp xếp, khóa phân vùng của GSI_1 Chứa ID liên quan: có thể là hóa đơn chi tiết, hóa đơn, hoặc khách hàng B#1721 hoặc C#506 hoặc I#1317 "
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.2/3.2.7/",
	"title": "Bước 7 - Tạo bảng mới với global secondary index dung lượng thấp",
	"tags": [],
	"description": "",
	"content": "Bây giờ, hãy tạo một bảng mới với các đơn vị dung lượng khác nhau. Chỉ mục phụ toàn cầu (GSI) của bảng mới chỉ có 1 đơn vị dung lượng ghi (WCU) và 1 đơn vị dung lượng đọc (RCU).\nĐể tạo bảng mới, chạy lệnh AWS CLI sau:\naws dynamodb create-table --table-name logfile_gsi_low \\ --attribute-definitions AttributeName=PK,AttributeType=S AttributeName=GSI_1_PK,AttributeType=S \\ --key-schema AttributeName=PK,KeyType=HASH \\ --provisioned-throughput ReadCapacityUnits=1000,WriteCapacityUnits=1000 \\ --tags Key=workshop-design-patterns,Value=targeted-for-cleanup \\ --global-secondary-indexes \u0026#34;IndexName=GSI_1,\\ KeySchema=[{AttributeName=GSI_1_PK,KeyType=HASH}],\\ Projection={ProjectionType=INCLUDE,NonKeyAttributes=[\u0026#39;bytessent\u0026#39;]},\\ ProvisionedThroughput={ReadCapacityUnits=1,WriteCapacityUnits=1}\u0026#34; Chạy lệnh AWS CLI sau để đợi cho đến khi bảng chuyển sang trạng thái ACTIVE:\naws dynamodb wait table-exists --table-name logfile_gsi_low Lệnh đầu tiên tạo một bảng mới và một chỉ mục phụ toàn cầu với định nghĩa sau:\nBảng: logfile_gsi_low Sơ đồ khóa: HASH (partition key) Số đơn vị dung lượng đọc (RCUs) của bảng = 1000 Số đơn vị dung lượng ghi (WCUs) của bảng = 1000 Chỉ mục phụ toàn cầu: GSI_1 (1 RCU, 1 WCU) - Cho phép truy vấn theo địa chỉ IP của host Tên thuộc tính (Loại) Thuộc tính đặc biệt? Trường hợp sử dụng thuộc tính Giá trị mẫu của thuộc tính PK (STRING) Partition key Lưu giữ request ID cho nhật ký truy cập request#104009 GSI_1_PK (STRING) GSI 1 partition key Host cho yêu cầu, một địa chỉ IPv4 host#66.249.67.3 Hãy nạp dữ liệu lớn vào bảng này. Bạn sẽ sử dụng phiên bản script tải dữ liệu Python có nhiều luồng để mô phỏng nhiều lần ghi mỗi giây vào bảng DynamoDB. Điều này sẽ tạo ra sự tranh chấp cho dung lượng cấp phát để mô phỏng một đợt tăng lưu lượng truy cập trên một bảng bị cấp phát dưới mức.\npython load_logfile_parallel.py logfile_gsi_low Sau vài phút, việc thực thi script này sẽ bị giới hạn và hiển thị một thông báo lỗi tương tự như lỗi sau. Điều này cho thấy bạn nên tăng dung lượng cấp phát của bảng DynamoDB hoặc kích hoạt tính năng tự động mở rộng của DynamoDB nếu bạn chưa làm như vậy (đọc thêm về tự động mở rộng DynamoDB trong tài liệu AWS).\nProvisionedThroughputExceededException: An error occurred (ProvisionedThroughputExceededException) when calling the BatchWriteItem operation (reached max retries: 9): The level of configured provisioned throughput for one or more global secondary indexes of the table was exceeded. Consider increasing your provisioning level for the under-provisioned global secondary indexes with the UpdateTable API Bạn có thể tạm dừng hoạt động bằng cách nhấn Ctrl+Z (Ctrl+C nếu bạn sử dụng Mac). Bảng mới này có nhiều RCUs (1,000) và WCUs (1,000), nhưng bạn vẫn gặp lỗi và thời gian tải tăng lên.\nChủ đề thảo luận: Bạn có thể giải thích hành vi của bài kiểm tra không? Một ngoại lệ có tên ProvisionedThroughputExceededException đã được DynamoDB trả về với thông báo ngoại lệ đề xuất tăng dung lượng cấp phát của GSI. Đây là một lỗi quan trọng và cần phải được xử lý. Nói ngắn gọn, nếu bạn muốn 100% các lần ghi trên bảng cơ sở DynamoDB được sao chép vào GSI, thì GSI nên được cấp phát với 100% (cùng mức) dung lượng trên bảng cơ sở, trong ví dụ này là 1,000 WCU. Đơn giản là GSI đã bị cấp phát dưới mức.\nXem lại bảng trong AWS Console Hãy xem lại các số liệu Amazon CloudWatch cho bài kiểm tra này trong bảng điều khiển quản lý AWS của Amazon DynamoDB. Chúng ta cần xem các số liệu nào đã được gửi tới CloudWatch trong khoảng thời gian ghi bị giới hạn này.\nMở bảng điều khiển AWS, hoặc chuyển sang tab trình duyệt của bạn với bảng điều khiển AWS, để xem các số liệu cho bảng logfile_gsi_low. Những số liệu này được tìm thấy dưới phần DynamoDB của bảng điều khiển quản lý AWS trong chế độ xem bảng. Nếu bạn không thấy bảng, hãy nhớ nhấn nút làm mới ở góc trên bên phải của bảng điều khiển DynamoDB.\nHình ảnh sau đây hiển thị số liệu dung lượng ghi cho bảng logfile_gsi_low. Lưu ý rằng các lần ghi đã tiêu thụ (đường màu xanh) thấp hơn so với các lần ghi cấp phát (đường màu đỏ) cho bảng trong bài kiểm tra. Điều này cho thấy bảng cơ sở có đủ dung lượng ghi cho đợt tăng yêu cầu.\nCó thể mất vài phút để dung lượng cấp phát (đường màu đỏ) hiển thị trên các biểu đồ. Các số liệu dung lượng cấp phát là tổng hợp và có thể có độ trễ từ năm đến mười phút cho đến khi chúng hiển thị sự thay đổi.\nHình ảnh sau đây hiển thị số liệu dung lượng ghi cho chỉ mục phụ toàn cầu. Lưu ý rằng các lần ghi đã tiêu thụ (đường màu xanh) cao hơn so với các lần ghi cấp phát (đường màu đỏ) cho chỉ mục phụ toàn cầu trong bài kiểm tra. Điều này cho thấy GSI đã bị cấp phát dưới mức đáng kể cho các yêu cầu mà nó nhận được.\nHình ảnh sau đây hiển thị các yêu cầu ghi bị giới hạn cho bảng logfile_gsi_low. Lưu ý rằng bảng có các yêu cầu ghi bị giới hạn, mặc dù bảng cơ sở đã được cấp phát đủ WCUs. Mỗi yêu cầu API bị giới hạn trên DynamoDB tạo ra một điểm dữ liệu cho số liệu ThrottledRequests. Trong hình này, khoảng 20 yêu cầu API đã bị giới hạn bởi DynamoDB. Tuy nhiên, bảng có một GSI và chúng ta chưa biết nếu GSI hoặc bảng cơ sở là nguồn của việc giới hạn. Chúng ta cần tiếp tục điều tra. Để xác định nguồn gốc của các yêu cầu ghi bị giới hạn này, hãy xem lại số liệu sự kiện ghi bị giới hạn. Nếu bảng cơ sở DynamoDB là nguồn giới hạn, nó sẽ có WriteThrottleEvents. Tuy nhiên, nếu GSI có dung lượng ghi không đủ, nó cũng sẽ có WriteThrottleEvents.\nKhi bạn xem xét các sự kiện giới hạn cho GSI, bạn sẽ thấy nguồn gốc của các lần giới hạn! Chỉ có GSI có \u0026lsquo;Throttled write events\u0026rsquo;, điều này có nghĩa là nó là nguồn gây ra giới hạn trên bảng, và là nguyên nhân của các yêu cầu ghi Batch bị giới hạn.\nCó thể mất một thời gian để các sự kiện ghi bị giới hạn xuất hiện trên biểu đồ sự kiện ghi bị giới hạn của GSI. Nếu bạn không thấy ngay lập tức các số liệu, hãy chạy lại lệnh trên để nạp dữ liệu vào DynamoDB và để nó tiếp tục trong vài phút để tạo ra nhiều sự kiện giới hạn.\nKhi việc giới hạn ghi của chỉ mục phụ toàn cầu (GSI) của DynamoDB đủ để tạo ra các yêu cầu bị giới hạn, hành vi này được gọi là áp lực ngược của GSI (GSI back pressure). Các yêu cầu bị giới hạn là lỗi ProvisionedThroughputExceededException trong các SDK của AWS, tạo ra các số liệu ThrottledRequests trong CloudWatch và\n"
},
{
	"uri": "//localhost:1313/vi/1-lhol/1.2/1.2.7/",
	"title": "Global Secondary Indexes",
	"tags": [],
	"description": "",
	"content": "Chúng ta đã chú ý đến việc truy cập dữ liệu dựa trên các thuộc tính khóa cho đến nay. Nếu chúng ta muốn tìm kiếm các mục dựa trên các thuộc tính không phải khóa, chúng ta phải thực hiện quét toàn bộ bảng và sử dụng điều kiện lọc để tìm những gì chúng ta muốn, điều này vừa chậm vừa tốn kém cho các hệ thống hoạt động ở quy mô lớn.\nDynamoDB cung cấp một tính năng gọi là Global Secondary Indexes (GSIs), cho phép tự động chuyển đổi dữ liệu của bạn xung quanh các Khóa Phân vùng và Khóa Sắp xếp khác nhau. Dữ liệu có thể được nhóm lại và sắp xếp lại để cho phép nhiều mẫu truy cập hơn nhanh chóng được phục vụ thông qua các API Query và Scan.\nNhớ lại ví dụ trước đó, nơi chúng ta muốn tìm tất cả các phản hồi trong bảng Reply được viết bởi User A:\naws dynamodb scan \\ --table-name Reply \\ --filter-expression \u0026#39;PostedBy = :user\u0026#39; \\ --expression-attribute-values \u0026#39;{ \u0026#34;:user\u0026#34; : {\u0026#34;S\u0026#34;: \u0026#34;User A\u0026#34;} }\u0026#39; \\ --return-consumed-capacity TOTAL Khi thực hiện lệnh quét đó, chúng ta có thể thấy rằng số Count trả về khác với ScannedCount. Nếu có một tỷ mục Reply nhưng chỉ ba trong số đó được viết bởi User A, chúng ta sẽ phải trả phí (cả về thời gian và tiền bạc) để quét qua một tỷ mục chỉ để tìm ba mục mà chúng ta muốn.\nVới kiến thức về GSIs, chúng ta giờ đây có thể tạo một GSI trên bảng Reply để phục vụ mẫu truy cập mới này. GSIs có thể được tạo và xóa bất kỳ lúc nào, ngay cả khi bảng đã có dữ liệu! GSI mới này sẽ sử dụng thuộc tính PostedBy làm khóa Phân vùng (HASH) và chúng ta vẫn giữ các tin nhắn được sắp xếp theo ReplyDateTime làm khóa Sắp xếp (RANGE). Chúng ta muốn tất cả các thuộc tính từ bảng được sao chép (dự đoán) vào GSI, vì vậy chúng ta sẽ sử dụng ALL ProjectionType. Lưu ý rằng tên của chỉ mục chúng ta tạo là PostedBy-ReplyDateTime-gsi.\naws dynamodb update-table \\ --table-name Reply \\ --attribute-definitions AttributeName=PostedBy,AttributeType=S AttributeName=ReplyDateTime,AttributeType=S \\ --global-secondary-index-updates \u0026#39;[{ \u0026#34;Create\u0026#34;:{ \u0026#34;IndexName\u0026#34;: \u0026#34;PostedBy-ReplyDateTime-gsi\u0026#34;, \u0026#34;KeySchema\u0026#34;: [ { \u0026#34;AttributeName\u0026#34; : \u0026#34;PostedBy\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;HASH\u0026#34; }, { \u0026#34;AttributeName\u0026#34; : \u0026#34;ReplyDateTime\u0026#34;, \u0026#34;KeyType\u0026#34;: \u0026#34;RANGE\u0026#34; } ], \u0026#34;ProvisionedThroughput\u0026#34;: { \u0026#34;ReadCapacityUnits\u0026#34;: 5, \u0026#34;WriteCapacityUnits\u0026#34;: 5 }, \u0026#34;Projection\u0026#34;: { \u0026#34;ProjectionType\u0026#34;: \u0026#34;ALL\u0026#34; } } }]\u0026#39; Có thể mất một chút thời gian trong khi DynamoDB tạo GSI và sao chép dữ liệu từ bảng vào chỉ mục. Chúng ta có thể theo dõi điều này từ dòng lệnh và đợi cho đến khi IndexStatus trở thành ACTIVE:\n# Lấy trạng thái ban đầu aws dynamodb describe-table --table-name Reply --query \u0026#34;Table.GlobalSecondaryIndexes[0].IndexStatus\u0026#34; # Theo dõi trạng thái với lệnh chờ (sử dụng Ctrl+C để thoát): watch -n 5 \u0026#34;aws dynamodb describe-table --table-name Reply --query \u0026#34;Table.GlobalSecondaryIndexes[0].IndexStatus\u0026#34;\u0026#34; Khi GSI đã trở thành ACTIVE, hãy tiếp tục với bài tập dưới đây. Sử dụng Ctrl+C để thoát lệnh theo dõi.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.1/3.1.7/",
	"title": "Kết nối đến máy chủ Public",
	"tags": [],
	"description": "",
	"content": " Lưu ý: Tất cả các lệnh đều được thực thi trong bảng điều khiển shell kết nối với phiên bản EC2, không phải trên máy tính cục bộ của bạn. (Nếu bạn không chắc chắn, bạn luôn có thể xác nhận lại bằng cách quay lại bước 1)\nTrong bước này, chúng ta sẽ nạp 1 triệu mục vào bảng để chuẩn bị cho bài tập này.\nChạy lệnh để tạo một bảng mới:\naws dynamodb create-table --table-name logfile_scan \\ --attribute-definitions AttributeName=PK,AttributeType=S AttributeName=GSI_1_PK,AttributeType=S AttributeName=GSI_1_SK,AttributeType=S \\ --key-schema AttributeName=PK,KeyType=HASH \\ --provisioned-throughput ReadCapacityUnits=5000,WriteCapacityUnits=5000 \\ --tags Key=workshop-design-patterns,Value=targeted-for-cleanup \\ --global-secondary-indexes \u0026#34;IndexName=GSI_1,\\ KeySchema=[{AttributeName=GSI_1_PK,KeyType=HASH},{AttributeName=GSI_1_SK,KeyType=RANGE}],\\ Projection={ProjectionType=KEYS_ONLY},\\ ProvisionedThroughput={ReadCapacityUnits=3000,WriteCapacityUnits=5000}\u0026#34; Lệnh này sẽ tạo một bảng mới và một GSI với định nghĩa sau:\nBảng: logfile_scan Key schema: HASH Table RCU = 5000 Table WCU = 5000 GSI(s): GSI_1 (3000 RCU, 5000 WCU) - Cho phép quét song song hoặc tuần tự các nhật ký truy cập. Sắp xếp theo mã trạng thái và dấu thời gian. Tên thuộc tính (Loại) Thuộc tính đặc biệt? Trường hợp sử dụng thuộc tính Giá trị mẫu của thuộc tính PK (STRING) Hash key Lưu giữ request id cho nhật ký truy cập request#104009 GSI_1_PK (STRING) GSI 1 hash key Khóa shard, với các giá trị từ 0-N, để cho phép tìm kiếm nhật ký shard#3 GSI_1_SK (STRING) GSI 1 sort key Sắp xếp các nhật ký theo thứ bậc, từ mã trạng thái -\u0026gt; ngày -\u0026gt; giờ 200#2019-09-21#01 Chạy lệnh để đợi cho đến khi bảng trở thành Active:\naws dynamodb wait table-exists --table-name logfile_scan Nạp dữ liệu vào bảng Chạy lệnh sau để tải dữ liệu nhật ký máy chủ vào bảng logfile_scan. Lệnh này sẽ nạp 1,000,000 dòng vào bảng.\nnohup python load_logfile_parallel.py logfile_scan \u0026amp; disown nohup được sử dụng để chạy tiến trình trong nền, và disown cho phép tiến trình tải tiếp tục ngay cả khi bạn bị ngắt kết nối.\nLệnh sau sẽ mất khoảng mười phút để hoàn thành. Nó sẽ chạy ở chế độ nền.\nChạy pgrep -l python để xác minh rằng script đang tải dữ liệu trong nền.\npgrep -l python Kết quả:\n3257 python Process id - số 4 chữ số trong ví dụ trên - sẽ khác nhau đối với mỗi người.\nScript sẽ tiếp tục chạy trong nền trong khi bạn làm bài tập tiếp theo.\nBạn đã hoàn thành phần THIẾT LẬP!\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/",
	"title": "LGME: Lập mô hình dữ liệu người chơi trò chơi với Amazon DynamoDB",
	"tags": [],
	"description": "",
	"content": "Trong workshop này, bạn sẽ học các mẫu mô hình dữ liệu nâng cao trong Amazon DynamoDB. Khi sử dụng DynamoDB, điều quan trọng là phải xem xét cách bạn sẽ truy cập dữ liệu của mình (các mẫu truy cập) trước khi mô hình hóa dữ liệu. Bạn sẽ đi qua một ví dụ về ứng dụng trò chơi nhiều người chơi, tìm hiểu về các mẫu truy cập trong ứng dụng trò chơi đó, và xem cách thiết kế một bảng DynamoDB để xử lý các mẫu truy cập bằng cách sử dụng chỉ mục phụ và giao dịch.\nĐọc thêm về cách DynamoDB được sử dụng bởi các khách hàng hiện tại trong GameTech, đặc biệt tại: https://aws.amazon.com/dynamodb/gaming/\nNội dung của workshop này bao gồm:\nBắt đầu Lập kế hoạch mô hình dữ liệu của bạn Sử dụng cốt lõi: hồ sơ người dùng và trò chơi Tìm trò chơi đang mở Tham gia và đóng trò chơi Xem lại các trò chơi trước đây Tóm tắt \u0026amp; Dọn dẹp Đối tượng mục tiêu Workshop này được thiết kế cho các nhà phát triển, kỹ sư, và quản trị viên cơ sở dữ liệu, những người tham gia vào việc thiết kế và duy trì các ứng dụng DynamoDB.\n"
},
{
	"uri": "//localhost:1313/vi/7-lgme/7.7/",
	"title": "Tóm tắt và dọn dẹp tài nguyên",
	"tags": [],
	"description": "",
	"content": "Dưới đây là bản dịch sang tiếng Việt, giữ nguyên các thuật ngữ chuyên ngành:\nTrong các module trước, các mẫu truy cập trong ứng dụng game đã được xử lý như sau:\nTạo hồ sơ người dùng (Write) Cập nhật hồ sơ người dùng (Write) Lấy hồ sơ người dùng (Read) Tạo game (Write) Tìm game mở (Read) Xem game (Read) Tham gia game cho người dùng (Write) Bắt đầu game (Write) Cập nhật game cho người dùng (Write) Cập nhật game (Write) Tìm game cho người dùng (Read) Các chiến lược được sử dụng để thỏa mãn các mẫu này bao gồm:\nThiết kế bảng đơn để kết hợp nhiều loại thực thể trong một bảng. Khóa chính tổng hợp cho phép mối quan hệ nhiều-nhiều. Chỉ mục thứ cấp toàn cục thưa (GSI) để lọc trên một trong các trường. Giao dịch DynamoDB để xử lý các mẫu ghi phức tạp trên nhiều thực thể. Chỉ mục đảo ngược (GSI) để cho phép tra cứu ngược trên thực thể nhiều-nhiều. Chúc mừng! Bạn đã hoàn thành khóa học này. Vui lòng dành vài phút để chia sẻ phản hồi của bạn với chúng tôi qua liên kết mà bạn đã nhận được từ người hướng dẫn lab.\nDọn dẹp Nếu bạn đang chạy lab này trong Tài khoản AWS của riêng mình (không phải sự kiện do AWS tổ chức), đừng quên dọn dẹp tài nguyên bằng cách xóa CloudFormation stack hoặc các tài nguyên (trong trường hợp không có CloudFormation stack) mà bạn đã sử dụng trong quá trình thiết lập.\nNếu bạn đang thực hiện lab trong Tài khoản AWS của mình, bạn sẽ tạo các bảng DynamoDB mà sẽ phát sinh chi phí có thể lên đến hàng chục hoặc hàng trăm đô la mỗi ngày. Hãy đảm bảo xóa các bảng DynamoDB bằng cách sử dụng bảng điều khiển DynamoDB và chắc chắn rằng bạn xóa môi trường Cloud9 ngay khi hoàn thành lab.\n"
},
{
	"uri": "//localhost:1313/vi/8-ldc/",
	"title": "LDC: Những thách thức thiết kế",
	"tags": [],
	"description": "",
	"content": "Thử thách thiết kế Đây là một bộ sưu tập các kịch bản thử thách về thiết kế mô hình dữ liệu để giúp bạn hiểu rõ hơn các quyết định mà bạn đưa ra khi xây dựng các mô hình dữ liệu hiệu quả. Mặc dù không bắt buộc cho phần này, NoSQL Workbench for Amazon DynamoDB là một công cụ tuyệt vời giúp bạn xây dựng, trực quan hóa và thao tác các mô hình dữ liệu cho DynamoDB.\n"
},
{
	"uri": "//localhost:1313/vi/3-ladv/3.9/",
	"title": "Bài tập 8: Amazon DynamoDB Streams và AWS Lambda",
	"tags": [],
	"description": "",
	"content": "Kết hợp DynamoDB Streams (tài liệu giải thích dịch vụ) với AWS Lambda mang lại nhiều mẫu thiết kế mạnh mẽ. Trong bài tập này, bạn sẽ sao chép các mục từ một bảng DynamoDB sang một bảng khác bằng cách sử dụng DynamoDB Streams và các hàm Lambda.\nDynamoDB Streams ghi lại một chuỗi các thay đổi cấp mục theo thứ tự thời gian trong bất kỳ bảng DynamoDB nào và lưu trữ thông tin này trong một bản ghi (log) lên đến 24 giờ. Các ứng dụng có thể truy cập vào bản ghi này và xem các mục dữ liệu như chúng đã xuất hiện trước và sau khi được sửa đổi, gần như thời gian thực. DynamoDB Streams cung cấp các trường hợp sử dụng sau:\nMột trò chơi nhiều người chơi toàn cầu có kiến trúc cơ sở dữ liệu nhiều lãnh đạo, lưu trữ dữ liệu ở nhiều khu vực AWS (AWS Regions). Mỗi khu vực luôn đồng bộ hóa bằng cách tiêu thụ và phát lại các thay đổi xảy ra ở các khu vực từ xa. (Thực tế, DynamoDB Global Tables dựa vào DynamoDB Streams để thực hiện việc sao chép toàn cầu.) Một khách hàng mới thêm dữ liệu vào một bảng DynamoDB. Sự kiện này kích hoạt một hàm AWS Lambda để sao chép dữ liệu sang một bảng DynamoDB riêng biệt để lưu trữ lâu dài (Điều này rất giống với bài tập này, nơi chúng ta sao chép dữ liệu từ một bảng DynamoDB sang một bảng khác bằng cách sử dụng DynamoDB Streams.) Bạn sẽ tái sử dụng bảng logfile mà bạn đã tạo trong Bài tập 1. Bạn sẽ kích hoạt DynamoDB Streams trên bảng logfile. Mỗi khi có sự thay đổi trong bảng logfile, thay đổi này sẽ xuất hiện ngay lập tức trong một stream. Tiếp theo, bạn gắn một hàm Lambda vào stream. Mục đích của hàm Lambda là truy vấn DynamoDB Streams để lấy các bản cập nhật cho bảng logfile và ghi các bản cập nhật này vào một bảng mới được tạo tên là logfile_replica. Sơ đồ sau đây cho thấy tổng quan về triển khai này.\n"
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]